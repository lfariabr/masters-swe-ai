{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OooAnVITeXWC"
      },
      "source": [
        "# Introduction to Natural Language  Processing (NLP)\n",
        "\n",
        "Reference Video is **[here](https://www.youtube.com/watch?v=fOvTtapxa9c)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL5A3nKGeXYv"
      },
      "source": [
        "## Why is NLP Important?\n",
        "\n",
        "Large volumes of text data that are largely unstructured  are being generated every second. Humans are not able to decipher the underlying knowledge about them and  make decisions.  This is what makes Natural Language  Processing (NLP) important.\n",
        "\n",
        "The below inforgraphic details the amount  of  data  generated per minute in 2019.\n",
        "![Per Minute Data Generation in 2019](https://2oqz471sa19h3vbwa53m33yj-wpengine.netdna-ssl.com/wp-content/uploads/2019/07/big-data-getting-bigger.jpg)\n",
        "**Image source https://bit.ly/3dh0oUW**\n",
        "\n",
        "With the expontial increase in devices, cheaper internet connectivity etc , data and  more so text data is  bound  to increase. Understanding this data to make business decisions  is  the reason why NLP is important going forward.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Oz661UnesKI"
      },
      "source": [
        "## History of NLP\n",
        "\n",
        "NLP as a field of Artificial Intelligence (AI) helps computers understand, utilize, and interpret human languages. This way, computers can connect with  people. History of  NLP dates back to 1957  when  Noam Chomsky published the book \"[Syntactic Structures](https://doubleoperative.files.wordpress.com/2009/12/chomsky-syntactic-structures-2ed.pdf)\". The conclusion was that for a computer to understand a language, the sentence  structure had to be changed too. This early research called for more innovation in making human languages understandable to computers. Right now, neural networks are able to  even understand the structure of  sentences and  to a large extent can correctly predict the next word a human would say/write in a sentence. A brief history of  NLP can be found  [**here**](https://en.wikipedia.org/wiki/History_of_natural_language_processing)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRAJxG_7evQT"
      },
      "source": [
        "## Applications of  NLP\n",
        "\n",
        "Some of the application areas in NLP are below:-\n",
        "\n",
        "1.   Content Categorization\n",
        "2.   Document Summarization\n",
        "3.   Sentiment Analysis and opinion mining\n",
        "4.   Text-to-Speech and Speech-to-Text Conversion\n",
        "5.   Topic Discovery and Modeling\n",
        "6.   Machine Translation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmR1jrQjfHOg"
      },
      "source": [
        "# Introduction to Natural Language  Toolkit (NLTK)\n",
        "\n",
        "**Paper:** Loper, E., & Bird, S. (2002). NLTK: the natural language toolkit. arXiv preprint cs/0205028"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri7ZmwqXgLcT"
      },
      "source": [
        "## Text Wrangling\n",
        "\n",
        "Wrangling text simply refers to the pre-processing  work that is applied on raw text to make it clean and more readable to computers  for  training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OS3iuPYbePm"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "We'll be making use of  the sentiment140 [Twitter Dataset](https://www.kaggle.com/kazanova/sentiment140) annotated with sentiments. It contains 1,600,000 tweets extracted using the twitter api . The tweets have been annotated (0 = negative, 4 = positive) and they can be used to detect sentiment. To a large extent, we'll be  making use of the \"text\" field in the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HENMgvXsY40L",
        "outputId": "41aba889-16f0-4144-d64f-7c9c89fbfb2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Import all the packages for data wrangling\n",
        "\n",
        "from nltk.tokenize import TweetTokenizer  #tokenizer for  tweets\n",
        "import numpy as np\n",
        "import sys\n",
        "import pandas as pd\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "stop = stopwords.words('english')\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%tensorflow_version 1.x #Invokes  running of TensorFlow (TF) version 1.xx. This version will work with BertLibrary package.\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTJuCLg0hlzk",
        "outputId": "009a6c34-aefb-4f7b-c43d-7a2e413085e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Google Colab Specific to access the location with the notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICSooLW62oNd",
        "outputId": "4ed784be-78ba-412c-bd2c-c9b1126184d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwsnf1-3h3Uc",
        "outputId": "cd88b2fa-e0f0-4d23-94b4-2359e983f85f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive/My Drive/Torrens/NLP/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Torrens/NLP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWe_beO2dosM",
        "outputId": "d2dfa484-70b4-4c9c-b168-2405099d4f56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Read the datase. Pandas package is  quite  helpful here. I'll write it as function\n",
        "dataset_columns = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"] #dataset columns\n",
        "def read_data():\n",
        "    dataset = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", encoding = \"ISO-8859-1\", names=dataset_columns) # Enter your file location\n",
        "    dataset.drop_duplicates(inplace=True)\n",
        "    dataset = dataset[dataset['text'].isnull() == False]\n",
        "    dataset.reset_index(inplace=True)\n",
        "    dataset.drop('index', axis=1, inplace=True)\n",
        "    print ('Dataset loaded with shape', dataset.shape  )\n",
        "    return dataset\n",
        "\n",
        "dataset = read_data() #Call the function defined above"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset loaded with shape (1600000, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtj90nMtlLtm",
        "outputId": "37f5e2ef-cd80-4eed-c5a1-c52e848b6d89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dataset.head() #Sample output . Instead  of \"head\", you use \"tail\" to view the  last records in the dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target  ...                                               text\n",
              "0       0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1       0  ...  is upset that he can't update his Facebook by ...\n",
              "2       0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "3       0  ...    my whole body feels itchy and like its on fire \n",
              "4       0  ...  @nationwideclass no, it's not behaving at all....\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5YMv9S4hq2w"
      },
      "source": [
        "### Cleaning Stop Word Removal\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj_7WFvRnpBx"
      },
      "source": [
        "#this  will take sometime  on a slow computer to clean the text part of the tweet\n",
        "dataset['text'] = dataset['text'].map(lambda x:re.sub('[^a-zA-Z]',' ',str(x))) #remove numbers. Not  o interest in this aspect\n",
        "dataset['text'] = dataset['text'].map(lambda x:re.sub('http.*','',str(x))) #Remove  hyperlinks\n",
        "dataset['text'] = dataset['text'].map(lambda x:re.sub(r'#','',str(x))) #Remove hashtags. Not of  interest\n",
        "dataset['text'] = dataset['text'].map(lambda x:re.sub(r'@\\w*','',str(x))) #Remove user mentions\n",
        "dataset['text'] = dataset['text'].map(lambda x:str(x).lower()) #lower case everything\n",
        "dataset['text'] = dataset['text'].str.split().map(lambda sl: \" \".join(s for s in sl if len(s) > 3)) #Remove words with less than characters\n",
        "dataset['text'] = dataset['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)])) #Stop word removal. Uses the defined NLTK stopword list defined above\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TFgQl8gpJ45",
        "outputId": "46868012-3106-4436-9ad5-c5241a3a503a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dataset.tail() # View cleaner tweets in the text part"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1599995</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601966</td>\n",
              "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>AmandaMarie1028</td>\n",
              "      <td>woke school best feeling ever</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599996</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601969</td>\n",
              "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>TheWDBoards</td>\n",
              "      <td>thewdb cool hear walt interviews</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599997</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601991</td>\n",
              "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>bpbabe</td>\n",
              "      <td>ready mojo makeover details</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599998</th>\n",
              "      <td>4</td>\n",
              "      <td>2193602064</td>\n",
              "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>tinydiamondz</td>\n",
              "      <td>happy birthday alll time tupac amaru shakur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599999</th>\n",
              "      <td>4</td>\n",
              "      <td>2193602129</td>\n",
              "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>RyanTrevMorris</td>\n",
              "      <td>happy charitytuesday thenspcc sparkscharity sp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         target  ...                                               text\n",
              "1599995       4  ...                      woke school best feeling ever\n",
              "1599996       4  ...                   thewdb cool hear walt interviews\n",
              "1599997       4  ...                        ready mojo makeover details\n",
              "1599998       4  ...        happy birthday alll time tupac amaru shakur\n",
              "1599999       4  ...  happy charitytuesday thenspcc sparkscharity sp...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Yw3zoZgpyRo"
      },
      "source": [
        "### Tokenization\n",
        "\n",
        "Tokenization breaks up a sequence of strings into words, keywords, phrases, symbols and other elements called tokens.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxCJ3ksp38Yv",
        "outputId": "4b3c72f0-2f96-4a00-8d51-63d4e4d8872a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#tokenization function\n",
        "def tokenization (text):\n",
        "  tokens = re.split('\\W+',text)\n",
        "  return tokens\n",
        "\n",
        "#Call the tokenization function\n",
        "dataset['tokens'] = dataset['text'].apply(lambda x: tokenization(x))\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>switchfoot</td>\n",
              "      <td>[switchfoot]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>upset update facebook texting might result sch...</td>\n",
              "      <td>[upset, update, facebook, texting, might, resu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>kenichan dived many times ball managed save re...</td>\n",
              "      <td>[kenichan, dived, many, times, ball, managed, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>whole body feels itchy like fire</td>\n",
              "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>nationwideclass behaving</td>\n",
              "      <td>[nationwideclass, behaving]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target  ...                                             tokens\n",
              "0       0  ...                                       [switchfoot]\n",
              "1       0  ...  [upset, update, facebook, texting, might, resu...\n",
              "2       0  ...  [kenichan, dived, many, times, ball, managed, ...\n",
              "3       0  ...            [whole, body, feels, itchy, like, fire]\n",
              "4       0  ...                        [nationwideclass, behaving]\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZVv9F9vhy6v"
      },
      "source": [
        "### Stemming and Lemmatisation\n",
        "\n",
        "Stemming is closely related to lemmatisation in the way the two categorize similar words. Words like ***fishing, fished***, and ***fisherto*** can be stemmed to \"***fish***\". A stemmer operates on a single word without knowledge of the context, and therefore cannot discriminate between words which have different meanings depending on part of speech.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnMA4BPlykal",
        "outputId": "ea28413e-ef4e-4390-8cb9-2e4da1ed4be8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "#Lemmatization\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = nltk.WordNetLemmatizer()\n",
        "def lemmatize_text(text):\n",
        "  output = [lemmatizer.lemmatize(word) for  word in text]\n",
        "  return output\n",
        "dataset[\"Lemmatized_text\"] = dataset[\"tokens\"].apply(lambda x: lemmatize_text(x))\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>Lemmatized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>switchfoot</td>\n",
              "      <td>[switchfoot]</td>\n",
              "      <td>[switchfoot]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>upset update facebook texting might result sch...</td>\n",
              "      <td>[upset, update, facebook, texting, might, resu...</td>\n",
              "      <td>[upset, update, facebook, texting, might, resu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>kenichan dived many times ball managed save re...</td>\n",
              "      <td>[kenichan, dived, many, times, ball, managed, ...</td>\n",
              "      <td>[kenichan, dived, many, time, ball, managed, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>whole body feels itchy like fire</td>\n",
              "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
              "      <td>[whole, body, feel, itchy, like, fire]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>nationwideclass behaving</td>\n",
              "      <td>[nationwideclass, behaving]</td>\n",
              "      <td>[nationwideclass, behaving]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target  ...                                    Lemmatized_text\n",
              "0       0  ...                                       [switchfoot]\n",
              "1       0  ...  [upset, update, facebook, texting, might, resu...\n",
              "2       0  ...  [kenichan, dived, many, time, ball, managed, s...\n",
              "3       0  ...             [whole, body, feel, itchy, like, fire]\n",
              "4       0  ...                        [nationwideclass, behaving]\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xthZjmN9Jrs"
      },
      "source": [
        "Nothing  much changes on the tokens when lemmatized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7Jy343r3PR2",
        "outputId": "4aad8828-252c-49ec-ae54-ace270d84427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "#Stemming\n",
        "stemmer = nltk.PorterStemmer()\n",
        "def stem_text(text):\n",
        "  output = [stemmer.stem(word) for  word in text]\n",
        "  return output\n",
        "dataset[\"Stemmed_text\"] = dataset[\"tokens\"].apply(lambda x: stem_text(x))\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>Lemmatized_text</th>\n",
              "      <th>Stemmed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>switchfoot</td>\n",
              "      <td>[switchfoot]</td>\n",
              "      <td>[switchfoot]</td>\n",
              "      <td>[switchfoot]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>upset update facebook texting might result sch...</td>\n",
              "      <td>[upset, update, facebook, texting, might, resu...</td>\n",
              "      <td>[upset, update, facebook, texting, might, resu...</td>\n",
              "      <td>[upset, updat, facebook, text, might, result, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>kenichan dived many times ball managed save re...</td>\n",
              "      <td>[kenichan, dived, many, times, ball, managed, ...</td>\n",
              "      <td>[kenichan, dived, many, time, ball, managed, s...</td>\n",
              "      <td>[kenichan, dive, mani, time, ball, manag, save...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>whole body feels itchy like fire</td>\n",
              "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
              "      <td>[whole, body, feel, itchy, like, fire]</td>\n",
              "      <td>[whole, bodi, feel, itchi, like, fire]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>nationwideclass behaving</td>\n",
              "      <td>[nationwideclass, behaving]</td>\n",
              "      <td>[nationwideclass, behaving]</td>\n",
              "      <td>[nationwideclass, behav]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target  ...                                       Stemmed_text\n",
              "0       0  ...                                       [switchfoot]\n",
              "1       0  ...  [upset, updat, facebook, text, might, result, ...\n",
              "2       0  ...  [kenichan, dive, mani, time, ball, manag, save...\n",
              "3       0  ...             [whole, bodi, feel, itchi, like, fire]\n",
              "4       0  ...                           [nationwideclass, behav]\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLVLXzcB9VHW"
      },
      "source": [
        "Stemmed text loses a few characters on each token.  A model cannot be  trained on such text. We'll therefore stick to the  tokens in their original form. They are good enough."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dugToZ-QgPFR"
      },
      "source": [
        "## Statistical Language Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fdo17T8VghjV"
      },
      "source": [
        "### Bag of Words (BoW) and Count Vectorizer\n",
        "\n",
        "The **CountVectorizer** provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4azPAo-9Z-hP"
      },
      "source": [
        "text =list(dataset[\"text\"][:100]) #Select just the top 100 tweets to count vectors. 1.6M tweets are such a huge number so not possible."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADT7w4Ne-Mo5"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize a CountVectorizer object: count_vectorizer\n",
        "count_vec_tweets = CountVectorizer(stop_words=\"english\", analyzer='word', ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None)\n",
        "\n",
        "# Transforms the data into a bag of words\n",
        "count_train = count_vec_tweets.fit(text)\n",
        "bag_of_words = count_vec_tweets.transform(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yszBH-LSaoJ3",
        "outputId": "21ce33f3-33e2-415f-9210-dda241a2a26d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(\"Vocabulary:\\n {}\".format(count_train.vocabulary_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary:\n",
            " {'switchfoot': 352, 'upset': 397, 'update': 396, 'facebook': 120, 'texting': 363, 'result': 295, 'school': 307, 'today': 374, 'blah': 44, 'kenichan': 198, 'dived': 102, 'times': 373, 'ball': 34, 'managed': 229, 'save': 303, 'rest': 294, 'bounds': 49, 'body': 47, 'feels': 131, 'itchy': 188, 'like': 209, 'nationwideclass': 246, 'behaving': 39, 'kwesidei': 201, 'crew': 89, 'need': 247, 'loltrish': 216, 'long': 217, 'time': 371, 'rains': 287, 'fine': 135, 'thanks': 365, 'tatiana': 356, 'nope': 254, 'twittera': 386, 'muera': 244, 'spring': 338, 'break': 51, 'plain': 270, 'city': 72, 'snowing': 328, 'pierced': 269, 'ears': 110, 'caregiving': 62, 'bear': 38, 'watch': 410, 'thought': 368, 'loss': 221, 'embarrassing': 112, 'octolinz': 256, 'counts': 86, 'talk': 355, 'anymore': 16, 'smarrison': 325, 'really': 290, 'snyder': 329, 'doucheclown': 105, 'iamjazzyfizzle': 185, 'wish': 417, 'miss': 236, 'iamlilnicki': 186, 'premiere': 278, 'hollis': 176, 'death': 95, 'scene': 306, 'hurt': 182, 'severely': 311, 'film': 133, 'directors': 100, 'file': 132, 'taxes': 357, 'lettya': 207, 'wanted': 409, 'rent': 292, 'love': 223, 'soundtrack': 334, 'fakerpattypattz': 122, 'dear': 94, 'drinking': 106, 'forgotten': 140, 'table': 353, 'drinks': 107, 'alydesigns': 10, 'friend': 141, 'called': 59, 'asked': 21, 'meet': 234, 'valley': 401, 'sigh': 319, 'angry': 14, 'barista': 36, 'baked': 33, 'cake': 58, 'ated': 25, 'week': 416, 'going': 152, 'hoped': 178, 'blagh': 43, 'class': 74, 'tomorrow': 375, 'hate': 166, 'wake': 405, 'people': 264, 'sleep': 323, 'watching': 411, 'marley': 231, 'lilly': 210, 'ooooh': 259, 'leslie': 206, 'lover': 224, 'exception': 117, 'track': 380, 'gets': 145, 'depressed': 97, 'hacked': 160, 'account': 1, 'make': 226, 'alielayus': 8, 'want': 408, 'promote': 282, 'gear': 144, 'groove': 158, 'unfornately': 393, 'ride': 297, 'anaheim': 11, 'sleeping': 324, 'option': 260, 'realizing': 289, 'evaluations': 114, 'morning': 241, 'work': 420, 'afternoon': 5, 'julieebaby': 196, 'humpninja': 181, 'asian': 20, 'eyes': 119, 'night': 250, 'sick': 318, 'spent': 336, 'hour': 179, 'sitting': 322, 'shower': 315, 'cause': 63, 'stand': 339, 'held': 172, 'puke': 283, 'champ': 66, 'cocomix': 76, 'tell': 360, 'story': 346, 'later': 202, 'good': 154, 'workin': 421, 'hours': 180, 'missxu': 239, 'sorry': 333, 'came': 60, 'fleurylis': 136, 'depressing': 98, 'think': 367, 'know': 200, 'kids': 199, 'suitcases': 350, 'gonna': 153, 'girlfriend': 149, 'feel': 129, 'getting': 146, 'study': 349, 'tomorrows': 376, 'practical': 276, 'exam': 116, 'reason': 291, 'teardrops': 359, 'guitar': 159, 'heart': 171, 'feeling': 130, 'wanna': 407, 'jonathanrknight': 195, 'awww': 30, 'finally': 134, 'comfortable': 79, 'missed': 237, 'falling': 123, 'asleep': 22, 'heard': 170, 'tracy': 381, 'girl': 148, 'breaks': 53, 'family': 124, 'viennah': 402, 'happy': 164, 'means': 233, 'checked': 68, 'user': 399, 'timeline': 372, 'blackberry': 42, 'looks': 219, 'twanking': 384, 'happening': 162, 'probs': 280, 'uids': 388, 'ironing': 187, 'jeancjumbe': 192, 'fave': 126, 'wear': 413, 'meeting': 235, 'burnt': 56, 'strangely': 347, 'lilo': 211, 'samro': 301, 'breaking': 52, 'retweeting': 296, 'broadband': 54, 'plan': 271, 'massive': 232, 'broken': 55, 'promise': 281, 'localtweeps': 214, 'tons': 378, 'replies': 293, 'unfollow': 392, 'friends': 142, 'tweets': 385, 'scrolling': 308, 'feed': 128, 'duck': 108, 'chicken': 69, 'taking': 354, 'wayyy': 412, 'hatch': 165, 'vacation': 400, 'photos': 266, 'online': 258, 'crashed': 88, 'forget': 139, 'site': 321, 'andywana': 13, 'sure': 351, 'dont': 104, 'trade': 382, 'away': 28, 'company': 82, 'assets': 23, 'andy': 12, 'oanhlove': 255, 'happens': 163, 'dallas': 91, 'gotta': 155, 'shows': 316, 'music': 245, 'game': 143, 'degrees': 96, 'hmmm': 175, 'random': 288, 'glad': 151, 'hear': 169, 'batmanyng': 37, 'commission': 81, 'wutcha': 424, 'playing': 272, 'copped': 85, 'blood': 46, 'sand': 302, 'leaving': 205, 'parking': 262, 'life': 208, 'cool': 84, 'sadly': 300, 'gotten': 156, 'experience': 118, 'post': 275, 'coitus': 77, 'cigarette': 70, 'nice': 249, 'rain': 286, 'comes': 78, 'starrbby': 341, 'lost': 222, 'phone': 265, 'lmao': 213, 'shucks': 317, 'damm': 92, 'jobs': 194, 'money': 240, 'hell': 173, 'wage': 404, 'clams': 73, 'katortiz': 197, 'forever': 138, 'soon': 331, 'algonquin': 7, 'agreed': 6, 'failwhale': 121, 'allllll': 9, 'jdarter': 191, 'haha': 161, 'dude': 109, 'look': 218, 'unless': 395, 'says': 305, 'added': 3, 'terrible': 362, 'ninjen': 252, 'right': 298, 'start': 342, 'working': 422, 'nikster': 251, 'jared': 190, 'diss': 101, 'bands': 35, 'trace': 379, 'clearly': 75, 'ugly': 387, 'attire': 27, 'puma': 284, 'singlet': 320, 'adidas': 4, 'shorts': 314, 'black': 41, 'business': 57, 'socks': 330, 'leather': 204, 'shoes': 313, 'lucky': 225, 'cute': 90, 'girls': 150, 'location': 215, 'picnic': 268, 'smells': 326, 'citrus': 71, 'ashleyac': 19, 'donkey': 103, 'sensitive': 310, 'comments': 80, 'asap': 18, 'charger': 67, 'awol': 29, 'tonight': 377, 'arms': 17, 'sore': 332, 'tennis': 361, 'wonders': 419, 'unhappy': 394, 'split': 337, 'seccond': 309, 'saying': 304, 'statravelau': 343, 'newsletter': 248, 'fares': 125, 'unbelievable': 390, 'shame': 312, 'booked': 48, 'paid': 261, 'missin': 238, 'markhardy': 230, 'damn': 93, 'chalk': 64, 'chalkboard': 65, 'useless': 398, 'blast': 45, 'getty': 147, 'villa': 403, 'hates': 167, 'throat': 370, 'worse': 423, 'msdrama': 242, 'mama': 228, 'tummy': 383, 'hurts': 183, 'wonder': 418, 'hypnosis': 184, 'stop': 345, 'smoking': 327, 'ones': 257, 'januarycrimson': 189, 'babe': 31, 'annoys': 15, 'thankfully': 364, 'muahaha': 243, 'evil': 115, 'laugh': 203, 'hollywoodheat': 177, 'attention': 26, 'covered': 87, 'photoshop': 267, 'webpage': 414, 'design': 99, 'undergrad': 391, 'wednesday': 415, 'poor': 274, 'cameron': 61, 'hills': 174, 'pray': 277, 'threatening': 369, 'babies': 32, 'birthday': 40, 'party': 263, 'jerk': 193, 'headache': 168, 'makeherfamous': 227, 'enjoy': 113, 'problems': 279, 'constants': 83, 'things': 366, 'ulike': 389, 'strider': 348, 'little': 212, 'puppy': 285, 'rylee': 299, 'grace': 157, 'wana': 406, 'steve': 344, 'easter': 111, 'able': 0, 'actually': 2, 'bracket': 50, 'pools': 273, 'stark': 340, 'follow': 137, 'nite': 253, 'favorite': 127, 'teams': 358, 'astros': 24, 'spartans': 335, 'lose': 220}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOkP6nAfTe8H"
      },
      "source": [
        "Vocabulary count for each word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odpJiN1sgjhk"
      },
      "source": [
        "### Term Frequency Inverse Document Frequency (TF-IDF) Vector\n",
        "\n",
        "![Term Frequency-Inverse Document Frequency ](https://miro.medium.com/max/1400/1*V9ac4hLVyms79jl65Ym_Bw.jpeg)\n",
        "Image  from https://bit.ly/3dmDDyS\n",
        "\n",
        "TF-IDF is a metric that factors the importance of a word relative to the  corpus. For example, words that are frequent in a document by Bag of Words, but the same frequency is not replicated across the documents in the collection tend to have a higher TF-IDF score. This means they are important  in the collection. On the contrary, words that appear frequently across the  collection like stopwords are less important thus have a lower TF-IDF score. A TF-IDF value can be  used as a feature representation in model building."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkWrMct-ZzoK",
        "outputId": "99cb7d7f-8e38-42cd-a3ca-70f3a61afbd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Term Frequency (TF)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tf = TfidfVectorizer(smooth_idf=False, sublinear_tf=False, norm=None, analyzer='word')\n",
        "fitted_text = tf.fit(text)\n",
        "transformed_text = fitted_text.transform(text)\n",
        "print (\"Listed Text: \", text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Listed Text:  ['switchfoot', 'upset update facebook texting might result school today also blah', 'kenichan dived many times ball managed save rest bounds', 'whole body feels itchy like fire', 'nationwideclass behaving', 'kwesidei whole crew', 'need', 'loltrish long time rains fine thanks', 'tatiana nope', 'twittera muera', 'spring break plain city snowing', 'pierced ears', 'caregiving bear watch thought loss embarrassing', 'octolinz counts either never talk anymore', 'smarrison would first really though snyder doucheclown', 'iamjazzyfizzle wish watch miss iamlilnicki premiere', 'hollis death scene hurt severely watch film directors', 'file taxes', 'lettya always wanted rent love soundtrack', 'fakerpattypattz dear drinking forgotten table drinks', 'alydesigns much done', 'friend called asked meet valley today time sigh', 'angry barista baked cake ated', 'week going hoped', 'blagh class tomorrow', 'hate call wake people', 'going sleep watching marley', 'miss lilly', 'ooooh leslie leslie', 'almost lover exception track gets depressed every time', 'hacked account make', 'alielayus want promote gear groove unfornately ride going anaheim though', 'thought sleeping option tomorrow realizing evaluations morning work afternoon', 'julieebaby love miss', 'humpninja asian eyes sleep night', 'sick spent hour sitting shower cause sick stand held back puke like champ', 'cocomix tell story later good workin like three hours', 'missxu sorry time came', 'fleurylis either depressing think even want know kids suitcases', 'class work class another gonna miss girlfriend', 'really feel like getting today study tomorrows practical exam', 'reason teardrops guitar enough break heart', 'know hate feeling wanna sleep still', 'jonathanrknight awww wish finally comfortable missed', 'falling asleep heard tracy girl body found heart breaks family', 'viennah happy also means less time', 'checked user timeline blackberry looks like twanking still happening still probs uids', 'ironing jeancjumbe fave wear meeting burnt', 'strangely lilo samro breaking', 'sorry think retweeting', 'broadband plan massive broken promise', 'localtweeps tons replies unfollow friends tweets scrolling feed', 'duck chicken taking wayyy long hatch', 'vacation photos online crashed forget name site', 'need', 'andywana sure much want dont think trade away company assets sorry andy', 'oanhlove hate happens', 'feeling dallas going show gotta though think shows would music game', 'degrees tomorrow', 'move thought already hmmm random found glad hear well', 'batmanyng miss commission wutcha playing copped blood sand', 'leaving parking work', 'life cool', 'sadly though never gotten experience post coitus cigarette never', 'nice rain comes tomorrow', 'starrbby around lost even phone bill lmao shucks', 'damm back school tomorrow', 'jobs money hell wage clams hour', 'katortiz forever soon', 'algonquin agreed failwhale allllll today', 'jdarter haha dude dont really look unless someone says added sorry terrible need', 'ninjen sure right need start working nikster jared least', 'really hate people diss bands trace clearly ugly', 'attire today puma singlet adidas shorts black business socks leather shoes lucky cute girls', 'show location', 'picnic phone smells like citrus', 'ashleyac donkey sensitive comments nevertheless glad asap charger still awol', 'tonight', 'think arms sore tennis', 'wonders someone like much make unhappy split seccond depressed', 'sleep soon hate saying tomorrow night', 'statravelau newsletter fares really unbelievable shame already booked paid mine', 'missin', 'markhardy', 'damn chalk chalkboard useless', 'blast getty villa hates sore throat getting worse', 'msdrama missed meeting mama', 'tummy hurts wonder hypnosis anything working stop smoking', 'always ones', 'januarycrimson sorry babe annoys thankfully asleep right muahaha evil laugh', 'hollywoodheat paid attention covered photoshop webpage design class undergrad', 'wednesday know', 'poor cameron hills', 'pray please threatening start babies birthday party jerk still headache', 'makeherfamous really enjoy problems constants think things find someone ulike', 'strider sick little puppy', 'rylee grace wana steve party sadly since easter able much well', 'actually bracket pools money', 'stark follow either work', 'nite favorite teams astros spartans lose nite good']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdUhnfztZdz_",
        "outputId": "016f420d-0e57-433c-9afa-7bfce2c2c955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tf.vocabulary_ #Learned  corpus vocabulary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'able': 0,\n",
              " 'account': 1,\n",
              " 'actually': 2,\n",
              " 'added': 3,\n",
              " 'adidas': 4,\n",
              " 'afternoon': 5,\n",
              " 'agreed': 6,\n",
              " 'algonquin': 7,\n",
              " 'alielayus': 8,\n",
              " 'allllll': 9,\n",
              " 'almost': 10,\n",
              " 'already': 11,\n",
              " 'also': 12,\n",
              " 'always': 13,\n",
              " 'alydesigns': 14,\n",
              " 'anaheim': 15,\n",
              " 'andy': 16,\n",
              " 'andywana': 17,\n",
              " 'angry': 18,\n",
              " 'annoys': 19,\n",
              " 'another': 20,\n",
              " 'anymore': 21,\n",
              " 'anything': 22,\n",
              " 'arms': 23,\n",
              " 'around': 24,\n",
              " 'asap': 25,\n",
              " 'ashleyac': 26,\n",
              " 'asian': 27,\n",
              " 'asked': 28,\n",
              " 'asleep': 29,\n",
              " 'assets': 30,\n",
              " 'astros': 31,\n",
              " 'ated': 32,\n",
              " 'attention': 33,\n",
              " 'attire': 34,\n",
              " 'away': 35,\n",
              " 'awol': 36,\n",
              " 'awww': 37,\n",
              " 'babe': 38,\n",
              " 'babies': 39,\n",
              " 'back': 40,\n",
              " 'baked': 41,\n",
              " 'ball': 42,\n",
              " 'bands': 43,\n",
              " 'barista': 44,\n",
              " 'batmanyng': 45,\n",
              " 'bear': 46,\n",
              " 'behaving': 47,\n",
              " 'bill': 48,\n",
              " 'birthday': 49,\n",
              " 'black': 50,\n",
              " 'blackberry': 51,\n",
              " 'blagh': 52,\n",
              " 'blah': 53,\n",
              " 'blast': 54,\n",
              " 'blood': 55,\n",
              " 'body': 56,\n",
              " 'booked': 57,\n",
              " 'bounds': 58,\n",
              " 'bracket': 59,\n",
              " 'break': 60,\n",
              " 'breaking': 61,\n",
              " 'breaks': 62,\n",
              " 'broadband': 63,\n",
              " 'broken': 64,\n",
              " 'burnt': 65,\n",
              " 'business': 66,\n",
              " 'cake': 67,\n",
              " 'call': 68,\n",
              " 'called': 69,\n",
              " 'came': 70,\n",
              " 'cameron': 71,\n",
              " 'caregiving': 72,\n",
              " 'cause': 73,\n",
              " 'chalk': 74,\n",
              " 'chalkboard': 75,\n",
              " 'champ': 76,\n",
              " 'charger': 77,\n",
              " 'checked': 78,\n",
              " 'chicken': 79,\n",
              " 'cigarette': 80,\n",
              " 'citrus': 81,\n",
              " 'city': 82,\n",
              " 'clams': 83,\n",
              " 'class': 84,\n",
              " 'clearly': 85,\n",
              " 'cocomix': 86,\n",
              " 'coitus': 87,\n",
              " 'comes': 88,\n",
              " 'comfortable': 89,\n",
              " 'comments': 90,\n",
              " 'commission': 91,\n",
              " 'company': 92,\n",
              " 'constants': 93,\n",
              " 'cool': 94,\n",
              " 'copped': 95,\n",
              " 'counts': 96,\n",
              " 'covered': 97,\n",
              " 'crashed': 98,\n",
              " 'crew': 99,\n",
              " 'cute': 100,\n",
              " 'dallas': 101,\n",
              " 'damm': 102,\n",
              " 'damn': 103,\n",
              " 'dear': 104,\n",
              " 'death': 105,\n",
              " 'degrees': 106,\n",
              " 'depressed': 107,\n",
              " 'depressing': 108,\n",
              " 'design': 109,\n",
              " 'directors': 110,\n",
              " 'diss': 111,\n",
              " 'dived': 112,\n",
              " 'done': 113,\n",
              " 'donkey': 114,\n",
              " 'dont': 115,\n",
              " 'doucheclown': 116,\n",
              " 'drinking': 117,\n",
              " 'drinks': 118,\n",
              " 'duck': 119,\n",
              " 'dude': 120,\n",
              " 'ears': 121,\n",
              " 'easter': 122,\n",
              " 'either': 123,\n",
              " 'embarrassing': 124,\n",
              " 'enjoy': 125,\n",
              " 'enough': 126,\n",
              " 'evaluations': 127,\n",
              " 'even': 128,\n",
              " 'every': 129,\n",
              " 'evil': 130,\n",
              " 'exam': 131,\n",
              " 'exception': 132,\n",
              " 'experience': 133,\n",
              " 'eyes': 134,\n",
              " 'facebook': 135,\n",
              " 'failwhale': 136,\n",
              " 'fakerpattypattz': 137,\n",
              " 'falling': 138,\n",
              " 'family': 139,\n",
              " 'fares': 140,\n",
              " 'fave': 141,\n",
              " 'favorite': 142,\n",
              " 'feed': 143,\n",
              " 'feel': 144,\n",
              " 'feeling': 145,\n",
              " 'feels': 146,\n",
              " 'file': 147,\n",
              " 'film': 148,\n",
              " 'finally': 149,\n",
              " 'find': 150,\n",
              " 'fine': 151,\n",
              " 'fire': 152,\n",
              " 'first': 153,\n",
              " 'fleurylis': 154,\n",
              " 'follow': 155,\n",
              " 'forever': 156,\n",
              " 'forget': 157,\n",
              " 'forgotten': 158,\n",
              " 'found': 159,\n",
              " 'friend': 160,\n",
              " 'friends': 161,\n",
              " 'game': 162,\n",
              " 'gear': 163,\n",
              " 'gets': 164,\n",
              " 'getting': 165,\n",
              " 'getty': 166,\n",
              " 'girl': 167,\n",
              " 'girlfriend': 168,\n",
              " 'girls': 169,\n",
              " 'glad': 170,\n",
              " 'going': 171,\n",
              " 'gonna': 172,\n",
              " 'good': 173,\n",
              " 'gotta': 174,\n",
              " 'gotten': 175,\n",
              " 'grace': 176,\n",
              " 'groove': 177,\n",
              " 'guitar': 178,\n",
              " 'hacked': 179,\n",
              " 'haha': 180,\n",
              " 'happening': 181,\n",
              " 'happens': 182,\n",
              " 'happy': 183,\n",
              " 'hatch': 184,\n",
              " 'hate': 185,\n",
              " 'hates': 186,\n",
              " 'headache': 187,\n",
              " 'hear': 188,\n",
              " 'heard': 189,\n",
              " 'heart': 190,\n",
              " 'held': 191,\n",
              " 'hell': 192,\n",
              " 'hills': 193,\n",
              " 'hmmm': 194,\n",
              " 'hollis': 195,\n",
              " 'hollywoodheat': 196,\n",
              " 'hoped': 197,\n",
              " 'hour': 198,\n",
              " 'hours': 199,\n",
              " 'humpninja': 200,\n",
              " 'hurt': 201,\n",
              " 'hurts': 202,\n",
              " 'hypnosis': 203,\n",
              " 'iamjazzyfizzle': 204,\n",
              " 'iamlilnicki': 205,\n",
              " 'ironing': 206,\n",
              " 'itchy': 207,\n",
              " 'januarycrimson': 208,\n",
              " 'jared': 209,\n",
              " 'jdarter': 210,\n",
              " 'jeancjumbe': 211,\n",
              " 'jerk': 212,\n",
              " 'jobs': 213,\n",
              " 'jonathanrknight': 214,\n",
              " 'julieebaby': 215,\n",
              " 'katortiz': 216,\n",
              " 'kenichan': 217,\n",
              " 'kids': 218,\n",
              " 'know': 219,\n",
              " 'kwesidei': 220,\n",
              " 'later': 221,\n",
              " 'laugh': 222,\n",
              " 'least': 223,\n",
              " 'leather': 224,\n",
              " 'leaving': 225,\n",
              " 'leslie': 226,\n",
              " 'less': 227,\n",
              " 'lettya': 228,\n",
              " 'life': 229,\n",
              " 'like': 230,\n",
              " 'lilly': 231,\n",
              " 'lilo': 232,\n",
              " 'little': 233,\n",
              " 'lmao': 234,\n",
              " 'localtweeps': 235,\n",
              " 'location': 236,\n",
              " 'loltrish': 237,\n",
              " 'long': 238,\n",
              " 'look': 239,\n",
              " 'looks': 240,\n",
              " 'lose': 241,\n",
              " 'loss': 242,\n",
              " 'lost': 243,\n",
              " 'love': 244,\n",
              " 'lover': 245,\n",
              " 'lucky': 246,\n",
              " 'make': 247,\n",
              " 'makeherfamous': 248,\n",
              " 'mama': 249,\n",
              " 'managed': 250,\n",
              " 'many': 251,\n",
              " 'markhardy': 252,\n",
              " 'marley': 253,\n",
              " 'massive': 254,\n",
              " 'means': 255,\n",
              " 'meet': 256,\n",
              " 'meeting': 257,\n",
              " 'might': 258,\n",
              " 'mine': 259,\n",
              " 'miss': 260,\n",
              " 'missed': 261,\n",
              " 'missin': 262,\n",
              " 'missxu': 263,\n",
              " 'money': 264,\n",
              " 'morning': 265,\n",
              " 'move': 266,\n",
              " 'msdrama': 267,\n",
              " 'muahaha': 268,\n",
              " 'much': 269,\n",
              " 'muera': 270,\n",
              " 'music': 271,\n",
              " 'name': 272,\n",
              " 'nationwideclass': 273,\n",
              " 'need': 274,\n",
              " 'never': 275,\n",
              " 'nevertheless': 276,\n",
              " 'newsletter': 277,\n",
              " 'nice': 278,\n",
              " 'night': 279,\n",
              " 'nikster': 280,\n",
              " 'ninjen': 281,\n",
              " 'nite': 282,\n",
              " 'nope': 283,\n",
              " 'oanhlove': 284,\n",
              " 'octolinz': 285,\n",
              " 'ones': 286,\n",
              " 'online': 287,\n",
              " 'ooooh': 288,\n",
              " 'option': 289,\n",
              " 'paid': 290,\n",
              " 'parking': 291,\n",
              " 'party': 292,\n",
              " 'people': 293,\n",
              " 'phone': 294,\n",
              " 'photos': 295,\n",
              " 'photoshop': 296,\n",
              " 'picnic': 297,\n",
              " 'pierced': 298,\n",
              " 'plain': 299,\n",
              " 'plan': 300,\n",
              " 'playing': 301,\n",
              " 'please': 302,\n",
              " 'pools': 303,\n",
              " 'poor': 304,\n",
              " 'post': 305,\n",
              " 'practical': 306,\n",
              " 'pray': 307,\n",
              " 'premiere': 308,\n",
              " 'problems': 309,\n",
              " 'probs': 310,\n",
              " 'promise': 311,\n",
              " 'promote': 312,\n",
              " 'puke': 313,\n",
              " 'puma': 314,\n",
              " 'puppy': 315,\n",
              " 'rain': 316,\n",
              " 'rains': 317,\n",
              " 'random': 318,\n",
              " 'realizing': 319,\n",
              " 'really': 320,\n",
              " 'reason': 321,\n",
              " 'rent': 322,\n",
              " 'replies': 323,\n",
              " 'rest': 324,\n",
              " 'result': 325,\n",
              " 'retweeting': 326,\n",
              " 'ride': 327,\n",
              " 'right': 328,\n",
              " 'rylee': 329,\n",
              " 'sadly': 330,\n",
              " 'samro': 331,\n",
              " 'sand': 332,\n",
              " 'save': 333,\n",
              " 'saying': 334,\n",
              " 'says': 335,\n",
              " 'scene': 336,\n",
              " 'school': 337,\n",
              " 'scrolling': 338,\n",
              " 'seccond': 339,\n",
              " 'sensitive': 340,\n",
              " 'severely': 341,\n",
              " 'shame': 342,\n",
              " 'shoes': 343,\n",
              " 'shorts': 344,\n",
              " 'show': 345,\n",
              " 'shower': 346,\n",
              " 'shows': 347,\n",
              " 'shucks': 348,\n",
              " 'sick': 349,\n",
              " 'sigh': 350,\n",
              " 'since': 351,\n",
              " 'singlet': 352,\n",
              " 'site': 353,\n",
              " 'sitting': 354,\n",
              " 'sleep': 355,\n",
              " 'sleeping': 356,\n",
              " 'smarrison': 357,\n",
              " 'smells': 358,\n",
              " 'smoking': 359,\n",
              " 'snowing': 360,\n",
              " 'snyder': 361,\n",
              " 'socks': 362,\n",
              " 'someone': 363,\n",
              " 'soon': 364,\n",
              " 'sore': 365,\n",
              " 'sorry': 366,\n",
              " 'soundtrack': 367,\n",
              " 'spartans': 368,\n",
              " 'spent': 369,\n",
              " 'split': 370,\n",
              " 'spring': 371,\n",
              " 'stand': 372,\n",
              " 'stark': 373,\n",
              " 'starrbby': 374,\n",
              " 'start': 375,\n",
              " 'statravelau': 376,\n",
              " 'steve': 377,\n",
              " 'still': 378,\n",
              " 'stop': 379,\n",
              " 'story': 380,\n",
              " 'strangely': 381,\n",
              " 'strider': 382,\n",
              " 'study': 383,\n",
              " 'suitcases': 384,\n",
              " 'sure': 385,\n",
              " 'switchfoot': 386,\n",
              " 'table': 387,\n",
              " 'taking': 388,\n",
              " 'talk': 389,\n",
              " 'tatiana': 390,\n",
              " 'taxes': 391,\n",
              " 'teams': 392,\n",
              " 'teardrops': 393,\n",
              " 'tell': 394,\n",
              " 'tennis': 395,\n",
              " 'terrible': 396,\n",
              " 'texting': 397,\n",
              " 'thankfully': 398,\n",
              " 'thanks': 399,\n",
              " 'things': 400,\n",
              " 'think': 401,\n",
              " 'though': 402,\n",
              " 'thought': 403,\n",
              " 'threatening': 404,\n",
              " 'three': 405,\n",
              " 'throat': 406,\n",
              " 'time': 407,\n",
              " 'timeline': 408,\n",
              " 'times': 409,\n",
              " 'today': 410,\n",
              " 'tomorrow': 411,\n",
              " 'tomorrows': 412,\n",
              " 'tonight': 413,\n",
              " 'tons': 414,\n",
              " 'trace': 415,\n",
              " 'track': 416,\n",
              " 'tracy': 417,\n",
              " 'trade': 418,\n",
              " 'tummy': 419,\n",
              " 'twanking': 420,\n",
              " 'tweets': 421,\n",
              " 'twittera': 422,\n",
              " 'ugly': 423,\n",
              " 'uids': 424,\n",
              " 'ulike': 425,\n",
              " 'unbelievable': 426,\n",
              " 'undergrad': 427,\n",
              " 'unfollow': 428,\n",
              " 'unfornately': 429,\n",
              " 'unhappy': 430,\n",
              " 'unless': 431,\n",
              " 'update': 432,\n",
              " 'upset': 433,\n",
              " 'useless': 434,\n",
              " 'user': 435,\n",
              " 'vacation': 436,\n",
              " 'valley': 437,\n",
              " 'viennah': 438,\n",
              " 'villa': 439,\n",
              " 'wage': 440,\n",
              " 'wake': 441,\n",
              " 'wana': 442,\n",
              " 'wanna': 443,\n",
              " 'want': 444,\n",
              " 'wanted': 445,\n",
              " 'watch': 446,\n",
              " 'watching': 447,\n",
              " 'wayyy': 448,\n",
              " 'wear': 449,\n",
              " 'webpage': 450,\n",
              " 'wednesday': 451,\n",
              " 'week': 452,\n",
              " 'well': 453,\n",
              " 'whole': 454,\n",
              " 'wish': 455,\n",
              " 'wonder': 456,\n",
              " 'wonders': 457,\n",
              " 'work': 458,\n",
              " 'workin': 459,\n",
              " 'working': 460,\n",
              " 'worse': 461,\n",
              " 'would': 462,\n",
              " 'wutcha': 463}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z6v6AgLaAr2",
        "outputId": "b99c1f32-cfdd-48d0-889a-85d58ecb89a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Lets get the  Inverse Document Frequency (IDF) part\n",
        "idf = tf.idf_\n",
        "print(dict(zip(fitted_text.get_feature_names(), idf)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'able': 5.605170185988092, 'account': 5.605170185988092, 'actually': 5.605170185988092, 'added': 5.605170185988092, 'adidas': 5.605170185988092, 'afternoon': 5.605170185988092, 'agreed': 5.605170185988092, 'algonquin': 5.605170185988092, 'alielayus': 5.605170185988092, 'allllll': 5.605170185988092, 'almost': 5.605170185988092, 'already': 4.912023005428146, 'also': 4.912023005428146, 'always': 4.912023005428146, 'alydesigns': 5.605170185988092, 'anaheim': 5.605170185988092, 'andy': 5.605170185988092, 'andywana': 5.605170185988092, 'angry': 5.605170185988092, 'annoys': 5.605170185988092, 'another': 5.605170185988092, 'anymore': 5.605170185988092, 'anything': 5.605170185988092, 'arms': 5.605170185988092, 'around': 5.605170185988092, 'asap': 5.605170185988092, 'ashleyac': 5.605170185988092, 'asian': 5.605170185988092, 'asked': 5.605170185988092, 'asleep': 4.912023005428146, 'assets': 5.605170185988092, 'astros': 5.605170185988092, 'ated': 5.605170185988092, 'attention': 5.605170185988092, 'attire': 5.605170185988092, 'away': 5.605170185988092, 'awol': 5.605170185988092, 'awww': 5.605170185988092, 'babe': 5.605170185988092, 'babies': 5.605170185988092, 'back': 4.912023005428146, 'baked': 5.605170185988092, 'ball': 5.605170185988092, 'bands': 5.605170185988092, 'barista': 5.605170185988092, 'batmanyng': 5.605170185988092, 'bear': 5.605170185988092, 'behaving': 5.605170185988092, 'bill': 5.605170185988092, 'birthday': 5.605170185988092, 'black': 5.605170185988092, 'blackberry': 5.605170185988092, 'blagh': 5.605170185988092, 'blah': 5.605170185988092, 'blast': 5.605170185988092, 'blood': 5.605170185988092, 'body': 4.912023005428146, 'booked': 5.605170185988092, 'bounds': 5.605170185988092, 'bracket': 5.605170185988092, 'break': 4.912023005428146, 'breaking': 5.605170185988092, 'breaks': 5.605170185988092, 'broadband': 5.605170185988092, 'broken': 5.605170185988092, 'burnt': 5.605170185988092, 'business': 5.605170185988092, 'cake': 5.605170185988092, 'call': 5.605170185988092, 'called': 5.605170185988092, 'came': 5.605170185988092, 'cameron': 5.605170185988092, 'caregiving': 5.605170185988092, 'cause': 5.605170185988092, 'chalk': 5.605170185988092, 'chalkboard': 5.605170185988092, 'champ': 5.605170185988092, 'charger': 5.605170185988092, 'checked': 5.605170185988092, 'chicken': 5.605170185988092, 'cigarette': 5.605170185988092, 'citrus': 5.605170185988092, 'city': 5.605170185988092, 'clams': 5.605170185988092, 'class': 4.506557897319982, 'clearly': 5.605170185988092, 'cocomix': 5.605170185988092, 'coitus': 5.605170185988092, 'comes': 5.605170185988092, 'comfortable': 5.605170185988092, 'comments': 5.605170185988092, 'commission': 5.605170185988092, 'company': 5.605170185988092, 'constants': 5.605170185988092, 'cool': 5.605170185988092, 'copped': 5.605170185988092, 'counts': 5.605170185988092, 'covered': 5.605170185988092, 'crashed': 5.605170185988092, 'crew': 5.605170185988092, 'cute': 5.605170185988092, 'dallas': 5.605170185988092, 'damm': 5.605170185988092, 'damn': 5.605170185988092, 'dear': 5.605170185988092, 'death': 5.605170185988092, 'degrees': 5.605170185988092, 'depressed': 4.912023005428146, 'depressing': 5.605170185988092, 'design': 5.605170185988092, 'directors': 5.605170185988092, 'diss': 5.605170185988092, 'dived': 5.605170185988092, 'done': 5.605170185988092, 'donkey': 5.605170185988092, 'dont': 4.912023005428146, 'doucheclown': 5.605170185988092, 'drinking': 5.605170185988092, 'drinks': 5.605170185988092, 'duck': 5.605170185988092, 'dude': 5.605170185988092, 'ears': 5.605170185988092, 'easter': 5.605170185988092, 'either': 4.506557897319982, 'embarrassing': 5.605170185988092, 'enjoy': 5.605170185988092, 'enough': 5.605170185988092, 'evaluations': 5.605170185988092, 'even': 4.912023005428146, 'every': 5.605170185988092, 'evil': 5.605170185988092, 'exam': 5.605170185988092, 'exception': 5.605170185988092, 'experience': 5.605170185988092, 'eyes': 5.605170185988092, 'facebook': 5.605170185988092, 'failwhale': 5.605170185988092, 'fakerpattypattz': 5.605170185988092, 'falling': 5.605170185988092, 'family': 5.605170185988092, 'fares': 5.605170185988092, 'fave': 5.605170185988092, 'favorite': 5.605170185988092, 'feed': 5.605170185988092, 'feel': 5.605170185988092, 'feeling': 4.912023005428146, 'feels': 5.605170185988092, 'file': 5.605170185988092, 'film': 5.605170185988092, 'finally': 5.605170185988092, 'find': 5.605170185988092, 'fine': 5.605170185988092, 'fire': 5.605170185988092, 'first': 5.605170185988092, 'fleurylis': 5.605170185988092, 'follow': 5.605170185988092, 'forever': 5.605170185988092, 'forget': 5.605170185988092, 'forgotten': 5.605170185988092, 'found': 4.912023005428146, 'friend': 5.605170185988092, 'friends': 5.605170185988092, 'game': 5.605170185988092, 'gear': 5.605170185988092, 'gets': 5.605170185988092, 'getting': 4.912023005428146, 'getty': 5.605170185988092, 'girl': 5.605170185988092, 'girlfriend': 5.605170185988092, 'girls': 5.605170185988092, 'glad': 4.912023005428146, 'going': 4.218875824868201, 'gonna': 5.605170185988092, 'good': 4.912023005428146, 'gotta': 5.605170185988092, 'gotten': 5.605170185988092, 'grace': 5.605170185988092, 'groove': 5.605170185988092, 'guitar': 5.605170185988092, 'hacked': 5.605170185988092, 'haha': 5.605170185988092, 'happening': 5.605170185988092, 'happens': 5.605170185988092, 'happy': 5.605170185988092, 'hatch': 5.605170185988092, 'hate': 3.995732273553991, 'hates': 5.605170185988092, 'headache': 5.605170185988092, 'hear': 5.605170185988092, 'heard': 5.605170185988092, 'heart': 4.912023005428146, 'held': 5.605170185988092, 'hell': 5.605170185988092, 'hills': 5.605170185988092, 'hmmm': 5.605170185988092, 'hollis': 5.605170185988092, 'hollywoodheat': 5.605170185988092, 'hoped': 5.605170185988092, 'hour': 4.912023005428146, 'hours': 5.605170185988092, 'humpninja': 5.605170185988092, 'hurt': 5.605170185988092, 'hurts': 5.605170185988092, 'hypnosis': 5.605170185988092, 'iamjazzyfizzle': 5.605170185988092, 'iamlilnicki': 5.605170185988092, 'ironing': 5.605170185988092, 'itchy': 5.605170185988092, 'januarycrimson': 5.605170185988092, 'jared': 5.605170185988092, 'jdarter': 5.605170185988092, 'jeancjumbe': 5.605170185988092, 'jerk': 5.605170185988092, 'jobs': 5.605170185988092, 'jonathanrknight': 5.605170185988092, 'julieebaby': 5.605170185988092, 'katortiz': 5.605170185988092, 'kenichan': 5.605170185988092, 'kids': 5.605170185988092, 'know': 4.506557897319982, 'kwesidei': 5.605170185988092, 'later': 5.605170185988092, 'laugh': 5.605170185988092, 'least': 5.605170185988092, 'leather': 5.605170185988092, 'leaving': 5.605170185988092, 'leslie': 5.605170185988092, 'less': 5.605170185988092, 'lettya': 5.605170185988092, 'life': 5.605170185988092, 'like': 3.659260036932778, 'lilly': 5.605170185988092, 'lilo': 5.605170185988092, 'little': 5.605170185988092, 'lmao': 5.605170185988092, 'localtweeps': 5.605170185988092, 'location': 5.605170185988092, 'loltrish': 5.605170185988092, 'long': 4.912023005428146, 'look': 5.605170185988092, 'looks': 5.605170185988092, 'lose': 5.605170185988092, 'loss': 5.605170185988092, 'lost': 5.605170185988092, 'love': 4.912023005428146, 'lover': 5.605170185988092, 'lucky': 5.605170185988092, 'make': 4.912023005428146, 'makeherfamous': 5.605170185988092, 'mama': 5.605170185988092, 'managed': 5.605170185988092, 'many': 5.605170185988092, 'markhardy': 5.605170185988092, 'marley': 5.605170185988092, 'massive': 5.605170185988092, 'means': 5.605170185988092, 'meet': 5.605170185988092, 'meeting': 4.912023005428146, 'might': 5.605170185988092, 'mine': 5.605170185988092, 'miss': 3.995732273553991, 'missed': 4.912023005428146, 'missin': 5.605170185988092, 'missxu': 5.605170185988092, 'money': 4.912023005428146, 'morning': 5.605170185988092, 'move': 5.605170185988092, 'msdrama': 5.605170185988092, 'muahaha': 5.605170185988092, 'much': 4.218875824868201, 'muera': 5.605170185988092, 'music': 5.605170185988092, 'name': 5.605170185988092, 'nationwideclass': 5.605170185988092, 'need': 4.218875824868201, 'never': 4.912023005428146, 'nevertheless': 5.605170185988092, 'newsletter': 5.605170185988092, 'nice': 5.605170185988092, 'night': 4.912023005428146, 'nikster': 5.605170185988092, 'ninjen': 5.605170185988092, 'nite': 5.605170185988092, 'nope': 5.605170185988092, 'oanhlove': 5.605170185988092, 'octolinz': 5.605170185988092, 'ones': 5.605170185988092, 'online': 5.605170185988092, 'ooooh': 5.605170185988092, 'option': 5.605170185988092, 'paid': 4.912023005428146, 'parking': 5.605170185988092, 'party': 4.912023005428146, 'people': 4.912023005428146, 'phone': 4.912023005428146, 'photos': 5.605170185988092, 'photoshop': 5.605170185988092, 'picnic': 5.605170185988092, 'pierced': 5.605170185988092, 'plain': 5.605170185988092, 'plan': 5.605170185988092, 'playing': 5.605170185988092, 'please': 5.605170185988092, 'pools': 5.605170185988092, 'poor': 5.605170185988092, 'post': 5.605170185988092, 'practical': 5.605170185988092, 'pray': 5.605170185988092, 'premiere': 5.605170185988092, 'problems': 5.605170185988092, 'probs': 5.605170185988092, 'promise': 5.605170185988092, 'promote': 5.605170185988092, 'puke': 5.605170185988092, 'puma': 5.605170185988092, 'puppy': 5.605170185988092, 'rain': 5.605170185988092, 'rains': 5.605170185988092, 'random': 5.605170185988092, 'realizing': 5.605170185988092, 'really': 3.8134107167600364, 'reason': 5.605170185988092, 'rent': 5.605170185988092, 'replies': 5.605170185988092, 'rest': 5.605170185988092, 'result': 5.605170185988092, 'retweeting': 5.605170185988092, 'ride': 5.605170185988092, 'right': 4.912023005428146, 'rylee': 5.605170185988092, 'sadly': 4.912023005428146, 'samro': 5.605170185988092, 'sand': 5.605170185988092, 'save': 5.605170185988092, 'saying': 5.605170185988092, 'says': 5.605170185988092, 'scene': 5.605170185988092, 'school': 4.912023005428146, 'scrolling': 5.605170185988092, 'seccond': 5.605170185988092, 'sensitive': 5.605170185988092, 'severely': 5.605170185988092, 'shame': 5.605170185988092, 'shoes': 5.605170185988092, 'shorts': 5.605170185988092, 'show': 4.912023005428146, 'shower': 5.605170185988092, 'shows': 5.605170185988092, 'shucks': 5.605170185988092, 'sick': 4.912023005428146, 'sigh': 5.605170185988092, 'since': 5.605170185988092, 'singlet': 5.605170185988092, 'site': 5.605170185988092, 'sitting': 5.605170185988092, 'sleep': 4.218875824868201, 'sleeping': 5.605170185988092, 'smarrison': 5.605170185988092, 'smells': 5.605170185988092, 'smoking': 5.605170185988092, 'snowing': 5.605170185988092, 'snyder': 5.605170185988092, 'socks': 5.605170185988092, 'someone': 4.506557897319982, 'soon': 4.912023005428146, 'sore': 4.912023005428146, 'sorry': 3.995732273553991, 'soundtrack': 5.605170185988092, 'spartans': 5.605170185988092, 'spent': 5.605170185988092, 'split': 5.605170185988092, 'spring': 5.605170185988092, 'stand': 5.605170185988092, 'stark': 5.605170185988092, 'starrbby': 5.605170185988092, 'start': 4.912023005428146, 'statravelau': 5.605170185988092, 'steve': 5.605170185988092, 'still': 4.218875824868201, 'stop': 5.605170185988092, 'story': 5.605170185988092, 'strangely': 5.605170185988092, 'strider': 5.605170185988092, 'study': 5.605170185988092, 'suitcases': 5.605170185988092, 'sure': 4.912023005428146, 'switchfoot': 5.605170185988092, 'table': 5.605170185988092, 'taking': 5.605170185988092, 'talk': 5.605170185988092, 'tatiana': 5.605170185988092, 'taxes': 5.605170185988092, 'teams': 5.605170185988092, 'teardrops': 5.605170185988092, 'tell': 5.605170185988092, 'tennis': 5.605170185988092, 'terrible': 5.605170185988092, 'texting': 5.605170185988092, 'thankfully': 5.605170185988092, 'thanks': 5.605170185988092, 'things': 5.605170185988092, 'think': 3.8134107167600364, 'though': 4.218875824868201, 'thought': 4.506557897319982, 'threatening': 5.605170185988092, 'three': 5.605170185988092, 'throat': 5.605170185988092, 'time': 3.995732273553991, 'timeline': 5.605170185988092, 'times': 5.605170185988092, 'today': 3.995732273553991, 'tomorrow': 3.8134107167600364, 'tomorrows': 5.605170185988092, 'tonight': 5.605170185988092, 'tons': 5.605170185988092, 'trace': 5.605170185988092, 'track': 5.605170185988092, 'tracy': 5.605170185988092, 'trade': 5.605170185988092, 'tummy': 5.605170185988092, 'twanking': 5.605170185988092, 'tweets': 5.605170185988092, 'twittera': 5.605170185988092, 'ugly': 5.605170185988092, 'uids': 5.605170185988092, 'ulike': 5.605170185988092, 'unbelievable': 5.605170185988092, 'undergrad': 5.605170185988092, 'unfollow': 5.605170185988092, 'unfornately': 5.605170185988092, 'unhappy': 5.605170185988092, 'unless': 5.605170185988092, 'update': 5.605170185988092, 'upset': 5.605170185988092, 'useless': 5.605170185988092, 'user': 5.605170185988092, 'vacation': 5.605170185988092, 'valley': 5.605170185988092, 'viennah': 5.605170185988092, 'villa': 5.605170185988092, 'wage': 5.605170185988092, 'wake': 5.605170185988092, 'wana': 5.605170185988092, 'wanna': 5.605170185988092, 'want': 4.506557897319982, 'wanted': 5.605170185988092, 'watch': 4.506557897319982, 'watching': 5.605170185988092, 'wayyy': 5.605170185988092, 'wear': 5.605170185988092, 'webpage': 5.605170185988092, 'wednesday': 5.605170185988092, 'week': 5.605170185988092, 'well': 4.912023005428146, 'whole': 4.912023005428146, 'wish': 4.912023005428146, 'wonder': 5.605170185988092, 'wonders': 5.605170185988092, 'work': 4.218875824868201, 'workin': 5.605170185988092, 'working': 4.912023005428146, 'worse': 5.605170185988092, 'would': 4.912023005428146, 'wutcha': 5.605170185988092}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuOVM3EAg-2O",
        "outputId": "0c4f73ce-2463-458a-b749-632512a324a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "feature_names = np.array(tf.get_feature_names())\n",
        "sorted_by_idf = np.argsort(tf.idf_)\n",
        "print(\"Features with lowest IDF:\\n{}\".format(feature_names[sorted_by_idf[:10]]))\n",
        "print(\"\\nFeatures with highest idf:\\n{}\".format(feature_names[sorted_by_idf[-10:]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features with lowest IDF:\n",
            "['like' 'think' 'tomorrow' 'really' 'sorry' 'time' 'today' 'miss' 'hate'\n",
            " 'though']\n",
            "\n",
            "Features with highest idf:\n",
            "['forgotten' 'forget' 'forever' 'follow' 'fleurylis' 'first' 'fire' 'fine'\n",
            " 'gear' 'wutcha']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOEkS7nEk1ob",
        "outputId": "ecc14cf2-31c6-48ed-a5aa-82660a056ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#TF-IDF - Maximum token value throughout the whole dataset\n",
        "\n",
        "tfidf_value = tf.transform(text)\n",
        "\n",
        "# find maximum value for each of the features over all of dataset:\n",
        "max_val = tfidf_value.max(axis=0).toarray().ravel()\n",
        "\n",
        "#sort weights from smallest to biggest and extract their indices\n",
        "sort_by_tfidf = max_val.argsort()\n",
        "\n",
        "print(\"Features with lowest tfidf:\\n{}\".format(feature_names[sort_by_tfidf[:10]]))\n",
        "print(\"\\nFeatures with highest tfidf: \\n{}\".format(feature_names[sort_by_tfidf[-10:]]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features with lowest tfidf:\n",
            "['like' 'think' 'tomorrow' 'really' 'hate' 'sorry' 'time' 'today' 'miss'\n",
            " 'though']\n",
            "\n",
            "Features with highest tfidf: \n",
            "['first' 'fire' 'fine' 'friend' 'still' 'class' 'never' 'sick' 'nite'\n",
            " 'leslie']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQIHmKWjgsyX"
      },
      "source": [
        "### Co-Occurrence Vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-61vpYhrrEPm"
      },
      "source": [
        "import collections# implements specialized container datatypes providing alternatives to Python’s general purpose built-in containers, dict, list, set, and tuple.\n",
        "def co_occurrence(sentences, window_size):\n",
        "    d = collections.defaultdict(int) #dict subclass that calls a factory function to supply missing values\n",
        "    vocab = set()\n",
        "    for text in sentences:\n",
        "        # preprocessing (use tokenizer instead)\n",
        "        text = text.lower().split()\n",
        "        # iterate over sentences\n",
        "        for i in range(len(text)):\n",
        "            token = text[i]\n",
        "            vocab.add(token)  # add to vocab\n",
        "            next_token = text[i+1 : i+1+window_size]\n",
        "            for t in next_token:\n",
        "                key = tuple( sorted([t, token]) )\n",
        "                d[key] += 1\n",
        "\n",
        "    # formulate the dictionary into dataframe\n",
        "    vocab = sorted(vocab) # sort vocab\n",
        "    df = pd.DataFrame(data=np.zeros((len(vocab), len(vocab)), dtype=np.int16),\n",
        "                      index=vocab,\n",
        "                      columns=vocab)\n",
        "    for key, value in d.items():\n",
        "        df.at[key[0], key[1]] = value\n",
        "        df.at[key[1], key[0]] = value\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kMB_Z9550Va"
      },
      "source": [
        "text_co = list(dataset[\"text\"][:50]) #Just the top 50 tweets\n",
        "co_occurence_df = co_occurrence(text_co, 2) #dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3jmZX2YD_WL",
        "outputId": "3349494e-c4eb-45e4-b38f-07cc9fe68f8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "co_occurence_df.head(50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account</th>\n",
              "      <th>afternoon</th>\n",
              "      <th>alielayus</th>\n",
              "      <th>almost</th>\n",
              "      <th>also</th>\n",
              "      <th>always</th>\n",
              "      <th>alydesigns</th>\n",
              "      <th>anaheim</th>\n",
              "      <th>angry</th>\n",
              "      <th>another</th>\n",
              "      <th>anymore</th>\n",
              "      <th>asian</th>\n",
              "      <th>asked</th>\n",
              "      <th>asleep</th>\n",
              "      <th>ated</th>\n",
              "      <th>awww</th>\n",
              "      <th>back</th>\n",
              "      <th>baked</th>\n",
              "      <th>ball</th>\n",
              "      <th>barista</th>\n",
              "      <th>bear</th>\n",
              "      <th>behaving</th>\n",
              "      <th>blackberry</th>\n",
              "      <th>blagh</th>\n",
              "      <th>blah</th>\n",
              "      <th>body</th>\n",
              "      <th>bounds</th>\n",
              "      <th>break</th>\n",
              "      <th>breaking</th>\n",
              "      <th>breaks</th>\n",
              "      <th>burnt</th>\n",
              "      <th>cake</th>\n",
              "      <th>call</th>\n",
              "      <th>called</th>\n",
              "      <th>came</th>\n",
              "      <th>caregiving</th>\n",
              "      <th>cause</th>\n",
              "      <th>champ</th>\n",
              "      <th>checked</th>\n",
              "      <th>city</th>\n",
              "      <th>...</th>\n",
              "      <th>tatiana</th>\n",
              "      <th>taxes</th>\n",
              "      <th>teardrops</th>\n",
              "      <th>tell</th>\n",
              "      <th>texting</th>\n",
              "      <th>thanks</th>\n",
              "      <th>think</th>\n",
              "      <th>though</th>\n",
              "      <th>thought</th>\n",
              "      <th>three</th>\n",
              "      <th>time</th>\n",
              "      <th>timeline</th>\n",
              "      <th>times</th>\n",
              "      <th>today</th>\n",
              "      <th>tomorrow</th>\n",
              "      <th>tomorrows</th>\n",
              "      <th>track</th>\n",
              "      <th>tracy</th>\n",
              "      <th>twanking</th>\n",
              "      <th>twittera</th>\n",
              "      <th>uids</th>\n",
              "      <th>unfornately</th>\n",
              "      <th>update</th>\n",
              "      <th>upset</th>\n",
              "      <th>user</th>\n",
              "      <th>valley</th>\n",
              "      <th>viennah</th>\n",
              "      <th>wake</th>\n",
              "      <th>wanna</th>\n",
              "      <th>want</th>\n",
              "      <th>wanted</th>\n",
              "      <th>watch</th>\n",
              "      <th>watching</th>\n",
              "      <th>wear</th>\n",
              "      <th>week</th>\n",
              "      <th>whole</th>\n",
              "      <th>wish</th>\n",
              "      <th>work</th>\n",
              "      <th>workin</th>\n",
              "      <th>would</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>account</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>afternoon</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alielayus</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>almost</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>also</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>always</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alydesigns</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anaheim</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>angry</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>another</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anymore</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>asian</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>asked</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>asleep</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ated</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>awww</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>back</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>baked</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ball</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>barista</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bear</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>behaving</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>blackberry</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>blagh</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>blah</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>body</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bounds</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>break</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>breaking</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>breaks</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>burnt</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cake</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>call</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>called</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>came</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>caregiving</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cause</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>champ</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>checked</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>city</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cocomix</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comfortable</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counts</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>crew</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dear</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>death</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>depressed</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>depressing</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>directors</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50 rows × 236 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             account  afternoon  alielayus  almost  ...  wish  work  workin  would\n",
              "account            0          0          0       0  ...     0     0       0      0\n",
              "afternoon          0          0          0       0  ...     0     1       0      0\n",
              "alielayus          0          0          0       0  ...     0     0       0      0\n",
              "almost             0          0          0       0  ...     0     0       0      0\n",
              "also               0          0          0       0  ...     0     0       0      0\n",
              "always             0          0          0       0  ...     0     0       0      0\n",
              "alydesigns         0          0          0       0  ...     0     0       0      0\n",
              "anaheim            0          0          0       0  ...     0     0       0      0\n",
              "angry              0          0          0       0  ...     0     0       0      0\n",
              "another            0          0          0       0  ...     0     1       0      0\n",
              "anymore            0          0          0       0  ...     0     0       0      0\n",
              "asian              0          0          0       0  ...     0     0       0      0\n",
              "asked              0          0          0       0  ...     0     0       0      0\n",
              "asleep             0          0          0       0  ...     0     0       0      0\n",
              "ated               0          0          0       0  ...     0     0       0      0\n",
              "awww               0          0          0       0  ...     1     0       0      0\n",
              "back               0          0          0       0  ...     0     0       0      0\n",
              "baked              0          0          0       0  ...     0     0       0      0\n",
              "ball               0          0          0       0  ...     0     0       0      0\n",
              "barista            0          0          0       0  ...     0     0       0      0\n",
              "bear               0          0          0       0  ...     0     0       0      0\n",
              "behaving           0          0          0       0  ...     0     0       0      0\n",
              "blackberry         0          0          0       0  ...     0     0       0      0\n",
              "blagh              0          0          0       0  ...     0     0       0      0\n",
              "blah               0          0          0       0  ...     0     0       0      0\n",
              "body               0          0          0       0  ...     0     0       0      0\n",
              "bounds             0          0          0       0  ...     0     0       0      0\n",
              "break              0          0          0       0  ...     0     0       0      0\n",
              "breaking           0          0          0       0  ...     0     0       0      0\n",
              "breaks             0          0          0       0  ...     0     0       0      0\n",
              "burnt              0          0          0       0  ...     0     0       0      0\n",
              "cake               0          0          0       0  ...     0     0       0      0\n",
              "call               0          0          0       0  ...     0     0       0      0\n",
              "called             0          0          0       0  ...     0     0       0      0\n",
              "came               0          0          0       0  ...     0     0       0      0\n",
              "caregiving         0          0          0       0  ...     0     0       0      0\n",
              "cause              0          0          0       0  ...     0     0       0      0\n",
              "champ              0          0          0       0  ...     0     0       0      0\n",
              "checked            0          0          0       0  ...     0     0       0      0\n",
              "city               0          0          0       0  ...     0     0       0      0\n",
              "class              0          0          0       0  ...     0     2       0      0\n",
              "cocomix            0          0          0       0  ...     0     0       0      0\n",
              "comfortable        0          0          0       0  ...     1     0       0      0\n",
              "counts             0          0          0       0  ...     0     0       0      0\n",
              "crew               0          0          0       0  ...     0     0       0      0\n",
              "dear               0          0          0       0  ...     0     0       0      0\n",
              "death              0          0          0       0  ...     0     0       0      0\n",
              "depressed          0          0          0       0  ...     0     0       0      0\n",
              "depressing         0          0          0       0  ...     0     0       0      0\n",
              "directors          0          0          0       0  ...     0     0       0      0\n",
              "\n",
              "[50 rows x 236 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miqaPfNLIjDl"
      },
      "source": [
        "The co-occurence matrix  above is quite sparse i.e. many 0s mean very few words co-occured in the  specified window i.e. window of  2 words in our case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNJPlgCigztG"
      },
      "source": [
        "### Continuous Bag of Words (CBoW)\n",
        "\n",
        "**Word Embedding** is a modeling technique where words are mapped to vectors of real numbers based in a vector space with set dimensions . Neural networks and  other probabilistic  models  generate them. **[Word2Vec](https://code.google.com/archive/p/word2vec/)** is  one technique. CBOW is one of the two ways of of  predicing the next word in a sentence.\n",
        "\n",
        "1. CBOW model predicts the current word given context words within specific window. The input layer in this  instance contains the context words and the output layer contains the current word. The hidden layer contains the number of dimensions in which we want to represent current word present at the output layer.\n",
        "\n",
        "![CBOW](https://cdn-images-1.medium.com/max/800/1*UVe8b6CWYykcxbBOR6uCfg.png)\n",
        "      \n",
        "The CBOW model Framework (Source: https://arxiv.org/pdf/1301.3781.pdf Mikolov el al.)\n",
        "\n",
        "\n",
        "**Reference:**\n",
        "\n",
        "Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems (pp. 3111-3119)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu2koe4REMTs",
        "outputId": "ba35dd15-69d5-4f0c-c2bb-5249beccd7a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import gensim  #Gensim makes it very easy to train complicated models with very few lines of  code\n",
        "from gensim.models import Word2Vec\n",
        "nltk.download('punkt')\n",
        "import warnings\n",
        "warnings.filterwarnings(action = 'ignore')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-csMrQtPEp0C"
      },
      "source": [
        "text_w2v =  dataset['tokens'][:10000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_1oJnHjFPYZ"
      },
      "source": [
        "CBOW_Model = gensim.models.Word2Vec(text_w2v, min_count = 1, size = 100, window = 5) #Default representatio is CBOW , unless specified as Skipgram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dgqTbESGioe",
        "outputId": "4cbadf93-6565-4bf1-9d48-c3b746e95a3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(\"Most Similar Word by CBOW  to 'tomorrow': \\n\")\n",
        "CBOW_Model.wv.most_similar(\"tomorrow\") #The score is the cosine similarity score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Similar Word by CBOW  to 'tomorrow': \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('going', 0.9997029304504395), ('still', 0.9996705651283264), ('time', 0.9996705651283264), ('today', 0.9996482133865356), ('hope', 0.9996415972709656), ('work', 0.9996351599693298), ('miss', 0.999625563621521), ('tonight', 0.9996063709259033), ('think', 0.9996018409729004), ('week', 0.9995994567871094)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll8ptBW6bohs"
      },
      "source": [
        "###  Skip Gram\n",
        "Skip gram model on the other hand predicts the surrounding context words within specific window given current word.\n",
        "\n",
        "![SkipGram Representation](https://cdn-images-1.medium.com/max/800/1*SR6l59udY05_bUICAjb6-w.png)\n",
        "\n",
        "The Skip-gram model Framework (Source: https://arxiv.org/pdf/1301.3781.pdf Mikolov el al.)\n",
        "\n",
        "The input layer contains the current word while the output layer contains the context words. The hidden layer contains the number of dimensions in which we want to represent current word present at the input layer.\n",
        "\n",
        "**Reference:**\n",
        "\n",
        "Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems (pp. 3111-3119)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxucZrmeTkyn"
      },
      "source": [
        "# Create CBOW model\n",
        "Skp_Gram_Model = gensim.models.Word2Vec(text_w2v, min_count = 1, size = 100, window = 5, sg = 1) #sg=1 changes the representation from CBOW to SkipGram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO2yYTOiIYsJ",
        "outputId": "a7eabf84-4cd6-4665-d94a-c43e6a602e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(\"Most Similar Word by SkipGram  to 'tomorrow': \\n\")\n",
        "Skp_Gram_Model.wv.most_similar(\"tomorrow\") #The score is the cosine similarity score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Similar Word by SkipGram  to 'tomorrow': \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('going', 0.9997503757476807), ('today', 0.999640941619873), ('tired', 0.9996140003204346), ('gonna', 0.9996077418327332), ('early', 0.9996066093444824), ('gotta', 0.9995886087417603), ('time', 0.9995882511138916), ('class', 0.9995787143707275), ('long', 0.9995675086975098), ('school', 0.9995666146278381)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3D_3h-ihXAt"
      },
      "source": [
        "# Deep Learning in NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7IWkS9Gh-Q4"
      },
      "source": [
        "### Bidirectional Encoder Representations from Transformers (BERT)\n",
        "\n",
        "BERT is a method of pre-training language representations, meaning that we train a general-purpose \"language understanding\" model on a large text corpus (like Wikipedia), and then use that model for downstream NLP tasks that we care about (e.g. question answering). BERT outperforms previous methods because it is the first unsupervised, deeply bidirectional system for pre-training NLP.\n",
        "\n",
        "Reference paper: [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jBP4ey9dyIm"
      },
      "source": [
        "We'll use a pre-trained BERT to generate the embedding vectors. We'll set up a BERT layer as a hidden layer which requires token_ids, mask_ids and  segment_ids as input sequence. More information on this can be found [here](https://github.com/google-research/bert/blob/master/run_classifier.py)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-79qbMgH0CUG"
      },
      "source": [
        "dataset_bert = dataset[[\"target\",\"text\"]] #Dataset for the BERT model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swn9co5B0PFW",
        "outputId": "b762f934-db37-44c7-f054-08118b90393e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dataset_bert.head() #Sample records"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>switchfoot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>upset update facebook texting might result sch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>kenichan dived many times ball managed save re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>whole body feels itchy like fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>nationwideclass behaving</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target                                               text\n",
              "0       0                                         switchfoot\n",
              "1       0  upset update facebook texting might result sch...\n",
              "2       0  kenichan dived many times ball managed save re...\n",
              "3       0                   whole body feels itchy like fire\n",
              "4       0                           nationwideclass behaving"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBEQhBZ5zmVM",
        "outputId": "50587aaf-4cae-4e27-e028-b5f89bc37e26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Split the dataset into training, validation and  testing sets for BERT modelling.\n",
        "from sklearn.model_selection import train_test_split\n",
        "TRAIN_SIZE = 0.75\n",
        "VAL_SIZE = 0.05\n",
        "dataset_count = len(dataset_bert)\n",
        "\n",
        "df_train_val, df_test = train_test_split(dataset_bert, test_size=1-TRAIN_SIZE-VAL_SIZE, random_state=42)\n",
        "df_train, df_val = train_test_split(df_train_val, test_size=VAL_SIZE / (VAL_SIZE + TRAIN_SIZE), random_state=42)\n",
        "\n",
        "print(\"TRAIN size:\", len(df_train))\n",
        "print(\"VALIDATION size:\", len(df_val))\n",
        "print(\"TEST size:\", len(df_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN size: 1200000\n",
            "VALIDATION size: 80000\n",
            "TEST size: 320000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PerjDnc56dWG",
        "outputId": "6d982614-ffc4-4963-e382-4e29f935ff0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_val.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1309287</th>\n",
              "      <td>4</td>\n",
              "      <td>heat brought letter summer slain fists raised ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>569311</th>\n",
              "      <td>0</td>\n",
              "      <td>missing days felt inside</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133752</th>\n",
              "      <td>0</td>\n",
              "      <td>rebeccao dear well</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1087939</th>\n",
              "      <td>4</td>\n",
              "      <td>chalkbored thank love bright colours could don...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1378591</th>\n",
              "      <td>4</td>\n",
              "      <td>thinking eating another doughnut</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         target                                               text\n",
              "1309287       4  heat brought letter summer slain fists raised ...\n",
              "569311        0                           missing days felt inside\n",
              "133752        0                                 rebeccao dear well\n",
              "1087939       4  chalkbored thank love bright colours could don...\n",
              "1378591       4                   thinking eating another doughnut"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwmdfLCS7EeT",
        "outputId": "9bd7a4bf-24b6-4844-cf59-4919bc105fd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Transform Dataframe to CSV files\n",
        "!mkdir dataset\n",
        "df_train.sample(frac=1.0).reset_index(drop=True).to_csv('dataset/train.tsv', sep='\\t', index=None, header=None)\n",
        "df_val.to_csv('dataset/dev.tsv', sep='\\t', index=None, header=None)\n",
        "df_test.to_csv('dataset/test.tsv', sep='\\t', index=None, header=None)\n",
        "! cd dataset && ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘dataset’: File exists\n",
            "dev.tsv  test.tsv  train.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZhwDtCIBmBB",
        "outputId": "ed7b11a4-ab47-46c8-ffb0-58e1e977250d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "#!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip - huge model. Takes sometime to train\n",
        "!wget https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-2_H-128_A-2.zip #smaller version. Ideal for students  learnign without  lots of  resources\n",
        "!unzip uncased_L-2_H-128_A-2.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-28 09:41:37--  https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-2_H-128_A-2.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16529104 (16M) [application/zip]\n",
            "Saving to: ‘uncased_L-2_H-128_A-2.zip’\n",
            "\n",
            "uncased_L-2_H-128_A 100%[===================>]  15.76M  4.92MB/s    in 3.2s    \n",
            "\n",
            "2020-04-28 09:41:41 (4.92 MB/s) - ‘uncased_L-2_H-128_A-2.zip’ saved [16529104/16529104]\n",
            "\n",
            "Archive:  uncased_L-2_H-128_A-2.zip\n",
            "  inflating: bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: bert_config.json        \n",
            "  inflating: vocab.txt               \n",
            "  inflating: bert_model.ckpt.index   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWpWCk4d8eiO",
        "outputId": "5a188395-a1b2-4370-e70a-26cbe1c2140a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!pip install BertLibrary #Tensorflow library for quick and easy training and finetuning of models based on Bert"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting BertLibrary\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/f6/62c112afb62265d980e44db418094e11950a47b79ea8d71d14a2a9c6f6d8/BertLibrary-0.0.4.tar.gz (57kB)\n",
            "\r\u001b[K     |█████▊                          | 10kB 23.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from BertLibrary) (1.18.3)\n",
            "Building wheels for collected packages: BertLibrary\n",
            "  Building wheel for BertLibrary (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for BertLibrary: filename=BertLibrary-0.0.4-cp36-none-any.whl size=75016 sha256=f3957b435ebcb574c3f9ea11d97868eea44107c18e6697dab79626fde9a24936\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/3d/ab/990438ec53e97a0203d2be35ad77fcdcb0750bee7057ddf25f\n",
            "Successfully built BertLibrary\n",
            "Installing collected packages: BertLibrary\n",
            "Successfully installed BertLibrary-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwZ8vU2W7Xub",
        "outputId": "dee0b4e9-d432-46e8-a81c-ef39c3b87288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from BertLibrary import BertFTModel\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/BertLibrary/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/BertLibrary/bert_evaluator.py:60: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahw_72GYrH4V",
        "outputId": "fe9db9f6-15b7-4da6-e1aa-c2ea1e4a053d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!mkdir output\n",
        "ft_model = BertFTModel( model_dir='uncased_L-2_H-128_A-2',\n",
        "                        ckpt_name=\"bert_model.ckpt\",\n",
        "                        labels=['0','1','2','3','4'], #Labels  in your  dataset. Sentiment scores in our case\n",
        "                        lr=1e-05,\n",
        "                        num_train_steps=10000, #Quite few steps. Increase the number as per your reference\n",
        "                        num_warmup_steps=1000,\n",
        "                        ckpt_output_dir='output',\n",
        "                        save_check_steps=1000,\n",
        "                        do_lower_case=False,\n",
        "                        max_seq_len=50,\n",
        "                        batch_size=32,\n",
        "                        )\n",
        "ft_trainer =  ft_model.get_trainer()\n",
        "ft_evaluator = ft_model.get_evaluator()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': device_count {\n",
            "  key: \"GPU\"\n",
            "  value: 1\n",
            "}\n",
            "gpu_options {\n",
            "  per_process_gpu_memory_fraction: 0.5\n",
            "  allow_growth: true\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fccb05a2f98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrReqUQ_t9R-",
        "outputId": "9b3a3428-2be7-4ba5-9462-f565b46b6e5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \u001b[0m\u001b[01;34mdataset\u001b[0m/                             training.1600000.processed.noemoticon.csv\n",
            "'Natural Language Processing.ipynb'   \u001b[01;34muncased_L-2_H-128_A-2\u001b[0m/\n",
            " \u001b[01;34moutput\u001b[0m/                              uncased_L-2_H-128_A-2.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r680aABYt4KH",
        "outputId": "b289080e-2fa5-4b8a-8553-53075bcec41b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Torrens/NLP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wz3k0yI3oHR",
        "outputId": "39acbaa0-a5f0-43fc-ac31-83705a127c66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \u001b[0m\u001b[01;34mdataset\u001b[0m/                                    \u001b[01;34muncased_L-12_H-768_A-12\u001b[0m/\n",
            "'Natural Language Processing.ipynb'          uncased_L-12_H-768_A-12.zip\n",
            " \u001b[01;34moutput\u001b[0m/                                     uncased_L-12_H-768_A-12.zip.1\n",
            " training.1600000.processed.noemoticon.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erpXQ56OrvOF",
        "outputId": "9873e33a-6c28-44be-f5db-6647456059d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "ft_trainer.train_from_file('dataset/',35000) #Training  the model on the  split data  in the dataset folder. Make sure you have such a folder or change the name to yours"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fcd300cac80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fcd300cac80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (32, 50)\n",
            "INFO:tensorflow:  name = input_mask, shape = (32, 50)\n",
            "INFO:tensorflow:  name = is_real_example, shape = (32,)\n",
            "INFO:tensorflow:  name = label_ids, shape = (32,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (32, 50)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (128, 512), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (512,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (128, 512), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (512,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (5, 128)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (5,)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into output/model.ckpt.\n",
            "INFO:tensorflow:loss = 1.5005836, step = 0\n",
            "INFO:tensorflow:global_step/sec: 2.99804\n",
            "INFO:tensorflow:loss = 1.3929, step = 100 (33.356 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.3865\n",
            "INFO:tensorflow:loss = 1.1845441, step = 200 (1.420 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.7731\n",
            "INFO:tensorflow:loss = 0.98771024, step = 300 (1.454 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.3215\n",
            "INFO:tensorflow:loss = 0.83712596, step = 400 (1.443 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.5921\n",
            "INFO:tensorflow:loss = 0.6953739, step = 500 (1.397 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.1605\n",
            "INFO:tensorflow:loss = 0.53509766, step = 600 (1.446 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.2854\n",
            "INFO:tensorflow:loss = 0.40363026, step = 700 (1.443 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.3202\n",
            "INFO:tensorflow:loss = 0.29899764, step = 800 (1.402 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.9454\n",
            "INFO:tensorflow:loss = 0.21213213, step = 900 (1.430 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into output/model.ckpt.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fcd2ff499d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fcd2ff499d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (32, 50)\n",
            "INFO:tensorflow:  name = input_mask, shape = (32, 50)\n",
            "INFO:tensorflow:  name = is_real_example, shape = (32,)\n",
            "INFO:tensorflow:  name = label_ids, shape = (32,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (32, 50)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (128, 512), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (512,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (128, 512), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (512,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (5, 128)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (5,)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-04-28T09:45:43Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from output/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2020-04-28-09:45:44\n",
            "INFO:tensorflow:Saving dict for global step 1000: eval_accuracy = 0.0, global_step = 1000, loss = 0.0\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: output/model.ckpt-1000\n",
            "INFO:tensorflow:global_step/sec: 35.0537\n",
            "INFO:tensorflow:loss = 0.14981914, step = 1000 (2.852 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.6958\n",
            "INFO:tensorflow:loss = 0.104891755, step = 1100 (1.435 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.5675\n",
            "INFO:tensorflow:loss = 0.07784368, step = 1200 (1.417 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.4265\n",
            "INFO:tensorflow:loss = 0.0619979, step = 1300 (1.420 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.7625\n",
            "INFO:tensorflow:loss = 0.048279446, step = 1400 (1.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.2465\n",
            "INFO:tensorflow:loss = 0.044198457, step = 1500 (1.444 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.1804\n",
            "INFO:tensorflow:loss = 0.035166953, step = 1600 (1.425 sec)\n",
            "INFO:tensorflow:global_step/sec: 65.2966\n",
            "INFO:tensorflow:loss = 0.03164608, step = 1700 (1.532 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.771\n",
            "INFO:tensorflow:loss = 0.028148953, step = 1800 (1.433 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.933\n",
            "INFO:tensorflow:loss = 0.025940603, step = 1900 (1.409 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 56.267\n",
            "INFO:tensorflow:loss = 0.0236848, step = 2000 (1.777 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.755\n",
            "INFO:tensorflow:loss = 0.022052474, step = 2100 (1.394 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.1439\n",
            "INFO:tensorflow:loss = 0.019160114, step = 2200 (1.446 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.7959\n",
            "INFO:tensorflow:loss = 0.018514792, step = 2300 (1.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.3303\n",
            "INFO:tensorflow:loss = 0.01670919, step = 2400 (1.422 sec)\n",
            "INFO:tensorflow:global_step/sec: 63.8582\n",
            "INFO:tensorflow:loss = 0.015145017, step = 2500 (1.566 sec)\n",
            "INFO:tensorflow:global_step/sec: 60.0371\n",
            "INFO:tensorflow:loss = 0.013968059, step = 2600 (1.666 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.8908\n",
            "INFO:tensorflow:loss = 0.014389541, step = 2700 (1.728 sec)\n",
            "INFO:tensorflow:global_step/sec: 60.3758\n",
            "INFO:tensorflow:loss = 0.012493761, step = 2800 (1.656 sec)\n",
            "INFO:tensorflow:global_step/sec: 60.4329\n",
            "INFO:tensorflow:loss = 0.011715604, step = 2900 (1.655 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 47.5006\n",
            "INFO:tensorflow:loss = 0.010658469, step = 3000 (2.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 63.5825\n",
            "INFO:tensorflow:loss = 0.0100777745, step = 3100 (1.573 sec)\n",
            "INFO:tensorflow:global_step/sec: 63.043\n",
            "INFO:tensorflow:loss = 0.010202992, step = 3200 (1.586 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.1611\n",
            "INFO:tensorflow:loss = 0.009517402, step = 3300 (1.405 sec)\n",
            "INFO:tensorflow:global_step/sec: 67.7242\n",
            "INFO:tensorflow:loss = 0.008886529, step = 3400 (1.477 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.5205\n",
            "INFO:tensorflow:loss = 0.008363044, step = 3500 (1.418 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.5982\n",
            "INFO:tensorflow:loss = 0.0076597873, step = 3600 (1.397 sec)\n",
            "INFO:tensorflow:global_step/sec: 67.6084\n",
            "INFO:tensorflow:loss = 0.007795883, step = 3700 (1.479 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.0467\n",
            "INFO:tensorflow:loss = 0.0070255627, step = 3800 (1.427 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.4215\n",
            "INFO:tensorflow:loss = 0.0064794365, step = 3900 (1.400 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 56.5037\n",
            "INFO:tensorflow:loss = 0.006044692, step = 4000 (1.770 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.418\n",
            "INFO:tensorflow:loss = 0.0058258316, step = 4100 (1.400 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.8293\n",
            "INFO:tensorflow:loss = 0.005726743, step = 4200 (1.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.1401\n",
            "INFO:tensorflow:loss = 0.0056759436, step = 4300 (1.426 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.5168\n",
            "INFO:tensorflow:loss = 0.005400256, step = 4400 (1.439 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.0054\n",
            "INFO:tensorflow:loss = 0.005154061, step = 4500 (1.408 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.5543\n",
            "INFO:tensorflow:loss = 0.004728862, step = 4600 (1.438 sec)\n",
            "INFO:tensorflow:global_step/sec: 67.9938\n",
            "INFO:tensorflow:loss = 0.004569471, step = 4700 (1.471 sec)\n",
            "INFO:tensorflow:global_step/sec: 66.5854\n",
            "INFO:tensorflow:loss = 0.0046085073, step = 4800 (1.502 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.3556\n",
            "INFO:tensorflow:loss = 0.00428491, step = 4900 (1.463 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 54.0293\n",
            "INFO:tensorflow:loss = 0.0042930217, step = 5000 (1.851 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.1787\n",
            "INFO:tensorflow:loss = 0.0038006203, step = 5100 (1.445 sec)\n",
            "INFO:tensorflow:global_step/sec: 67.2477\n",
            "INFO:tensorflow:loss = 0.0039302986, step = 5200 (1.488 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.0009\n",
            "INFO:tensorflow:loss = 0.003518832, step = 5300 (1.449 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.178\n",
            "INFO:tensorflow:loss = 0.0035319305, step = 5400 (1.425 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.5364\n",
            "INFO:tensorflow:loss = 0.0034097293, step = 5500 (1.417 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.8331\n",
            "INFO:tensorflow:loss = 0.0032301932, step = 5600 (1.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.4221\n",
            "INFO:tensorflow:loss = 0.0031475357, step = 5700 (1.441 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.7752\n",
            "INFO:tensorflow:loss = 0.0028807872, step = 5800 (1.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.2492\n",
            "INFO:tensorflow:loss = 0.0030165033, step = 5900 (1.424 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 6000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 56.8586\n",
            "INFO:tensorflow:loss = 0.0028231544, step = 6000 (1.758 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.8181\n",
            "INFO:tensorflow:loss = 0.0028768964, step = 6100 (1.374 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.657\n",
            "INFO:tensorflow:loss = 0.0026936857, step = 6200 (1.395 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.993\n",
            "INFO:tensorflow:loss = 0.0026865413, step = 6300 (1.409 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.5457\n",
            "INFO:tensorflow:loss = 0.00235124, step = 6400 (1.397 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.0771\n",
            "INFO:tensorflow:loss = 0.0022812446, step = 6500 (1.387 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.3633\n",
            "INFO:tensorflow:loss = 0.0025267936, step = 6600 (1.401 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.0404\n",
            "INFO:tensorflow:loss = 0.0021630158, step = 6700 (1.428 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.3965\n",
            "INFO:tensorflow:loss = 0.0021846972, step = 6800 (1.400 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.5462\n",
            "INFO:tensorflow:loss = 0.0021220916, step = 6900 (1.438 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 7000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 55.6639\n",
            "INFO:tensorflow:loss = 0.0020566431, step = 7000 (1.797 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.2176\n",
            "INFO:tensorflow:loss = 0.0021061993, step = 7100 (1.384 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.3076\n",
            "INFO:tensorflow:loss = 0.0020736812, step = 7200 (1.403 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.4712\n",
            "INFO:tensorflow:loss = 0.0017794177, step = 7300 (1.419 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.4143\n",
            "INFO:tensorflow:loss = 0.0018583823, step = 7400 (1.381 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.7664\n",
            "INFO:tensorflow:loss = 0.0016722416, step = 7500 (1.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.6255\n",
            "INFO:tensorflow:loss = 0.0015996462, step = 7600 (1.416 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.7738\n",
            "INFO:tensorflow:loss = 0.0017582264, step = 7700 (1.454 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.5779\n",
            "INFO:tensorflow:loss = 0.0015583648, step = 7800 (1.437 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.543\n",
            "INFO:tensorflow:loss = 0.0017302666, step = 7900 (1.418 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 8000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 57.6095\n",
            "INFO:tensorflow:loss = 0.001597883, step = 8000 (1.736 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.1507\n",
            "INFO:tensorflow:loss = 0.0014876935, step = 8100 (1.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.923\n",
            "INFO:tensorflow:loss = 0.0015212392, step = 8200 (1.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.2324\n",
            "INFO:tensorflow:loss = 0.0014798593, step = 8300 (1.404 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.8388\n",
            "INFO:tensorflow:loss = 0.0014605046, step = 8400 (1.411 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.877\n",
            "INFO:tensorflow:loss = 0.001477551, step = 8500 (1.411 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.4506\n",
            "INFO:tensorflow:loss = 0.001421545, step = 8600 (1.400 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.8254\n",
            "INFO:tensorflow:loss = 0.0013780969, step = 8700 (1.432 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.7564\n",
            "INFO:tensorflow:loss = 0.0012663067, step = 8800 (1.454 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.5883\n",
            "INFO:tensorflow:loss = 0.0013171792, step = 8900 (1.417 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 9000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 52.391\n",
            "INFO:tensorflow:loss = 0.0012651674, step = 9000 (1.909 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.4063\n",
            "INFO:tensorflow:loss = 0.0012985908, step = 9100 (1.420 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.1234\n",
            "INFO:tensorflow:loss = 0.0013783133, step = 9200 (1.387 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.1979\n",
            "INFO:tensorflow:loss = 0.0012788507, step = 9300 (1.404 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.4892\n",
            "INFO:tensorflow:loss = 0.0012055556, step = 9400 (1.419 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.376\n",
            "INFO:tensorflow:loss = 0.0012225935, step = 9500 (1.401 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.8949\n",
            "INFO:tensorflow:loss = 0.0012115819, step = 9600 (1.391 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.4534\n",
            "INFO:tensorflow:loss = 0.0011775321, step = 9700 (1.420 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.8367\n",
            "INFO:tensorflow:loss = 0.0013431513, step = 9800 (1.453 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.544\n",
            "INFO:tensorflow:loss = 0.0011841375, step = 9900 (1.402 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 57.7806\n",
            "INFO:tensorflow:loss = 0.0012339376, step = 10000 (1.727 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.5702\n",
            "INFO:tensorflow:loss = 0.001268931, step = 10100 (1.360 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.9746\n",
            "INFO:tensorflow:loss = 0.0011824633, step = 10200 (1.389 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.799\n",
            "INFO:tensorflow:loss = 0.0010731642, step = 10300 (1.433 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.9647\n",
            "INFO:tensorflow:loss = 0.0011558582, step = 10400 (1.450 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.0034\n",
            "INFO:tensorflow:loss = 0.0012857374, step = 10500 (1.449 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.5883\n",
            "INFO:tensorflow:loss = 0.0012105854, step = 10600 (1.437 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.3329\n",
            "INFO:tensorflow:loss = 0.0012156458, step = 10700 (1.463 sec)\n",
            "INFO:tensorflow:global_step/sec: 67.0191\n",
            "INFO:tensorflow:loss = 0.0012605203, step = 10800 (1.492 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.6322\n",
            "INFO:tensorflow:loss = 0.0012519744, step = 10900 (1.436 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 11000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 52.8794\n",
            "INFO:tensorflow:loss = 0.0012436274, step = 11000 (1.891 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.1104\n",
            "INFO:tensorflow:loss = 0.0011833326, step = 11100 (1.387 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.8905\n",
            "INFO:tensorflow:loss = 0.0012438109, step = 11200 (1.431 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.7619\n",
            "INFO:tensorflow:loss = 0.0012314325, step = 11300 (1.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.1271\n",
            "INFO:tensorflow:loss = 0.0012822205, step = 11400 (1.447 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.7852\n",
            "INFO:tensorflow:loss = 0.0012261197, step = 11500 (1.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.8091\n",
            "INFO:tensorflow:loss = 0.0011709492, step = 11600 (1.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.4938\n",
            "INFO:tensorflow:loss = 0.0012117021, step = 11700 (1.439 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.0415\n",
            "INFO:tensorflow:loss = 0.0011358011, step = 11800 (1.428 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.8439\n",
            "INFO:tensorflow:loss = 0.0012481078, step = 11900 (1.432 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 12000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 57.1992\n",
            "INFO:tensorflow:loss = 0.0012821822, step = 12000 (1.748 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.2152\n",
            "INFO:tensorflow:loss = 0.0012734141, step = 12100 (1.366 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.1331\n",
            "INFO:tensorflow:loss = 0.0012706053, step = 12200 (1.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.9341\n",
            "INFO:tensorflow:loss = 0.0011448789, step = 12300 (1.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.3582\n",
            "INFO:tensorflow:loss = 0.0012020181, step = 12400 (1.442 sec)\n",
            "INFO:tensorflow:global_step/sec: 67.6031\n",
            "INFO:tensorflow:loss = 0.0011583251, step = 12500 (1.479 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.2477\n",
            "INFO:tensorflow:loss = 0.0011971929, step = 12600 (1.445 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.6824\n",
            "INFO:tensorflow:loss = 0.0012242433, step = 12700 (1.435 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.768\n",
            "INFO:tensorflow:loss = 0.0012206759, step = 12800 (1.433 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.5237\n",
            "INFO:tensorflow:loss = 0.0011503021, step = 12900 (1.418 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 13000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 51.397\n",
            "INFO:tensorflow:loss = 0.0012439641, step = 13000 (1.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.2461\n",
            "INFO:tensorflow:loss = 0.0011856528, step = 13100 (1.444 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.3613\n",
            "INFO:tensorflow:loss = 0.0011578087, step = 13200 (1.401 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.5784\n",
            "INFO:tensorflow:loss = 0.0012629607, step = 13300 (1.768 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.4202\n",
            "INFO:tensorflow:loss = 0.0011721028, step = 13400 (1.400 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.9966\n",
            "INFO:tensorflow:loss = 0.0011102238, step = 13500 (1.429 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.4989\n",
            "INFO:tensorflow:loss = 0.0011527201, step = 13600 (1.419 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.4241\n",
            "INFO:tensorflow:loss = 0.0011749003, step = 13700 (1.461 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.7861\n",
            "INFO:tensorflow:loss = 0.0011718225, step = 13800 (1.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.0665\n",
            "INFO:tensorflow:loss = 0.0011862181, step = 13900 (1.448 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 14000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 56.251\n",
            "INFO:tensorflow:loss = 0.0012346533, step = 14000 (1.777 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.5975\n",
            "INFO:tensorflow:loss = 0.0011581066, step = 14100 (1.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 67.7888\n",
            "INFO:tensorflow:loss = 0.0011695009, step = 14200 (1.475 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.7541\n",
            "INFO:tensorflow:loss = 0.0010945012, step = 14300 (1.434 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.1257\n",
            "INFO:tensorflow:loss = 0.0010821851, step = 14400 (1.426 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.2764\n",
            "INFO:tensorflow:loss = 0.0013251884, step = 14500 (1.443 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.8509\n",
            "INFO:tensorflow:loss = 0.0011199388, step = 14600 (1.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.8612\n",
            "INFO:tensorflow:loss = 0.0011650943, step = 14700 (1.452 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.2911\n",
            "INFO:tensorflow:loss = 0.0012847611, step = 14800 (1.423 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.321\n",
            "INFO:tensorflow:loss = 0.0012816265, step = 14900 (1.422 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 15000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 57.5948\n",
            "INFO:tensorflow:loss = 0.0013165982, step = 15000 (1.736 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.5751\n",
            "INFO:tensorflow:loss = 0.0013064715, step = 15100 (1.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.4529\n",
            "INFO:tensorflow:loss = 0.0011616568, step = 15200 (1.399 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.5123\n",
            "INFO:tensorflow:loss = 0.0012783991, step = 15300 (1.398 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.9862\n",
            "INFO:tensorflow:loss = 0.0012135637, step = 15400 (1.409 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.6537\n",
            "INFO:tensorflow:loss = 0.0011742011, step = 15500 (1.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.9855\n",
            "INFO:tensorflow:loss = 0.0011811301, step = 15600 (1.389 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.6919\n",
            "INFO:tensorflow:loss = 0.0012197361, step = 15700 (1.417 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.3266\n",
            "INFO:tensorflow:loss = 0.0012229999, step = 15800 (1.461 sec)\n",
            "INFO:tensorflow:global_step/sec: 67.6472\n",
            "INFO:tensorflow:loss = 0.0012404185, step = 15900 (1.478 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 16000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 54.9647\n",
            "INFO:tensorflow:loss = 0.0011933297, step = 16000 (1.821 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.5664\n",
            "INFO:tensorflow:loss = 0.0012590599, step = 16100 (1.436 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.7275\n",
            "INFO:tensorflow:loss = 0.0011496431, step = 16200 (1.434 sec)\n",
            "INFO:tensorflow:global_step/sec: 67.8665\n",
            "INFO:tensorflow:loss = 0.0011719693, step = 16300 (1.473 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.4706\n",
            "INFO:tensorflow:loss = 0.0012073744, step = 16400 (1.439 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.0424\n",
            "INFO:tensorflow:loss = 0.0012078459, step = 16500 (1.388 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.0242\n",
            "INFO:tensorflow:loss = 0.0011975955, step = 16600 (1.428 sec)\n",
            "INFO:tensorflow:global_step/sec: 66.2164\n",
            "INFO:tensorflow:loss = 0.0011688629, step = 16700 (1.510 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.6696\n",
            "INFO:tensorflow:loss = 0.0011501333, step = 16800 (1.435 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.6758\n",
            "INFO:tensorflow:loss = 0.0012334867, step = 16900 (1.435 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 17000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 50.8518\n",
            "INFO:tensorflow:loss = 0.0011982566, step = 17000 (1.966 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.8345\n",
            "INFO:tensorflow:loss = 0.0012196611, step = 17100 (1.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.2461\n",
            "INFO:tensorflow:loss = 0.0011781135, step = 17200 (1.404 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.7827\n",
            "INFO:tensorflow:loss = 0.001245182, step = 17300 (1.433 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.1575\n",
            "INFO:tensorflow:loss = 0.0011219416, step = 17400 (1.386 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.134\n",
            "INFO:tensorflow:loss = 0.0011468485, step = 17500 (1.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.5302\n",
            "INFO:tensorflow:loss = 0.0013368849, step = 17600 (1.398 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.6863\n",
            "INFO:tensorflow:loss = 0.0012556417, step = 17700 (1.435 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.6717\n",
            "INFO:tensorflow:loss = 0.0011469601, step = 17800 (1.415 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.8668\n",
            "INFO:tensorflow:loss = 0.0012038567, step = 17900 (1.411 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 18000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 57.9216\n",
            "INFO:tensorflow:loss = 0.0011951819, step = 18000 (1.726 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.431\n",
            "INFO:tensorflow:loss = 0.0012675307, step = 18100 (1.381 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.1336\n",
            "INFO:tensorflow:loss = 0.0011148242, step = 18200 (1.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.9751\n",
            "INFO:tensorflow:loss = 0.001190582, step = 18300 (1.409 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.4646\n",
            "INFO:tensorflow:loss = 0.001306005, step = 18400 (1.419 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.7521\n",
            "INFO:tensorflow:loss = 0.0012143285, step = 18500 (1.394 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.4434\n",
            "INFO:tensorflow:loss = 0.0012757108, step = 18600 (1.400 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.1311\n",
            "INFO:tensorflow:loss = 0.0011993609, step = 18700 (1.426 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.6032\n",
            "INFO:tensorflow:loss = 0.001300296, step = 18800 (1.417 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.3859\n",
            "INFO:tensorflow:loss = 0.0012863502, step = 18900 (1.401 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 19000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 56.4355\n",
            "INFO:tensorflow:loss = 0.0012549276, step = 19000 (1.772 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.4765\n",
            "INFO:tensorflow:loss = 0.0012740684, step = 19100 (1.399 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.0476\n",
            "INFO:tensorflow:loss = 0.0012211218, step = 19200 (1.388 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.0378\n",
            "INFO:tensorflow:loss = 0.0011748606, step = 19300 (1.388 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.6487\n",
            "INFO:tensorflow:loss = 0.0012716562, step = 19400 (1.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.9221\n",
            "INFO:tensorflow:loss = 0.0012450295, step = 19500 (1.391 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.1265\n",
            "INFO:tensorflow:loss = 0.0012791308, step = 19600 (1.386 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.1191\n",
            "INFO:tensorflow:loss = 0.0011491881, step = 19700 (1.387 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.3584\n",
            "INFO:tensorflow:loss = 0.0012174975, step = 19800 (1.465 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.3013\n",
            "INFO:tensorflow:loss = 0.0011423209, step = 19900 (1.400 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 20000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 56.5332\n",
            "INFO:tensorflow:loss = 0.001179486, step = 20000 (1.769 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.9603\n",
            "INFO:tensorflow:loss = 0.0013135592, step = 20100 (1.370 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.3851\n",
            "INFO:tensorflow:loss = 0.0012171294, step = 20200 (1.382 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.9771\n",
            "INFO:tensorflow:loss = 0.0012938452, step = 20300 (1.409 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.0159\n",
            "INFO:tensorflow:loss = 0.0011825324, step = 20400 (1.389 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.3678\n",
            "INFO:tensorflow:loss = 0.0012414798, step = 20500 (1.401 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.0681\n",
            "INFO:tensorflow:loss = 0.0012286772, step = 20600 (1.388 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.2155\n",
            "INFO:tensorflow:loss = 0.0012012157, step = 20700 (1.466 sec)\n",
            "INFO:tensorflow:global_step/sec: 65.9859\n",
            "INFO:tensorflow:loss = 0.0012356304, step = 20800 (1.516 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.3889\n",
            "INFO:tensorflow:loss = 0.0012428378, step = 20900 (1.420 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 21000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 56.34\n",
            "INFO:tensorflow:loss = 0.0012804, step = 21000 (1.775 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.4236\n",
            "INFO:tensorflow:loss = 0.0012378889, step = 21100 (1.400 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.6247\n",
            "INFO:tensorflow:loss = 0.001160518, step = 21200 (1.416 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.3416\n",
            "INFO:tensorflow:loss = 0.0011242123, step = 21300 (1.402 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.8053\n",
            "INFO:tensorflow:loss = 0.0010930486, step = 21400 (1.433 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.9621\n",
            "INFO:tensorflow:loss = 0.0011438827, step = 21500 (1.429 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.0217\n",
            "INFO:tensorflow:loss = 0.0011297353, step = 21600 (1.428 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.2492\n",
            "INFO:tensorflow:loss = 0.0011970259, step = 21700 (1.444 sec)\n",
            "INFO:tensorflow:global_step/sec: 67.9895\n",
            "INFO:tensorflow:loss = 0.0013336588, step = 21800 (1.471 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.2756\n",
            "INFO:tensorflow:loss = 0.001290526, step = 21900 (1.443 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 22000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 56.6201\n",
            "INFO:tensorflow:loss = 0.0012368069, step = 22000 (1.766 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.6689\n",
            "INFO:tensorflow:loss = 0.001239966, step = 22100 (1.376 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.7878\n",
            "INFO:tensorflow:loss = 0.0012441606, step = 22200 (1.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.198\n",
            "INFO:tensorflow:loss = 0.0011588458, step = 22300 (1.425 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.277\n",
            "INFO:tensorflow:loss = 0.0012542203, step = 22400 (1.403 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.0836\n",
            "INFO:tensorflow:loss = 0.0011287313, step = 22500 (1.407 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.0278\n",
            "INFO:tensorflow:loss = 0.0012185238, step = 22600 (1.408 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.7592\n",
            "INFO:tensorflow:loss = 0.0012374241, step = 22700 (1.434 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.9818\n",
            "INFO:tensorflow:loss = 0.0012504577, step = 22800 (1.429 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.4196\n",
            "INFO:tensorflow:loss = 0.001231852, step = 22900 (1.420 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 23000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 56.3862\n",
            "INFO:tensorflow:loss = 0.0012455577, step = 23000 (1.773 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.3572\n",
            "INFO:tensorflow:loss = 0.0012242182, step = 23100 (1.363 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.7783\n",
            "INFO:tensorflow:loss = 0.0011835659, step = 23200 (1.374 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.5763\n",
            "INFO:tensorflow:loss = 0.0012202986, step = 23300 (1.397 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.3079\n",
            "INFO:tensorflow:loss = 0.0012115578, step = 23400 (1.403 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.9023\n",
            "INFO:tensorflow:loss = 0.0011793964, step = 23500 (1.391 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.1264\n",
            "INFO:tensorflow:loss = 0.0011137583, step = 23600 (1.386 sec)\n",
            "INFO:tensorflow:global_step/sec: 59.8613\n",
            "INFO:tensorflow:loss = 0.0012932008, step = 23700 (1.671 sec)\n",
            "INFO:tensorflow:global_step/sec: 59.7959\n",
            "INFO:tensorflow:loss = 0.0011883806, step = 23800 (1.672 sec)\n",
            "INFO:tensorflow:global_step/sec: 59.1392\n",
            "INFO:tensorflow:loss = 0.0011998019, step = 23900 (1.691 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 24000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 47.9375\n",
            "INFO:tensorflow:loss = 0.0011966241, step = 24000 (2.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 59.4414\n",
            "INFO:tensorflow:loss = 0.0011918603, step = 24100 (1.682 sec)\n",
            "INFO:tensorflow:global_step/sec: 61.8858\n",
            "INFO:tensorflow:loss = 0.0012259444, step = 24200 (1.616 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.4336\n",
            "INFO:tensorflow:loss = 0.0012252207, step = 24300 (1.420 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.8737\n",
            "INFO:tensorflow:loss = 0.0012052461, step = 24400 (1.372 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.4816\n",
            "INFO:tensorflow:loss = 0.0012801435, step = 24500 (1.399 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.7251\n",
            "INFO:tensorflow:loss = 0.0012150302, step = 24600 (1.375 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.785\n",
            "INFO:tensorflow:loss = 0.0011572442, step = 24700 (1.454 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.379\n",
            "INFO:tensorflow:loss = 0.0011825268, step = 24800 (1.421 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.6553\n",
            "INFO:tensorflow:loss = 0.0012046187, step = 24900 (1.395 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 25000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 57.1057\n",
            "INFO:tensorflow:loss = 0.0011859932, step = 25000 (1.751 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.1917\n",
            "INFO:tensorflow:loss = 0.001105869, step = 25100 (1.385 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.5573\n",
            "INFO:tensorflow:loss = 0.00124705, step = 25200 (1.417 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.2917\n",
            "INFO:tensorflow:loss = 0.0011518864, step = 25300 (1.423 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.8102\n",
            "INFO:tensorflow:loss = 0.0012091205, step = 25400 (1.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.7524\n",
            "INFO:tensorflow:loss = 0.0012496249, step = 25500 (1.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.1351\n",
            "INFO:tensorflow:loss = 0.0011927916, step = 25600 (1.426 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.0329\n",
            "INFO:tensorflow:loss = 0.0012146778, step = 25700 (1.470 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.9936\n",
            "INFO:tensorflow:loss = 0.0012470341, step = 25800 (1.429 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.0749\n",
            "INFO:tensorflow:loss = 0.00136646, step = 25900 (1.427 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 26000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 56.0638\n",
            "INFO:tensorflow:loss = 0.0011889767, step = 26000 (1.784 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.1623\n",
            "INFO:tensorflow:loss = 0.001298826, step = 26100 (1.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.1099\n",
            "INFO:tensorflow:loss = 0.0012248689, step = 26200 (1.387 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.1076\n",
            "INFO:tensorflow:loss = 0.0011763459, step = 26300 (1.387 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.9755\n",
            "INFO:tensorflow:loss = 0.0012301267, step = 26400 (1.429 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.2253\n",
            "INFO:tensorflow:loss = 0.001208221, step = 26500 (1.384 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.4221\n",
            "INFO:tensorflow:loss = 0.0012921052, step = 26600 (1.381 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.5871\n",
            "INFO:tensorflow:loss = 0.0012103361, step = 26700 (1.397 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.9335\n",
            "INFO:tensorflow:loss = 0.0013070011, step = 26800 (1.451 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.7568\n",
            "INFO:tensorflow:loss = 0.0012109759, step = 26900 (1.454 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 27000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 56.3944\n",
            "INFO:tensorflow:loss = 0.0012676881, step = 27000 (1.773 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.439\n",
            "INFO:tensorflow:loss = 0.0012306329, step = 27100 (1.420 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.0116\n",
            "INFO:tensorflow:loss = 0.0013015056, step = 27200 (1.428 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.351\n",
            "INFO:tensorflow:loss = 0.0011794025, step = 27300 (1.402 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.1126\n",
            "INFO:tensorflow:loss = 0.0011382508, step = 27400 (1.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.7505\n",
            "INFO:tensorflow:loss = 0.0012128508, step = 27500 (1.434 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.5641\n",
            "INFO:tensorflow:loss = 0.0012429033, step = 27600 (1.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.7037\n",
            "INFO:tensorflow:loss = 0.001299093, step = 27700 (1.415 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.2488\n",
            "INFO:tensorflow:loss = 0.001188711, step = 27800 (1.444 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.2676\n",
            "INFO:tensorflow:loss = 0.0011875376, step = 27900 (1.384 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 28000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 57.2687\n",
            "INFO:tensorflow:loss = 0.0012087029, step = 28000 (1.746 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.5115\n",
            "INFO:tensorflow:loss = 0.0011685102, step = 28100 (1.379 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.5372\n",
            "INFO:tensorflow:loss = 0.0011862312, step = 28200 (1.398 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.0314\n",
            "INFO:tensorflow:loss = 0.0011676739, step = 28300 (1.369 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.5438\n",
            "INFO:tensorflow:loss = 0.0011169111, step = 28400 (1.398 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.2486\n",
            "INFO:tensorflow:loss = 0.0012906769, step = 28500 (1.384 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.8629\n",
            "INFO:tensorflow:loss = 0.0013490992, step = 28600 (1.392 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.955\n",
            "INFO:tensorflow:loss = 0.0012144851, step = 28700 (1.430 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.6398\n",
            "INFO:tensorflow:loss = 0.0011385395, step = 28800 (1.436 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.8892\n",
            "INFO:tensorflow:loss = 0.0012204914, step = 28900 (1.411 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 29000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 57.0831\n",
            "INFO:tensorflow:loss = 0.0011190749, step = 29000 (1.752 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.9811\n",
            "INFO:tensorflow:loss = 0.0012777139, step = 29100 (1.389 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.8647\n",
            "INFO:tensorflow:loss = 0.0012904513, step = 29200 (1.431 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.2369\n",
            "INFO:tensorflow:loss = 0.0012359028, step = 29300 (1.424 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.0307\n",
            "INFO:tensorflow:loss = 0.0012234369, step = 29400 (1.408 sec)\n",
            "INFO:tensorflow:global_step/sec: 67.3035\n",
            "INFO:tensorflow:loss = 0.0012028627, step = 29500 (1.486 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.0322\n",
            "INFO:tensorflow:loss = 0.0011358495, step = 29600 (1.428 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.4582\n",
            "INFO:tensorflow:loss = 0.0012256966, step = 29701 (1.382 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.4899\n",
            "INFO:tensorflow:loss = 0.0012683512, step = 29800 (1.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.7643\n",
            "INFO:tensorflow:loss = 0.0011282727, step = 29900 (1.393 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 30000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 57.5277\n",
            "INFO:tensorflow:loss = 0.0012035121, step = 30000 (1.738 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.5771\n",
            "INFO:tensorflow:loss = 0.0012227441, step = 30100 (1.398 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.9796\n",
            "INFO:tensorflow:loss = 0.0012689354, step = 30200 (1.389 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.3669\n",
            "INFO:tensorflow:loss = 0.0012444737, step = 30300 (1.401 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.3977\n",
            "INFO:tensorflow:loss = 0.0011844165, step = 30400 (1.381 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.1383\n",
            "INFO:tensorflow:loss = 0.0012047114, step = 30500 (1.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.6411\n",
            "INFO:tensorflow:loss = 0.0012711519, step = 30600 (1.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.9753\n",
            "INFO:tensorflow:loss = 0.0011488321, step = 30700 (1.409 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.2331\n",
            "INFO:tensorflow:loss = 0.0011245917, step = 30800 (1.424 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.3047\n",
            "INFO:tensorflow:loss = 0.0012298857, step = 30900 (1.402 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 31000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 58.0764\n",
            "INFO:tensorflow:loss = 0.00124879, step = 31000 (1.722 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.1369\n",
            "INFO:tensorflow:loss = 0.0011325212, step = 31100 (1.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.5247\n",
            "INFO:tensorflow:loss = 0.0012790404, step = 31200 (1.360 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.2262\n",
            "INFO:tensorflow:loss = 0.0012470584, step = 31300 (1.385 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.6886\n",
            "INFO:tensorflow:loss = 0.0012508816, step = 31400 (1.375 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.4712\n",
            "INFO:tensorflow:loss = 0.0012852693, step = 31500 (1.380 sec)\n",
            "INFO:tensorflow:global_step/sec: 66.2834\n",
            "INFO:tensorflow:loss = 0.0012742088, step = 31600 (1.509 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.3148\n",
            "INFO:tensorflow:loss = 0.0012705616, step = 31700 (1.443 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.1931\n",
            "INFO:tensorflow:loss = 0.0012679889, step = 31800 (1.404 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.3866\n",
            "INFO:tensorflow:loss = 0.0012129952, step = 31900 (1.401 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 32000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 47.0263\n",
            "INFO:tensorflow:loss = 0.0012460247, step = 32000 (2.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.8368\n",
            "INFO:tensorflow:loss = 0.0011867294, step = 32100 (1.373 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.6637\n",
            "INFO:tensorflow:loss = 0.0011398678, step = 32200 (1.376 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.0022\n",
            "INFO:tensorflow:loss = 0.0012416809, step = 32300 (1.409 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.5213\n",
            "INFO:tensorflow:loss = 0.0011625154, step = 32400 (1.418 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.463\n",
            "INFO:tensorflow:loss = 0.0012407079, step = 32500 (1.399 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.7657\n",
            "INFO:tensorflow:loss = 0.0013425327, step = 32600 (1.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.0025\n",
            "INFO:tensorflow:loss = 0.0011790546, step = 32700 (1.471 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.2035\n",
            "INFO:tensorflow:loss = 0.001126817, step = 32800 (1.445 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.7276\n",
            "INFO:tensorflow:loss = 0.0012368667, step = 32900 (1.434 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 33000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 56.0633\n",
            "INFO:tensorflow:loss = 0.0012173399, step = 33000 (1.783 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.4647\n",
            "INFO:tensorflow:loss = 0.0011889606, step = 33100 (1.399 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.63\n",
            "INFO:tensorflow:loss = 0.0011135694, step = 33200 (1.377 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.0458\n",
            "INFO:tensorflow:loss = 0.0012558823, step = 33300 (1.388 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.075\n",
            "INFO:tensorflow:loss = 0.0011999554, step = 33400 (1.427 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.1216\n",
            "INFO:tensorflow:loss = 0.0012565078, step = 33500 (1.368 sec)\n",
            "INFO:tensorflow:global_step/sec: 64.9496\n",
            "INFO:tensorflow:loss = 0.0011737, step = 33600 (1.540 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.876\n",
            "INFO:tensorflow:loss = 0.0011156693, step = 33700 (1.411 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.2103\n",
            "INFO:tensorflow:loss = 0.0012015353, step = 33800 (1.385 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.1846\n",
            "INFO:tensorflow:loss = 0.0012528684, step = 33900 (1.385 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 34000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 55.8328\n",
            "INFO:tensorflow:loss = 0.0011713142, step = 34000 (1.791 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.2096\n",
            "INFO:tensorflow:loss = 0.0012259354, step = 34100 (1.404 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.4825\n",
            "INFO:tensorflow:loss = 0.0011617616, step = 34200 (1.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.3065\n",
            "INFO:tensorflow:loss = 0.0012171981, step = 34300 (1.402 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.6168\n",
            "INFO:tensorflow:loss = 0.0012947536, step = 34400 (1.416 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.6196\n",
            "INFO:tensorflow:loss = 0.0010613941, step = 34500 (1.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.5886\n",
            "INFO:tensorflow:loss = 0.0011523641, step = 34600 (1.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.398\n",
            "INFO:tensorflow:loss = 0.0012514233, step = 34700 (1.421 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.2304\n",
            "INFO:tensorflow:loss = 0.0012408996, step = 34800 (1.444 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.7276\n",
            "INFO:tensorflow:loss = 0.0011948314, step = 34900 (1.414 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 35000 into output/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fcd2ff7be18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fcd2ff7be18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (32, 50)\n",
            "INFO:tensorflow:  name = input_mask, shape = (32, 50)\n",
            "INFO:tensorflow:  name = is_real_example, shape = (32,)\n",
            "INFO:tensorflow:  name = label_ids, shape = (32,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (32, 50)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (128, 512), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (512,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (128, 512), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (512,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (5, 128)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (5,)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-04-28T09:54:02Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from output/model.ckpt-35000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2020-04-28-09:54:03\n",
            "INFO:tensorflow:Saving dict for global step 35000: eval_accuracy = 0.0, global_step = 35000, loss = 0.0\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 35000: output/model.ckpt-35000\n",
            "INFO:tensorflow:Loss for final step: 0.0011846593.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7K73QjGNp_N",
        "outputId": "203ddf76-60c1-4b27-8ec2-177fe907ea07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "ft_evaluator.evaluate_from_file('dataset', checkpoint=\"output/model.ckpt-35000\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 319999\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: 1\n",
            "INFO:tensorflow:tokens: [CLS] miss ##tori ##bla ##ck cool t ##wee ##t apps ra ##z ##r [SEP]\n",
            "INFO:tensorflow:input_ids: 101 3335 29469 28522 3600 4658 1056 28394 2102 18726 10958 2480 2099 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: 2\n",
            "INFO:tensorflow:tokens: [CLS] tian ##nac ##ha ##os know family drama lame next time hang guys like sleep ##over whatever call [SEP]\n",
            "INFO:tensorflow:input_ids: 101 23401 18357 3270 2891 2113 2155 3689 20342 2279 2051 6865 4364 2066 3637 7840 3649 2655 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: 3\n",
            "INFO:tensorflow:tokens: [CLS] school email open geography stuff rev ##ise stupid school [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2082 10373 2330 10505 4933 7065 5562 5236 2082 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: 4\n",
            "INFO:tensorflow:tokens: [CLS] upper airways problem [SEP]\n",
            "INFO:tensorflow:input_ids: 101 3356 13095 3291 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: 5\n",
            "INFO:tensorflow:tokens: [CLS] going miss pastor sermon faith [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2183 3335 9220 18408 4752 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:Writing example 10000 of 319999\n",
            "INFO:tensorflow:Writing example 20000 of 319999\n",
            "INFO:tensorflow:Writing example 30000 of 319999\n",
            "INFO:tensorflow:Writing example 40000 of 319999\n",
            "INFO:tensorflow:Writing example 50000 of 319999\n",
            "INFO:tensorflow:Writing example 60000 of 319999\n",
            "INFO:tensorflow:Writing example 70000 of 319999\n",
            "INFO:tensorflow:Writing example 80000 of 319999\n",
            "INFO:tensorflow:Writing example 90000 of 319999\n",
            "INFO:tensorflow:Writing example 100000 of 319999\n",
            "INFO:tensorflow:Writing example 110000 of 319999\n",
            "INFO:tensorflow:Writing example 120000 of 319999\n",
            "INFO:tensorflow:Writing example 130000 of 319999\n",
            "INFO:tensorflow:Writing example 140000 of 319999\n",
            "INFO:tensorflow:Writing example 150000 of 319999\n",
            "INFO:tensorflow:Writing example 160000 of 319999\n",
            "INFO:tensorflow:Writing example 170000 of 319999\n",
            "INFO:tensorflow:Writing example 180000 of 319999\n",
            "INFO:tensorflow:Writing example 190000 of 319999\n",
            "INFO:tensorflow:Writing example 200000 of 319999\n",
            "INFO:tensorflow:Writing example 210000 of 319999\n",
            "INFO:tensorflow:Writing example 220000 of 319999\n",
            "INFO:tensorflow:Writing example 230000 of 319999\n",
            "INFO:tensorflow:Writing example 240000 of 319999\n",
            "INFO:tensorflow:Writing example 250000 of 319999\n",
            "INFO:tensorflow:Writing example 260000 of 319999\n",
            "INFO:tensorflow:Writing example 270000 of 319999\n",
            "INFO:tensorflow:Writing example 280000 of 319999\n",
            "INFO:tensorflow:Writing example 290000 of 319999\n",
            "INFO:tensorflow:Writing example 300000 of 319999\n",
            "INFO:tensorflow:Writing example 310000 of 319999\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fcd2ff39bf8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fcd2ff39bf8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 50)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 50)\n",
            "INFO:tensorflow:  name = is_real_example, shape = (?,)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 50)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (128, 512), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (512,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (128, 512), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (512,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (5, 128)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (5,)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-04-28T09:57:32Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from output/model.ckpt-35000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Reached iteration 1000, processed 32000 sentences\n",
            "INFO:tensorflow:Reached iteration 2000, processed 64000 sentences\n",
            "INFO:tensorflow:Reached iteration 3000, processed 96000 sentences\n",
            "INFO:tensorflow:Reached iteration 4000, processed 128000 sentences\n",
            "INFO:tensorflow:Reached iteration 5000, processed 160000 sentences\n",
            "INFO:tensorflow:Reached iteration 6000, processed 192000 sentences\n",
            "INFO:tensorflow:Reached iteration 7000, processed 224000 sentences\n",
            "INFO:tensorflow:Reached iteration 8000, processed 256000 sentences\n",
            "INFO:tensorflow:Reached iteration 9000, processed 288000 sentences\n",
            "INFO:tensorflow:Reached iteration 10000, processed 320000 sentences\n",
            "INFO:tensorflow:Finished evaluation at 2020-04-28-09:58:00\n",
            "INFO:tensorflow:Saving dict for global step 35000: eval_accuracy = 0.49841717, global_step = 35000, loss = 4.158586\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 35000: output/model.ckpt-35000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_2zItFFOgtK"
      },
      "source": [
        "Evaluation Metrics: *eval_accuracy = 0.49841717, global_step = 35000, loss = 4.158586* .  Very low scores because we trained the  model on a very tiny BERT model. Please train the model on a larger model here https://github.com/google-research/bert ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDqNgOVBiaQe"
      },
      "source": [
        "## Part of Speech (POS) tagging\n",
        "POS tagging is the process of marking up a word in a corpus to a corresponding part of a speech tag, based on its context and definition. The primary target of Part-of-Speech(POS) tagging is to identify the grammatical group of a given word. Whether it is a NOUN, PRONOUN, ADJECTIVE, VERB, ADVERBS, etc. based on the context. POS Tagging looks for relationships within the sentence and assigns a corresponding tag to the word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhwaf2jig7Uh"
      },
      "source": [
        "sentence = \"This is the  first tweet about Torrens University\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th__BnzGj__l",
        "outputId": "b6fd6371-677a-40e1-df1e-1e7a66f893d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "tokens=nltk.word_tokenize(sentence)\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "['This', 'is', 'the', 'first', 'tweet', 'about', 'Torrens', 'University']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYK3WCTTlPyv",
        "outputId": "bf34d2e7-c2c3-4b42-b615-eb6c28e0fa67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "nltk.pos_tag(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('This', 'DT'),\n",
              " ('is', 'VBZ'),\n",
              " ('the', 'DT'),\n",
              " ('first', 'JJ'),\n",
              " ('tweet', 'NN'),\n",
              " ('about', 'IN'),\n",
              " ('Torrens', 'NNP'),\n",
              " ('University', 'NNP')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbvso1L8ih8P"
      },
      "source": [
        "## Named Entity Recognition (NER) Using SPacy\n",
        "\n",
        "Named entity recognition (NER) is technique in information extraction that seeks to locate and classify named entities in text into pre-defined categories. Such categories  can include names of persons, organizations, locations,time, currency etc.  We'll use [Spacy](https://spacy.io/), a very versatile  Python package  that is designed for  real and production level NLP work. Its a great alternative to NLTK."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgeFXN40p0rd",
        "outputId": "429fe554-282e-462c-dbe7-da59dc2d3c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "import spacy\n",
        "# ​# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (46.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.38.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQyQdoayp70X"
      },
      "source": [
        "bbc_news = (\"HSBC has paused plans to cut 35,000 jobs, saying it does not want to leave staff unable to find work elsewhere during the coronavirus outbreak.\"\n",
        "                             \"The bank announced the cuts in February as part of a massive cost-cutting programme.But boss Noel Quinn said the vast majority  of redundancies \"\n",
        "                             \"would now be put on hold due  to the exceptional circumstances. It came as HSBC reported a 50% fall in profits linked to the pandemic. \"\n",
        "                             \"Pre-tax earnings for the first three months came in at $3.2bn (£2.6bn), down from $6.2bn a year ago.\")\n",
        "\n",
        "document = nlp(bbc_news)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1ZHTMKsuAPm",
        "outputId": "529a1fec-b9d5-4282-fc6c-5ba456c636e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "# Analyze syntax\n",
        "print(\"Noun phrases:\", [chunk.text for chunk in document.noun_chunks])\n",
        "print(\"Verbs:\", [token.lemma_ for token in document if token.pos_ == \"VERB\"])\n",
        "\n",
        "# Find named entities, phrases and concepts\n",
        "for entity in document.ents:\n",
        "    print(entity.text, entity.label_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Noun phrases: ['HSBC', 'plans', '35,000 jobs', 'it', 'staff', 'work', 'the coronavirus outbreak', 'The bank', 'the cuts', 'February', 'part', 'a massive cost-cutting programme', 'boss Noel Quinn', 'the vast majority', 'redundancies', 'hold', 'the exceptional circumstances', 'It', 'HSBC', 'a 50% fall', 'profits', 'the pandemic', 'Pre-tax earnings', 'the first three months']\n",
            "Verbs: ['pause', 'cut', 'say', 'want', 'leave', 'find', 'announce', 'cut', 'say', 'would', 'put', 'come', 'report', 'link', 'come']\n",
            "HSBC ORG\n",
            "35,000 CARDINAL\n",
            "February DATE\n",
            "Noel Quinn PERSON\n",
            "HSBC ORG\n",
            "50% PERCENT\n",
            "the first three months DATE\n",
            "3.2bn MONEY\n",
            "2.6bn MONEY\n",
            "6.2bn MONEY\n",
            "a year ago DATE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_ARtrpDui4J"
      },
      "source": [
        "Spacy's NER model is able to correctly identify categories in the text."
      ]
    }
  ]
}