{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_90FUm8P44e"
      },
      "source": [
        "# Deep Learning (DL) Concepts\n",
        "\n",
        "**Reference:**\n",
        "\n",
        "Zaccone, G., & Karim, M. (2018). Deep Learning with Tensorflow : Explore neural networks and build intelligent systems with python, 2nd edition (2nd ed.) [2nd ed.]. Birmingham: Packt Publishing. (2018). Retrieved April 9, 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUQgntklP-s2"
      },
      "source": [
        "## What is DL and Why the Popularity?\n",
        "\"*Deep learning is a particular kind of machine learning that achieves great power and flexibility by learning to represent the world as a nested hierarchy of concepts, with each concept defined in relation to simpler concepts, and more abstract ones*\" - Ian Googfellow\n",
        "\n",
        "DL is important  when simple Machine Learning (ML) methods are not  effective anymore.  This is  because either the dataset size or complexity is much higher. Although classical ML techniques allow researchers to identify groups, or clusters, of related variables, the accuracy and effectiveness of these methods diminishes with large and high-dimensional datasets.\n",
        "\n",
        "**Example - Adapted from the above reference**\n",
        "\n",
        "\n",
        "```\n",
        "Suppose we want to develop a predictive analytics model, such as an animal recognizer, where our system has to resolve two problems:\n",
        "1.   Classify if an image represents a cat or a dog\n",
        "2.   Cluster dog and cat images\n",
        "\n",
        "If we solve the first problem using a typical ML method, we must define the facial features (ears, eyes, whiskers, and so on), and write a method to identify which features (typically non-linear ) are more important when classifying a particular animal.\n",
        "The second  problem cannot be  solved by classical ML algorithms  such as K-Means as they cannot handle non-linear features.\n",
        "\n",
        "```\n",
        "In summary the  DL Algorithm will solve the  above problem as follows:-\n",
        "\n",
        "```\n",
        "\n",
        "1. Identify the edges that are most relevant when clustering cats or dogs.\n",
        "\n",
        "2. Build on the edges hierarchically to find the various combinations of shapes and edges\n",
        "\n",
        "3. Decides which of the built up features can be used to classify the animal, then takes out the label column and performs unsupervised training using an autoencoder, before doing the clustering.\n",
        "```\n",
        "\n",
        "**Why the Popularity?**\n",
        "The  below  image captions, the need for DL driven solutions in todays  data problems.\n",
        "\n",
        "![Why Deep Learning?](https://miro.medium.com/max/1400/1*x0nnGPQfjuVhUne0BDsP5A.png)\n",
        "\n",
        "Source: https://bit.ly/3c89eUK\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-q5AIG-QPdK"
      },
      "source": [
        "## Definitions and  Concept"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whgFA4BfQUFF"
      },
      "source": [
        "### Biological Nuerons\n",
        "\n",
        "DL systems  mimic biological systems and most specifically the  brain achitecture. Biological neurons  receive short electrical impulses called signals  from other neurons and in response fire their own signals. This forms the basis of  how artificial neurons work in DL systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR7-CSMqQdL0"
      },
      "source": [
        "### Artificial Neurons\n",
        "\n",
        "The idea of  artificial neurons was inspired by the biological ones. Similar to  biological neurons, they consist of  the following: -\n",
        "```\n",
        "*   One or more incoming connections, with the task of collecting numerical signals from other neurons: each connection is assigned a weight that will be used to consider each signal sent.\n",
        "*   One or more output connections that carry the signal to the other neurons.\n",
        "*   An activation function, which determines the numerical value of the output signal, based on the signals received from the input connections with other neurons, and suitably collected from the weights associated with each received signal, and the activation threshold of the neuron itself:\n",
        "```\n",
        "Therefore, neural networks  in essence are  composed of *input, hidden*, and *output* layers — all of which are composed of “nodes”.\n",
        "\n",
        "Input layers take in a numerical representation of data (e.g. images with pixel specifications), output layers output predictions, while hidden layers are correlated with most of the computation.\n",
        "\n",
        "The  below image details the structures of the two neurons. ![Biological and Artificial Neuron Structure](https://drive.google.com/uc?id=1OkeAvMK53a9h-erZOFJ1H1YSlt4T6tUe)\n",
        "\n",
        "A biological and artificial neuron (Source: https://bit.ly/3coxaTO)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNn2Q6hAQma6"
      },
      "source": [
        "### Activation Functions\n",
        "\n",
        "In an Neural Network (NN), inputs are numerical representations e.g.  images with pixel specs output layers output predictions, while hidden layers are correlated with most of the computation. Information is  passed between the layers through an **activation function.** It actually map the resulting values  between 0 to 1 or -1 to 1 depending  upon the function.\n",
        "\n",
        "They are divided into two categories: -\n",
        "\n",
        "\n",
        "1.   Linear Activation Functions\n",
        "2.   Non-linear Activation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6mKdQtoVdRk"
      },
      "source": [
        "####  Linear Activation Functions\n",
        "\n",
        "Function is  linear and the output cannot be  confined to a range.\n",
        "\n",
        "**Equation:**$ f(x) = x$\n",
        "\n",
        "**Range:**$ -inf $ to $inf$\n",
        "\n",
        "**Downside:** Not very useful with increased complexity or various parameters of usual data that is fed to the neural network.\n",
        "\n",
        "![Linear Activation Function](https://drive.google.com/uc?id=1aQYMhxqMsgQQxGK9-vJ_EJ4CE4aQuUDa)\n",
        "Linear Activation Function Image. Source: https://bit.ly/3be8DzD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEYbMUkoVdtV"
      },
      "source": [
        "####  Non-linear Activation Function\n",
        "They are the most used functions as they make it easy for a model to generalize or adapt with variety of data and to differentiate between the output.\n",
        "\n",
        "![Non-Linear Activation Function](https://drive.google.com/uc?id=1RbE9G2rXkkUwaaVGtGGXLPhF4UYVgLsd)\n",
        "\n",
        "Non-Linear Activation Function Graph. Source: https://bit.ly/3be8DzD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2emQk0-58zPj"
      },
      "source": [
        "#####  Sigmoid or Logistic Activation Function\n",
        "\n",
        "The function is  applicable  in cases where the output is a probability  i.e. ranges from 0 to 1 as it  exists  between these values.\n",
        "\n",
        "Its in the form of $f(x) = \\frac{1} {1 + exp(-x)}$\n",
        "\n",
        "**Downsides:**\n",
        "\n",
        "```\n",
        "1.   Sigmoids have slow convergence.\n",
        "2.   Sigmoids saturate and kill gradients.\n",
        "3.   Vanishing gradient problem\n",
        "4.   Makes optimization hard as gradient  updates go too far in different directions.\n",
        "```\n",
        "However, for multiclass classification, the softmax function is  used as its  more generalized.\n",
        "\n",
        "![Sigmoid  Function](https://drive.google.com/uc?id=1LHGUwSzIMFkWnQIxkd8wUwhQpTBt0u4t)\n",
        "\n",
        "Sigmoid  Function Graph. Source: https://bit.ly/3be8DzD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRSIoB-J87zx"
      },
      "source": [
        "##### ReLU (Rectified Linear Unit) Activation Function\n",
        "\n",
        "Its  the most used activation function at the moment,since it's used in almost all the convolutional neural networks and  other deep learning algorithms.\n",
        "\n",
        "![ReLU](https://drive.google.com/uc?id=17Zr-QZo0eG6URCsF-w0wGOP0la46TEo9)\n",
        "\n",
        "ReLU Activation Function Graph. Source: https://bit.ly/3be8DzD\n",
        "\n",
        "**Range:** $0$ to $inf$\n",
        "\n",
        "\n",
        "Its represented as $R(x) = max(0,x)$ i.e if $x < 0$ , $R(x) = 0$ and if $x >= 0$ , $R(x) = x$.\n",
        "\n",
        "Its a simple and efficient  function thus avoids and rectifies **vanishing gradient** problem.\n",
        "\n",
        "**Downside:** Should only be used within hidden layers of an NN model. Hence  a **Softmax**  function for  classification problem should be  used in the output layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07R7Kdwu89hd"
      },
      "source": [
        "##### Tanh or hyperbolic tangent Activation Function\n",
        "\n",
        "Tanh is more like the  Sigmoid  function but better in the sense that its sigmoidal but ranges from (-1 to 1.\n",
        "\n",
        "Its represenred as $f(x) = \\frac{1 — exp(-2x)} {1 + exp(-2x)}$\n",
        "\n",
        "\n",
        "![Tahn](https://drive.google.com/uc?id=15gKP5g4b3aTXyWy4K-ZHhgi0X40bqMTG)\n",
        "\n",
        "Tanh Activation Function Graph. Source: https://bit.ly/3be8DzD\n",
        "\n",
        "The tanh function is mainly used classification between two classes.  Both tanh and logistic sigmoid activation functions are used in feed-forward nets.\n",
        "\n",
        "Range: Output ranges between $-1$ to $1$. This  means optimization is  easier though still has the *vanishing gradient* problem.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMfkmFW6RBe6"
      },
      "source": [
        "# Introduction to TensorFlow\n",
        "\n",
        "TensorFlow (TF) is an end-to-end open source framework from Google for scientific and numerical computation using data flow graphs that stand for TensorFlow's execution model. TF helps experts perform advanced resource  intensive training on their data for modelling and predictions.\n",
        "\n",
        "More information can be found [here](https://www.tensorflow.org/)\n",
        "\n",
        "\n",
        "Instructions on its installation and  configuration can be found **[here](https://www.tensorflow.org/install)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMo-4YyLRYuM"
      },
      "source": [
        "## TensorFlow Computation Graphs\n",
        "\n",
        "When performing a complex operation with TF e.g. clustering compex datasets, TF internally represents its computation using a data flow graph called **Computation graph** that is directed.\n",
        "\n",
        "It consists of:-\n",
        "```\n",
        "1.   A set of nodes, each one representing an operation\n",
        "2.   A set of directed arcs, each one representing the data on which the operations are performed\n",
        "```\n",
        "TF edges:\n",
        "```\n",
        "1.   Normal - They carry the data structures between the nodes. One node becomes the input of the other.\n",
        "2.   Special -  This edge doesn't carry values, but only represents a control dependency between two nodes\n",
        "```\n",
        "Main components of a TF graph:-\n",
        "```\n",
        "1.   Variables - Contain values for weights and biases between TF sessions.\n",
        "2.   Tensors - A set of values that pass between nodes to perform operations.\n",
        "3.   Placeholders - Used to send data between the program and the TensorFlow graph.\n",
        "4.   Session - When a session is started, TensorFlow automatically calculates gradients for all the operations in the graph and uses them in a chain rule\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXsaAZOTXX9r"
      },
      "source": [
        "## TensorFlow Code Structure\n",
        "\n",
        "A TF program is normally divided in the below phases:-\n",
        "\n",
        "\n",
        "1.   Construction of the computational graph.\n",
        "2.   Creation of a session.\n",
        "3.   Running a session\n",
        "4.   Computation for data collection and analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAvkDx3TJBqp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e90f03b-8c44-45df-b827-cb671a2e0fbc"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Launch the graph in a session.\n",
        "with tf.compat.v1.Session() as ses:\n",
        "\n",
        "     # Build a graph.\n",
        "     a = tf.constant(5.0)\n",
        "     b = tf.constant(6.0)\n",
        "     c = a * b\n",
        "\n",
        "     # Evaluate the tensor `c`.\n",
        "     print(ses.run(c))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niO7W9RNVvvr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bf210014-448a-48b0-adce-e00f5fa3de49"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#Placeholders\n",
        "# Build a graph and create session passing the graph\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    x = tf.compat.v1.placeholder(tf.float32, name=\"x\")\n",
        "    y = tf.compat.v1.placeholder(tf.float32, name=\"y\")\n",
        "    z = x * y\n",
        "    print(sess.run(z,feed_dict={x:8, y:9}))  #Put the values 8,9 on the placeholders x,y and  execute the graph\n",
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWlEh1JNRdUv"
      },
      "source": [
        "## TensorFlow Data Model\n",
        "The data model in TF is represented by tensors. A tensor in TF identifies a multidimensional numerical array.\n",
        "\n",
        "As per [Wikipedia](https://en.wikipedia.org/wiki/Tensor):-\n",
        "\n",
        "*Tensors are geometric objects that describe linear relations between geometric vectors, scalars, and other tensors. Elementary examples of such relations include the dot product, the cross product, and linear maps. Geometric vectors, often used in physics and engineering applications, and scalars themselves are also tensors.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq6jfV16ikGb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "3df661d8-3f35-46f2-cff1-d395a9f0174f"
      },
      "source": [
        "X = [[2.0, 4.0], [6.0, 8.0]] # X is a list of lists\n",
        "Y = np.array([[2.0, 4.0], [6.0, 6.0]], dtype=np.float32)#Y is a Numpy array\n",
        "Z = tf.constant([[2.0, 4.0], [6.0, 8.0]]) # Z is a tensor\n",
        "\n",
        "print(type(X))\n",
        "print(type(Y))\n",
        "print(type(Z))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OI93Xgsi7sM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3215e0a5-4c68-4bbe-a944-843da172c763"
      },
      "source": [
        "t1 = tf.convert_to_tensor(X, dtype=tf.float32)\n",
        "t2 = tf.convert_to_tensor(Z, dtype=tf.float32)\n",
        "print(type(t1))\n",
        "print(type(t2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IdkiehcRoLf"
      },
      "source": [
        "## Visualising Computations via TensorBoard\n",
        "\n",
        "**TensorBoard** is a framework designed for analyzing and debugging predictive models. TensorBoard uses the so-called summaries to view the parameters of the model: once a TensorFlow code is executed, we can call TensorBoard to view the summaries in a GUI.\n",
        "\n",
        "We'll have a look at one it  in later experiments.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFp73xGLUqm1"
      },
      "source": [
        "# Multi-Layer Perceptron (MLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8QzAgCkVMex"
      },
      "source": [
        "## Artificial Neural Network (ANN) with Multiple Layers of Perceptron.\n",
        "\n",
        "A perceptron is a single neuron model that was a precursor to larger neural networks. Multilayer perceptron comprises of a combinations of neurons.\n",
        "\n",
        "For a simple example of a three-layer network, first layer will be the input layer and last will be output layer and middle layer will be called hidden layer. Data is input into the input layer and take the output from the output layer. An example using the Bank Marketing Dataset  is below:-\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yUkRCRa0ClI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "750f599a-9125-439f-8f32-633d1a1850dc"
      },
      "source": [
        "#Colab specific. Encourage to use Colab if you have no GPU access. TF works great on GPU\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dC5b-pUyM-B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0eca4df7-41f0-4183-b92f-85fc8e0c143e"
      },
      "source": [
        "%cd gdrive/My Drive/Torrens/DeepLearning_ps3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'gdrive/My Drive/Torrens/Computer Vision'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30y1fK4kjhEj"
      },
      "source": [
        "import pandas as pd\n",
        "## Dataset\n",
        "data = pd.read_csv('train.csv',sep=',',header='infer')## This will work straighaway if the  dataset and notebook is in the same folder\n",
        "y = pd.get_dummies(data['y'], columns = ['y'], prefix = ['y'], drop_first = True) #Convert categorical variable into dummy/indicator variables.\n",
        "data.drop(columns=['id'],inplace=True) # since pandas create id column automatically, we don't need id as a separate column\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K3ppGC2xyDO"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder #encodes the labels with a value between 0 and n_classes-1 where n is no. of distinct labels.\n",
        "label_encoder = LabelEncoder() # Instantiate sklearn LabelEncoder\n",
        "\n",
        "data[\"education_code\"] = label_encoder.fit_transform(data[\"education\"]) # Encoding education column\n",
        "data['job_code']      = label_encoder.fit_transform(data['job'])  # Encoding job column\n",
        "data['default_code']  = label_encoder.fit_transform(data['default']) # Encoding default column\n",
        "data['housing_code']  = label_encoder.fit_transform(data['housing']) # Encoding housing column\n",
        "data['loan_code']     = label_encoder.fit_transform(data['loan']) # Encoding loan column\n",
        "data['contact_code']     = label_encoder.fit_transform(data['contact']) # Encoding contact column\n",
        "data['poutcome_code']     = label_encoder.fit_transform(data['poutcome']) # Encoding poutcome column\n",
        "data[\"marital_code\"] = label_encoder.fit_transform(data[\"marital\"]) # Encoding marital column\n",
        "\n",
        "# Drop columns that we dont need. Only coded ones are  needed\n",
        "data=data.drop(['job','marital','education','housing','loan','contact','poutcome','y','day_of_week','month','default']\n",
        "             ,axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv05QfYCzc52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "dda34c37-187e-46e8-c491-92a700301318"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>emp.var.rate</th>\n",
              "      <th>cons.price.idx</th>\n",
              "      <th>cons.conf.idx</th>\n",
              "      <th>euribor3m</th>\n",
              "      <th>nr.employed</th>\n",
              "      <th>education_code</th>\n",
              "      <th>job_code</th>\n",
              "      <th>default_code</th>\n",
              "      <th>housing_code</th>\n",
              "      <th>loan_code</th>\n",
              "      <th>contact_code</th>\n",
              "      <th>poutcome_code</th>\n",
              "      <th>marital_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.856</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>93.918</td>\n",
              "      <td>-42.7</td>\n",
              "      <td>4.968</td>\n",
              "      <td>5228.1</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>2</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>92.893</td>\n",
              "      <td>-46.2</td>\n",
              "      <td>1.327</td>\n",
              "      <td>5099.1</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>92.893</td>\n",
              "      <td>-46.2</td>\n",
              "      <td>1.327</td>\n",
              "      <td>5099.1</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>93.918</td>\n",
              "      <td>-42.7</td>\n",
              "      <td>4.962</td>\n",
              "      <td>5228.1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  campaign  pdays  ...  contact_code  poutcome_code  marital_code\n",
              "0   36         1    999  ...             1              1             1\n",
              "1   34         3    999  ...             0              1             1\n",
              "2   28         2    999  ...             0              1             2\n",
              "3   36         1    999  ...             0              0             2\n",
              "4   53         2    999  ...             0              1             1\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLzj876GzkWL"
      },
      "source": [
        "### MLP NN Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2TTVu7Vzi7r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b2459ca2-2c96-4dde-e21f-6385ba03c4d1"
      },
      "source": [
        "#Always great normalizing the data before modellin\n",
        "X=data.copy()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "# Fit the Training Data\n",
        "scaler.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HZQlTgV0F3i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "6d36d8cf-db3b-4935-bf30-bf2051b8c01a"
      },
      "source": [
        "#MLP classifier models take at least 3 layers .\n",
        "#For simplicity sake we shall be taking 3 layers — ( 13 input, 10 hidden & 2 output) with maximum iterations of 1000.\n",
        "#Parameters  can still be  fine tuned later but this should  be great for a start\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(13,10,2),max_iter=1000)\n",
        "mlp.fit(X_train,y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(13, 10, 2), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhVaw2V_2ATD"
      },
      "source": [
        "### Model Validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypkVZWmq2VxM"
      },
      "source": [
        "#### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UC9NBth18Ml",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b1276a5f-26bb-4d97-d004-6aed4bee3b1b"
      },
      "source": [
        "preds_MLP =mlp.predict(X_test)\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(confusion_matrix(y_test,preds_MLP))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7877  139]\n",
            " [ 785  261]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trXkzWEv2Pi9"
      },
      "source": [
        "#### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7Zs3Z412QYr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "33affbac-8f23-4799-ee92-135bca5bb518"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,preds_MLP)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8980357536967557"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRL56S86UxbO"
      },
      "source": [
        "# Convolutional Neural Networks (ConvNet/CNN)\n",
        "\n",
        "Reference:\n",
        "https://cs231n.github.io/convolutional-networks/\n",
        "\n",
        "CNN is a DL algorithm capable of taking input as an image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other.\n",
        "\n",
        "The architecture performs a better fitting to the image dataset due to the reduction in the number of parameters involved and reusability of weights. Therefore, ConvNets perform quite well on image datasets.\n",
        "\n",
        "![CNN Architecture](https://drive.google.com/uc?id=1Jvl1KbPD1g05Q9WVPGCycKmCUBTlUZ4v)\n",
        "\n",
        "CNN Framework. Source: https://bit.ly/3fq2bc1\n",
        "\n",
        "\n",
        "3 Layers form the  CNN framework:-\n",
        "\n",
        "1. Convolutional Layer\n",
        "2. Pooling Layer\n",
        "3. Fully-Connected Layer\n",
        "\n",
        "Every Layer in the CNN architecture transforms an input 3D volume to an output 3D volume with some differentiable function that may or may not have parameters.\n",
        "\n",
        "Using  the  [**CIFAR-10 dataset**](https://www.cs.toronto.edu/~kriz/cifar.html) as  an example, a simple CNN classification architecture could  have these layers [Input - Convolutional - RELU - Pooling - Fully Connected Layer]\n",
        "\n",
        "![CIFAR-10 Dataset](https://drive.google.com/uc?id=1IJRPaQTRHKWMO88mbHLPuAwHL72Rg_29)\n",
        "\n",
        "Source: https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "1.   Input [32x32x3] - Holds raw pixel values of  RGB images.  Dimensions (Width 32, Height 32) and  3 color channels i.e. R,G,B.\n",
        "2.   Convolutional - Compute the output of neurons that are connected to local regions in the input. Computation is  the dot product between their weights and a small region they are connected to in the input volume. Result in volume could be[32x32x12] if 12  filters are used.\n",
        "3.   RELU - Applies elementwise activation function, such as the $max(0,x)$ thresholding at zero. This leaves the size of the volume unchanged ([32x32x12]).\n",
        "4.   Pooling - Performs downsampling operation along the width and height. Result is [16x16x12].\n",
        "5.   Fully Connected Layer - Computes class scores.Results in volume of size [1x1x10]. 10 corresponds to the categories of the images.\n",
        "\n",
        "The above process in test data is summarized in the below image.\n",
        "\n",
        "![CNN Architecture](https://drive.google.com/uc?id=13dK13fZmlp1e5Jmw0FpYzMQWd1mvPyED)\n",
        "\n",
        "Source: http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture6.pdf\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSRMidCpgiqX"
      },
      "source": [
        "### Importing the Dataset\n",
        "\n",
        "The [**MNIST Database**](http://yann.lecun.com/exdb/mnist/) of handwritten digits is what we'll use here. The [dataset](https://en.wikipedia.org/wiki/MNIST_database) has 60,000 training images and 10,000 testing images taken from American Census Bureau employees and American high school students. Sample  writings looks like the below:-\n",
        "\n",
        "![MNIST Handwriting Sample](https://drive.google.com/uc?id=1e2aCdsYH3EDi_Ff-0VwytIlMfXEF-PrR)\n",
        "\n",
        "Sample Digits from [MNIST dataset](http://yann.lecun.com/exdb/mnist)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXMl4wYpi7it"
      },
      "source": [
        "#import relevant  packages\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPf_xfSPj-JS"
      },
      "source": [
        "#Training and test set\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B41tIKuukgqi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40246ea3-8bbf-4195-f6ec-d22a04eb8103"
      },
      "source": [
        "#Sample image\n",
        "image_index = 4774 # You may select anything up to 60,000. Thats the size of  the training set\n",
        "print(train_images[image_index]) # The label is 7\n",
        "plt.imshow(train_images[image_index], cmap='Greys')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  11 140\n",
            "  223 125   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  84 217 233\n",
            "  253 145   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  21 120 223 239 114  37\n",
            "  254 145   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  11  94 135 238 254 191  42   0  37\n",
            "  253 125   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1  89 171 254 253 228 103  42   0   0   0  68\n",
            "  253  42   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  84 119 180 129  46  21   0   0   0   0   0 213\n",
            "  191   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  32 255\n",
            "   99   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 176 233\n",
            "   16   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  37 244  94\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 150 253  11\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  11 234 160   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 243  26   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  16 233 135   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  99 253  52   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 171 191   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  63 254 109   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 105 249  73   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 207 197   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  37 254 145   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  37 253 125   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fac9e8d7dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBGEHkiDsQBKEHUiCsANJEHYgif8DsZnv1hGw9NAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpFZofef5oPt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c7e03aa4-0d2d-4d26-a086-f247ce466d90"
      },
      "source": [
        "train_images.shape #Size is 28 by 28 and 60,000 is the  training  set size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scIaKxOTgr_l"
      },
      "source": [
        "### Reshaping and Normalizing Images\n",
        "\n",
        "4-dims numpy arrays are needed to use the  dataset with Keras API yet we have  3 -dimensional one i.e. [60000,28,28].\n",
        "To normalize images for input in the CNN, RGB codes are divided by 255(maximum RGB code minus the minimum RGB code)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrE1kLdRkU-7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1c29d1bd-c8c9-43aa-e3c1-96b0577d362e"
      },
      "source": [
        "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
        "\n",
        "\n",
        "# Making sure that the values are float so that we can get decimal points after division\n",
        "train_images = train_images.astype('float32')\n",
        "test_images = test_images.astype('float32')\n",
        "\n",
        "# ----------Normalizing the RGB codes by dividing it to the max RGB value. -------------\n",
        "train_images /= 255\n",
        "test_images /= 255\n",
        "\n",
        "print('Training Set Shape:', train_images.shape)\n",
        "print('Number of images in training set', train_images.shape[0])\n",
        "print('Number of images in test set', test_images.shape[0])\n",
        "\n",
        "# # Normalize pixel values to be between 0 and 1\n",
        "# train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Shape: (60000, 28, 28, 1)\n",
            "Number of images in training set 60000\n",
            "Number of images in test set 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_AsEnfcgz6Z"
      },
      "source": [
        "### CNN Modelling\n",
        "\n",
        "The  model is built using the Keras API with either Theano or  Tensorflow backends. We'll use  Keras APIs in building the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX8JrtfpAG5E"
      },
      "source": [
        "# Importing the required Keras modules containing model and layers. Using Tensorflow  backend\n",
        "from tensorflow.python.keras.layers import Dense,Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "from tensorflow.python.keras import Sequential\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUfv_5ugAJMR"
      },
      "source": [
        "#Create a sequential model then add layers\n",
        "input_shp= (28, 28, 1) #Input shape of  the dataset as above\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shp))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "cnn_model.add(Dense(128, activation=tf.nn.relu))\n",
        "#cnn_model.add(Dropout(0.2))\n",
        "cnn_model.add(Dense(10,activation=tf.nn.softmax))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c05Ra2qGCrOj"
      },
      "source": [
        "You are  allowed to play around with the values. Dense  layer must have 10 neurons as thats the  number of  possible output classes  (0 to 9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHEKr-Q4g42u"
      },
      "source": [
        "### Model Fitting and  Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13BOI14CDQ_W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "ad0dbdc5-8d6f-4e29-bb93-d1f2981525c9"
      },
      "source": [
        "cnn_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "cnn_model.fit(x=train_images,y=train_labels, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.1773 - accuracy: 0.9470\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0607 - accuracy: 0.9811\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0389 - accuracy: 0.9872\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0258 - accuracy: 0.9916\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0188 - accuracy: 0.9935\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0127 - accuracy: 0.9956\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0121 - accuracy: 0.9958\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0088 - accuracy: 0.9970\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0085 - accuracy: 0.9972\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0073 - accuracy: 0.9976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1a580fe470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba35mcmKDo9A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6e603cb8-9359-4f4d-f8cf-77b010f8f7c1"
      },
      "source": [
        "#Evaluating the  model on test data\n",
        "cnn_model.evaluate(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0895 - accuracy: 0.9825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0894746482372284, 0.9825000166893005]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ8zx9SrFSfd"
      },
      "source": [
        "Results show a 98.25% accuracy which is quite good with just 10 epochs. All in all, it critical systems like autonomous cars,a 0.1% error can be lead to a catastrophy. The model needs to be  as accurate as possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPkBvOQuFLlZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "fc5f4ba3-e23c-484b-9be5-d00d7753c31f"
      },
      "source": [
        "#Quick trial on  a known value\n",
        "image_index_2 = 309\n",
        "plt.imshow(test_images[image_index_2].reshape(28, 28),cmap='Greys')\n",
        "prediction = cnn_model.predict(test_images[image_index_2].reshape(1, 28, 28, 1))\n",
        "print(\"Model Predicted:\",prediction.argmax())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Predicted: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdHLz86BU4QZ"
      },
      "source": [
        "# Recurrent Neural Networks (RNN)\n",
        "\n",
        "RNNs process in sequence i.e. one element at a time  while retaining  a memory called a **state** of what had previously come  in the sequence. Recurrent in essence  meanss that the output at the current time step, becomes the  input to the next time step. Thus, the model considers  not just the immediate input, but  remembers preceding elements.\n",
        "\n",
        "Therefore, RNNs learn *long-term dependencies* in a sequence which means it can take the entire context into account when making a prediction regardless of whether its a word or  classification etc.\n",
        "\n",
        "Recurrent means the output at the current time step becomes the input to the next time step. At each element of the sequence, the model considers not just the current input, but what it remembers about the preceding elements.\n",
        "\n",
        "**Memory cells** such as Long Short-Term Memory (LSTM) are the heart of RNNs.  LSTMs  maintain thee cell state ensuring the  signal is  not lost as the  sequence is processed. At each time step the LSTM considers the current word, the carry, and the cell state. Anatomy of an LSTM is  as in the below  figure.\n",
        "\n",
        "![LSTM Structure](https://drive.google.com/uc?id=1TVE6IaqOmhgviZQ5u9rI-eytAjKW0lRi)\n",
        "\n",
        "LSTM (Long Short Term Memory) Cell. Source: https://bit.ly/2WgYjTo\n",
        "\n",
        "We'll implement an RNN with LSTM as the  memory cell on the same MNIST dataset that we used  for  CNNs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLWU_8dbQoqD"
      },
      "source": [
        "### Normalizing Images\n",
        "\n",
        "4-dims numpy arrays are needed to use the  dataset with Keras API yet we have  3 -dimensional one i.e. [60000,28,28].\n",
        "To normalize images for input in the CNN, RGB codes are divided by 255(maximum RGB code minus the minimum RGB code)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KwQXidpQvLM"
      },
      "source": [
        "# Making sure that the values are float so that we can get decimal points after division\n",
        "train_images = train_images.astype('float32')\n",
        "test_images = test_images.astype('float32')\n",
        "\n",
        "# ----------Normalizing the RGB codes by dividing it to the max RGB value. -------------\n",
        "train_images /= 255\n",
        "test_images /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6deTDfceRHJq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e03ea2dd-117a-41c9-b3f2-197405084f5d"
      },
      "source": [
        "print(train_images[0].shape) #Dimensions of a sample image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSyIMfA7RhHM"
      },
      "source": [
        "### RNN Modelling with LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQYHDLV8RexI"
      },
      "source": [
        "from tensorflow.python.keras.layers import Dense,Dropout,LSTM\n",
        "from tensorflow.python.keras import Sequential\n",
        "\n",
        "# building the model\n",
        "#Create a sequential model then add layers\n",
        "RNN_LSTM = Sequential()\n",
        "RNN_LSTM.add(LSTM(128, input_shape=(train_images.shape[1:]), activation='relu', return_sequences=True))\n",
        "RNN_LSTM.add(Dropout(0.2))\n",
        "\n",
        "RNN_LSTM.add(LSTM(128, activation='relu'))\n",
        "RNN_LSTM.add(Dropout(0.2))\n",
        "\n",
        "RNN_LSTM.add(Dense(32, activation='relu'))\n",
        "RNN_LSTM.add(Dropout(0.2))\n",
        "\n",
        "RNN_LSTM.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erRgosh0SKLz"
      },
      "source": [
        "optzer = tf.keras.optimizers.Adam(lr=1e-3, decay=1e-5)\n",
        "RNN_LSTM.compile(loss='sparse_categorical_crossentropy', optimizer=optzer,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJAFVOaBSSHv"
      },
      "source": [
        "### Model Fitting and  Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10EGTfXXOj82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "a75027e3-4ee2-488c-8e35-3792984f29f3"
      },
      "source": [
        "RNN_LSTM.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 115s 61ms/step - loss: 0.6385 - accuracy: 0.7944 - val_loss: 0.1528 - val_accuracy: 0.9508\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 115s 61ms/step - loss: 0.1565 - accuracy: 0.9578 - val_loss: 0.0882 - val_accuracy: 0.9769\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 115s 61ms/step - loss: 0.1086 - accuracy: 0.9709 - val_loss: 0.0994 - val_accuracy: 0.9733\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 115s 61ms/step - loss: 0.0886 - accuracy: 0.9770 - val_loss: 0.0671 - val_accuracy: 0.9800\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 116s 62ms/step - loss: 0.0712 - accuracy: 0.9816 - val_loss: 0.0591 - val_accuracy: 0.9848\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 115s 62ms/step - loss: 0.0625 - accuracy: 0.9834 - val_loss: 0.0606 - val_accuracy: 0.9837\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 116s 62ms/step - loss: 0.0538 - accuracy: 0.9856 - val_loss: 0.0485 - val_accuracy: 0.9874\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 116s 62ms/step - loss: 0.0462 - accuracy: 0.9876 - val_loss: 0.0383 - val_accuracy: 0.9902\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 116s 62ms/step - loss: 0.0394 - accuracy: 0.9894 - val_loss: 0.0584 - val_accuracy: 0.9878\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 116s 62ms/step - loss: 0.0375 - accuracy: 0.9901 - val_loss: 0.0369 - val_accuracy: 0.9893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1a5c626d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5FbK4NYa_6N"
      },
      "source": [
        "Results show a 98.93% validation accuracy which is quite good with 10 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkFMytixU5ed"
      },
      "source": [
        "# Optimization\n",
        "\n",
        "Overfitting in NNs is  a major issue. Therefore, models need to be  optimized in such a way that they overcome  this  problem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Wp--7cWlbRN"
      },
      "source": [
        "## Dropout\n",
        "\n",
        "One  effective way of  dealing with overfitting is  called  “**dropout**”. Dropout ignores considering  some neurons during a particular forward or backward pass. Therefore, at each training stage, nodes  are either dropped out of the NN with probability ${1-p}$ or kept with probability $p$.  This leaves a reduced network like in the below image.\n",
        "![Dropout in Neural Networks](https://drive.google.com/uc?id=1biM_k29LE8VRe2M836lec6A_eY_CkpSv)\n",
        "\n",
        "Source: https://bit.ly/3cf2Paz\n",
        "\n",
        "In essence, dropout roughly doubles the number of  iterations needed to converge. It also forces the model to learn more robust features.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrMD6ZKiVgdX"
      },
      "source": [
        "### CNN modification\n",
        "\n",
        "We'll look at adding dropout to the CNN model with MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-Ha0pi9oAqc"
      },
      "source": [
        "from tensorflow.python.keras.layers import Dense,Convolution2D, Dropout, Flatten, MaxPooling2D, Activation\n",
        "import time\n",
        "\n",
        "# #Create a sequential model then add more layers. Remember to rerun CNN modeling related experiments first\n",
        "input_shp= (28, 28, 1) #Input shape of  the dataset as above\n",
        "cnn_model_mod = Sequential()\n",
        "cnn_model_mod.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shp))\n",
        "cnn_model_mod.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_model_mod.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "cnn_model_mod.add(Dense(128, activation=tf.nn.relu))\n",
        "#Add dropout\n",
        "cnn_model_mod.add(Dropout(0.5))#50% chance a node will be dropped.\n",
        "cnn_model_mod.add(Dense(10,activation=tf.nn.softmax))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4lrZbDRqjOU"
      },
      "source": [
        "cnn_model_mod.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLQ-V9XYuXiO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "1cdbde92-965b-4ec1-e950-c42abf7bc405"
      },
      "source": [
        "start = time.time()\n",
        "cnn_model_mod.fit(x=train_images,y=train_labels, epochs=10)\n",
        "#cnn_model_modified_info  = cnn_model_modified.fit(train_images, train_labels, batch_size=128,nb_epoch=10, verbose=0, validation_split=0.2)\n",
        "end = time.time()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.2962 - accuracy: 0.9110\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.1457 - accuracy: 0.9555\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.1148 - accuracy: 0.9657\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0954 - accuracy: 0.9698\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0828 - accuracy: 0.9739\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0750 - accuracy: 0.9758\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 31s 16ms/step - loss: 0.0693 - accuracy: 0.9776\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0598 - accuracy: 0.9803\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0571 - accuracy: 0.9813\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0541 - accuracy: 0.9822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-K7oR_o0C7S"
      },
      "source": [
        "Model accuracy is 98.22%. Slighly lower than the original model without dropout. With addition of  more convolutional layers to the  original model, dropout  effect would  have been more evident."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h6-3RZY0hrk"
      },
      "source": [
        "# Exercise\n",
        "\n",
        "Using the  above example for referencing, develop a modified CNN model, adding 2 more convolutional layers and two dropout layers of varied dropout values. Compare the model's performance with the original CNNs."
      ]
    }
  ]
}