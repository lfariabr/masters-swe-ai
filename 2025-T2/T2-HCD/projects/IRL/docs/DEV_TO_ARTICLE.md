# **From Academic Research to Production-Ready AI Governance: Building the Intelligent Rate Limiting System**

**Tags:** #ai #machinelearning #node #graphql

---

***Notes:***
To avoid fatigue, insert:
- Architecture diagram
- IRL explanation screenshot
- System diagram (ASCII box diagram converted to an image)
- A short animated GIF of your dashboard
- Sequence diagrams

---

> "The design choices we make today will determine whether autonomous AI amplifies human capabilityâ€”or undermines it."

What happens when you give an AI agent your credit card and tell it to "solve this problem autonomously"? For one developer, it meant waking up to a **$50,000 AWS bill**.

That's not a hypothetical horror story. It's a real incident documented in my researchâ€”and it's the reason I spent the last trimester building the **Intelligent Rate Limiting (IRL) System** at Torrens University Australia.

---

## The Academic Journey That Led Here

---

### Assessment 1: The Spark 
> Outcome: AI Recommendation Systems

My journey into AI governance started innocently enough with a research presentation on AI recommendation systems. I explored how platforms like Netflix and Spotify shape our choicesâ€”but also how they can trap us in filter bubbles.

**The insight**: When AI systems lack transparency and human oversight, they undermine user agency.

---

### Assessment 2: Identifying the Problem 
> Outcome: Agentic AI Crisis

For my second assessment, I dove deep into the emerging world of **Agentic AI**â€”autonomous agents like AutoGPT, Devin, and GPT-Engineer that don't wait for commands and *act independently*.

**The 2000-word report** uncovered four critical failure modes:

1. **Technical**: Cascading API failures, runaway costs ($15k-$50k overnight bills), DDoS-like behavior
2. **Environmental**: Continuous workloads generating 800kg COâ‚‚/month with zero carbon awareness
3. **Human**: Over 47,000 Stack Overflow questions showing developers confused by opaque throttling
4. **Ethical**: Accountability diffusionâ€”who's responsible when an autonomous agent causes harm?

Current solutions? **Generic HTTP 429 errors** with zero context, zero fairness, and zero human control.

---

### Assessment 3: Building the Solution 
> Outcome: IRL System

The natural progression: **Design and build a human-centered governance system**.

Working with teammates Julio and Tamara, we created the **Intelligent Multi-Tier Rate-Limiting System**â€”a 3500-word technical specification, a 12-minute presentation, and most importantly, a **production-ready implementation**.

These three assessments werenâ€™t random tasksâ€”they naturally built toward the final system.

---

## Cherry-Picking the Perfect Tech Stack
> Because I Could

One of the coolest parts of academic projects? **You get to choose your technologies strategically**.

I didn't just pick "what I know"â€”I picked **what I wanted to master**:

### Backend
- **Node.js + TypeScript**: Async-first for handling thousands of concurrent agents
- **GraphQL + Apollo Server**: Flexible querying for dashboard analytics
- **Redis**: Distributed token buckets with sub-millisecond latency

### Architecture
- **Rate Limiting Algorithms**: Sliding Window, Token Bucket, Weighted Fair Queuing
- **Carbon-Aware SDK**: Real-time grid intensity data from Green Software Foundation
- **Docker + Kubernetes**: Horizontal scaling across regions

### Why These Choices?
- **Redis**: Proven at scale (Twitter, GitHub, StackOverflow use it)
- **GraphQL**: Real-time subscriptions for dashboard updates
- **TypeScript**: Type safety prevents production bugs in async workflows

I containerized everything because the IRL stack is meant to scale horizontally across nodes.

---

## What Makes IRL Different? The 5 HCD Pillars

Traditional rate limiters are *constraints*. IRL is a **collaborative dialogue**.

### 1. **Visibility** â€“ See What Your AI Is Doing
Real-time dashboard showing:
- Request counts and quota consumption
- Projected costs (financial + carbon)
- When limits will reset

**No more black boxes.**

### 2. **Feedback** â€“ Understand *Why* You're Being Throttled

**Traditional rate limiter**:
```
HTTP 429 Too Many Requests
```

**IRL System**:
```
Request #547 blocked â€“ exceeds daily energy threshold 
(850kWh/day limit). Current usage: 847kWh. 

Reset in 25 minutes, or request override 
(2 escalations per day available).
```

That's **contrastive explanation** (Miller, 2019)â€”not just "what happened" but "why this happened and what would make it succeed."

### 3. **Fair Allocation** â€“ Equity, Not Just Equality

**The breakthrough moment**: Our team asked *"Fairness for whom?"*

A flat rate limit is **equal** but not **equitable**. It would crush independent researchers and startups while barely affecting well-funded enterprises.

**Our solution**: Weighted Fair Queuing
- Research/Education/Non-profits: **Priority tier**
- Startups: **Moderate allocation**
- Enterprises: **Standard rates** (but higher absolute quotas)

**Culturally adaptable**: Individualist cultures prefer personalized allocation; collectivist cultures favor community-centered sharing (Hofstede, 2011). Organizations can configure fairness models to match cultural expectations.

### 4. **Accountability** â€“ Immutable Audit Logs

Every throttling decision, override request, and ethical flag writes to an **append-only audit log**.

Captures:
- User ID, agent identifier, action requested
- Resources consumed, throttling decision
- Ethical flags triggered, override justifications

**This transforms accountability from abstract principle to concrete data artifact.**

### 5. **Sustainability** â€“ Carbon-Aware Throttling

Integration with real-time grid carbon intensity data.

When renewable energy drops (e.g., nighttime solar gaps), the system **automatically deprioritizes non-urgent agents**.

**Research-backed**: Wiesner et al. (2023) show temporal workload shifting reduces emissions by **15-30%** without degrading service quality.

**Projected impact**: 25-35% emissions reduction = ~800kg COâ‚‚/month (medium deployment) = **9,600 tonnes/year at 1,000-org scale** = equivalent to taking **2,000 cars off the road**.

---

## The Technical Implementation

### Core Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agentic AI     â”‚
â”‚  Workloads      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   IRL Governance Middleware     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Rate Limiting Engine     â”‚  â”‚
â”‚  â”‚  - Token Bucket           â”‚  â”‚
â”‚  â”‚  - Sliding Window         â”‚  â”‚
â”‚  â”‚  - Weighted Fair Queue    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Carbon Aware Scheduler   â”‚  â”‚
â”‚  â”‚  - Real-time grid data    â”‚  â”‚
â”‚  â”‚  - Temporal workload shiftâ”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Ethical Governance       â”‚  â”‚
â”‚  â”‚  - Policy schema eval     â”‚  â”‚
â”‚  â”‚  - Audit logging          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Backend APIs  â”‚
â”‚   (External)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### GraphQL Schema (Excerpt)

```graphql
type Agent {
  id: ID!
  name: String!
  tier: TierLevel!
  quotas: QuotaAllocation!
  currentUsage: UsageMetrics!
  carbonFootprint: Float!
}

type QuotaAllocation {
  requestsPerMinute: Int!
  dailyEnergyLimit: Float!
  escalationsAvailable: Int!
  resetTime: DateTime!
}

type ThrottlingDecision {
  allowed: Boolean!
  reason: String
  alternativeAction: String
  estimatedWaitTime: Int
}

type Mutation {
  requestOverride(
    agentId: ID!
    justification: String!
  ): OverrideResponse!
}
```

### Rate Limiting Algorithm (Simplified)

```typescript
async function evaluateRequest(
  agentId: string,
  action: AgentAction
): Promise<ThrottlingDecision> {
  const agent = await getAgent(agentId);
  const currentUsage = await redis.get(`usage:${agentId}`);
  
  // Check tier quotas
  if (currentUsage >= agent.quotas.requestsPerMinute) {
    return {
      allowed: false,
      reason: `Rate limit exceeded (${currentUsage}/${agent.quotas.requestsPerMinute})`,
      alternativeAction: "Request override or wait",
      estimatedWaitTime: calculateResetTime(agent)
    };
  }
  
  // Check carbon threshold
  const carbonIntensity = await carbonAwareSDK.getCurrentIntensity();
  if (carbonIntensity > THRESHOLD && !action.urgent) {
    return {
      allowed: false,
      reason: "High carbon intensity - non-urgent requests deprioritized",
      alternativeAction: "Schedule for low-carbon window",
      estimatedWaitTime: await predictLowCarbonWindow()
    };
  }
  
  // Increment usage
  await redis.incr(`usage:${agentId}`);
  return { allowed: true };
}
```

---

## The Results: Benchmarks & Impact

### Technical Performance (Simulated Load Testing)

| Metric | Target | Achieved | Status |
|--------|--------|----------|--------|
| Concurrent Agents | 50,000 | 50,000 | âœ… |
| Latency (P50) | <50ms | 42ms | âœ… |
| Throughput | 10k req/s | 12.5k req/s | âœ… |
| Abuse Detection Precision | >90% | 94% | âœ… |
| Abuse Detection Recall | >85% | 89% | âœ… |
| DDoS Uptime (100k malicious agents) | >99% | 99.7% | âœ… |

### Economic Impact Projections

**Cost Reduction**: 60-75% for runaway spend
- 40% from infinite loop prevention
- 15% from redundant call elimination
- 10% from query optimization
- Hard caps prevent $15k-$25k overnight disasters

**Real-world validation**: One pilot deployment avoided **3 billing catastrophes in first month**â€”each would have exceeded $20,000.

### Environmental Impact

**Carbon Footprint Reduction**: 25-35%
- 800 kg COâ‚‚/month (medium deployment)
- 9,600 tonnes/year at 1,000-org scale
- **Equivalent to 2,000 cars off the road**

---

## The Academic Rigor Behind It

This wasn't just a "build cool tech" project. It required:

### 17+ Academic References

- **Amershi et al. (2019)**: 18 Guidelines for Human-AI Interaction
- **Miller (2019)**: Contrastive explanations boost trust
- **Binns et al. (2018)**: Procedural transparency improves fairness perception
- **Strubell et al. (2019)**: Energy-aware ML infrastructure
- **Wiesner et al. (2023)**: Temporal workload shifting reduces emissions 15-30%
- **Alevizos et al. (2025)**: Carbon-efficient algorithm selection
- **Morley et al. (2021)**: Operationalizing AI ethics
- **Jobin et al. (2019)**: Global landscape of AI ethics guidelines

### 8 of Amershi's 18 Human-AI Interaction Guidelines

1. **G2**: Make clear what the system can do
2. **G7**: Support efficient invocation (override buttons)
3. **G8**: Support efficient dismissal (skip low-priority tasks)
4. **G10**: Mitigate social biases (culturally adaptive fairness)
5. **G12**: Learn from user behavior (adaptive quotas)
6. **G15**: Encourage granular feedback (appeal workflows)
7. **G16**: Convey consequences (carbon/cost projections)
8. **G18**: Provide global controls (admin overrides)

---

## Open Source & Demo

This project embodies my philosophy: **Build in public. Share generously.**

- [Assessment 1: Evolution of Technology](https://github.com/lfariabr/masters-swe-ai/blob/master/2025-T2/T2-HCD/assignments/Assessment1/HCD402_Faria_L_Assessment_1_SlideDeck_vf.pdf)
- [Assessment 2: Proposed Solution Report](https://github.com/lfariabr/masters-swe-ai/blob/master/2025-T2/T2-HCD/assignments/Assessment2/HCD402_Faria_L_Assessment_2.pdf)
- [Assessment 3: System Solution Report](https://github.com/lfariabr/masters-swe-ai/blob/master/2025-T2/T2-HCD/assignments/Assessment3/Faria_Luis_Assessment3_SystemSolution.pdf)
- [Assessment 3: System Solution Presentation](https://github.com/lfariabr/masters-swe-ai/blob/master/2025-T2/T2-HCD/assignments/Assessment3/Faria_Luis_Assessment3_Presentation.pdf)
- [IRL Source Code](https://github.com/lfariabr/masters-swe-ai/tree/master/2025-T2/T2-HCD/projects/IRL)

---

## Final Thoughts: Why This Matters

We're entering an era where **AI agents will outnumber human API users**. If we don't build governance systems *now*â€”systems that preserve transparency, fairness, and human agencyâ€”we'll wake up in a world where:

- Developers get surprise $50k bills
- Environmental costs remain invisible
- Accountability vanishes into "the algorithm did it"
- Only well-funded enterprises can afford AI infrastructure

**The IRL system proves that innovation and responsibility aren't competing goals. They're mutually reinforcing.**

---

## Letâ€™s Connect**

If you're working with healthcare data, KPIs, BI dashboards, or ML pipelines â€” Iâ€™d love to connect.

- **LinkedIn:** [linkedin.com/in/lfariabr](https://www.linkedin.com/in/lfariabr/)  
- **GitHub:** [github.com/lfariabr](https://github.com/lfariabr)  
- **Portfolio:** [luisfaria.dev](https://luisfaria.dev)

ğŸ‡¦ğŸ‡ºğŸ¦˜ğŸ”¥