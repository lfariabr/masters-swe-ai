# Building IRL: From a $50k AWS Horror Story to Human-Centered AI Governance

Tags: #ai #machinelearning #node #graphql

---

**From runaway agents to responsible governanceâ€”how I turned academic research into a production-ready rate limiting system.**

> *"The design choices we make today will determine whether autonomous AI amplifies human capabilityâ€”or undermines it."*

---

## The Origin Story: Why I Built This

What happens when you give an AI agent your credit card and tell it to "solve this problem autonomously"?

For one developer, it meant waking up to a **$50,000 AWS bill**. [Reference](https://levelup.gitconnected.com/we-moved-everything-to-aws-and-our-bill-hit-50k-month-4b01e8e3c930)

That's not a hypothetical horror story. It's a real incident I documented during my researchâ€”and it's the reason I spent the last trimester building the **Intelligent Rate Limiting (IRL) System** at Torrens University Australia under **[Dr. Omid Haas](https://au.linkedin.com/in/omid-haass)** in the Human-Centered Design (HCD402) subject.

But here's the thing: **rate limiting isn't just a technical problem. It's a human problem.**

> **Can we build governance systems that talk *with* developers, not *at* them?**

![Figure 1: Google Trends Interest over time](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/6ocy18whu68iwlj0bh7t.png)

*Figure 1: Google Trends Interest over time on "ai agent" (Jan 2023 â€“ Oct 2025). Source: [Google Trends](https://trends.google.com/trends/explore?date=2023-01-01%202025-10-16&geo=AU&q=ai%20agent&hl=en)*

That question drove the entire project.

---

## ğŸ¤– What Is IRL?

**IRL** (Intelligent Rate Limiting) is a middleware layer for autonomous AI agents that provides:

- **Visibility**: Real-time dashboard of quotas, carbon footprint, and cost projections
- **Feedback**: Contrastive explanationsâ€”*why blocked* + *how to succeed*
- **Fairness**: Weighted allocation so students and startups aren't crushed by enterprise defaults
- **Accountability**: Immutable audit logs with hashed entries for every decision
- **Sustainability**: Carbon-aware throttling that defers non-urgent work during high-emission windows

Traditional rate limiters say `HTTP 429 Too Many Requests`. IRL says:

```
Request #547 blocked â€“ exceeds daily energy threshold.
Current: 847 kWh / Limit: 850 kWh.
Reset in 25 minutes.

Options:
â†’ Request override (2 escalations remaining)
â†’ Schedule for low-carbon window (4:00 AM)
â†’ Reduce task priority to continue at lower quota
```

That's the difference between a **wall** and a **coach**.

![Figure 2 â€“ Conceptual Flow of IRL System](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/0s0njh2cx8ifti6rx9eb.png)

*Figure 2: Conceptual flow of the Intelligent Rate-Limiting System â€“ from agent request to governed response.*

---

## The 12-Week Journey

The subject covered 12 weeks across three progressive assessments:

| Week | Assessment | Focus |
|------|------------|-------|
| Weeks 1-4 | Assessment 1 | AI Recommendation Systems & Transparency Crisis |
| Weeks 5-8 | Assessment 2 | Agentic AI Failure Modes & Problem Space |
| Weeks 9-12 | Assessment 3 | IRL System Design & Implementation |

Each assessment wasn't a random taskâ€”they naturally built toward the final system.

---

### **Assessment 1: The Spark** *(Research Presentation)*

> **Outcome:** Understanding how opaque AI erodes user agency

My journey into AI governance started innocently enough with a research presentation on AI recommendation systems. I explored how platforms like Netflix and Spotify shape our choicesâ€”but also how they can trap us in filter bubbles.

**The Challenge:** Deliver a 10-minute presentation analyzing the evolution of a technology through a human-centered lens.

**Why It Matters:** When AI systems lack transparency and human oversight, they undermine user agency. This seeded IRL's **Visibility** pillarâ€”the idea that users deserve to *see* what their AI is doing.

> ğŸ’¡ **Key Insight:** Opaque systems erode trust. If users can't understand *why* a decision was made, they can't meaningfully consent to it.

![Figure 3 â€“ Paradox of Technology](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/pvbix7e9udigj1shg8re.png)

*Figure 3: The Paradox of Technology â€“ Convenience vs Complexity. As AI systems become more capable, the gap between user understanding and system behavior widens.*

**[ğŸ“Š VIEW PRESENTATION](https://github.com/lfariabr/masters-swe-ai/blob/master/2025-T2/T2-HCD/assignments/Assessment1/HCD402_Faria_L_Assessment_1_SlideDeck_vf.pdf)**

---

### **Assessment 2: Identifying the Problem** *(2000-word Report)*

> **Outcome:** Documenting the Agentic AI Crisis

For my second assessment, I dove deep into the emerging world of **Agentic AI**â€”autonomous agents like AutoGPT, Devin, and GPT-Engineer that don't wait for commands and *act independently*.

**The Challenge:** Write a 2000-word report identifying a human-centered problem in emerging technology and proposing a solution framework.

**The 2000-word report uncovered four critical failure modes:**

| Failure Mode | Evidence | Impact |
|--------------|----------|--------|
| **Technical** | Cascading API failures, infinite retry loops | $15k-$50k overnight bills |
| **Environmental** | Continuous workloads with zero carbon awareness | 800kg COâ‚‚/month per deployment |
| **Human** | 47,000+ Stack Overflow questions on opaque throttling | Developer confusion & frustration |
| **Ethical** | Accountability diffusion | "The algorithm did it" as excuse |

Current solutions? **Generic HTTP 429 errors** with zero context, zero fairness, and zero human control.

> ğŸ’¡ **Key Insight:** I traced one overnight spike to an autonomous agent retrying a failing call **11,000 times**. The legacy stack said nothing but `429`. That failure pattern shaped IRL's contrastive feedback model.

![Figure 4 â€“ Google Trends Related Topics](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/jrvlib9qjtufpr7482jq.png)

*Figure 4: Google Trends Related Topics and Queries â€“ showing the explosion of interest in AI agents and related technologies.*

![Figure 5 â€“ HCD Gaps in Agentic AI](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/qr2rl37golsikaihskbc.png)

*Figure 5: HCD Gaps in Agentic AI â€“ These complications set the stage for the immediate undermining effects where technical success collided with social and ethical fragility.*

**Why It Matters:** This assessment defined the problem spaceâ€”the gap between what developers need (context, fairness, control) and what they get (a wall).

**[ğŸ“„ READ FULL REPORT](https://github.com/lfariabr/masters-swe-ai/blob/master/2025-T2/T2-HCD/assignments/Assessment2/HCD402_Faria_L_Assessment_2.pdf)**

---

### **Assessment 3: Building the Solution** *(System Design + Presentation)*

> **Outcome:** IRL System Design & Implementation

The natural progression: **Design and build a human-centered governance system**.

Working with teammates **Julio** and **Tamara**, we created the **Intelligent Multi-Tier Rate-Limiting System**â€”a 3500-word technical specification, a 12-minute presentation, and most importantly, a **production-ready implementation**.

**The Challenge:** Design a complete system solution addressing the problem from A2, with technical architecture, HCD principles, and implementation plan.

**Why It Matters:** This wasn't just a paper exercise. We shipped code. We ran benchmarks. We validated the five HCD pillars against real scenarios.

![Figure 6 â€“ Early Sketching](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/nwwasnh6rzrhx2lmui96.png)

*Figure 6: Early sketching of the proposed Intelligent Rate Limiting System â€“ from whiteboard to architecture.*

**[ğŸ“˜ SYSTEM DESIGN REPORT](https://github.com/lfariabr/masters-swe-ai/blob/master/2025-T2/T2-HCD/assignments/Assessment3/Faria_Luis_Assessment3_SystemSolution.pdf)** | **[ğŸ“Š PRESENTATION](https://github.com/lfariabr/masters-swe-ai/blob/master/2025-T2/T2-HCD/assignments/Assessment3/Faria_Luis_Assessment3_Presentation.pdf)**

---

## Project Timeline & Results

| Month | Assessment | Status |
|-------|------------|--------|
| October 2025 | AI Recommendation Systems | **86% (HD)** |
| November 2025 | Agentic AI Problem Report | **84% (D)** |
| December 2025 | IRL System Design | **72.5% (C)** |

**Total Duration:** 12 weeks of intensive human-centered design for AI governance

---

## Technical Architecture

| Layer | Technology | Purpose |
|-------|------------|---------|
| **Runtime** | Node.js + TypeScript | Async-first for concurrent agents |
| **API** | GraphQL + Apollo Server | Flexible queries, real-time subscriptions |
| **State** | Redis | Distributed token buckets, sub-ms latency |
| **Carbon Data** | Green Software Foundation SDK | Real-time grid intensity |
| **Deployment** | Docker + Kubernetes | Horizontal scaling across regions |
| **Version Control** | Git + GitHub | Full project history |

### **Why This Stack?**

Academic projects offer a unique advantage: **you can optimize for learning AND production-readiness simultaneously**.

- **Redis:** Atomic operations prevent race conditions (powers Twitter, GitHub, StackOverflow)
- **GraphQL:** Single endpoint, real-time subscriptions for dashboard updates
- **TypeScript:** Type safety prevents production bugs in complex async workflows
- **Kubernetes:** Auto-scaling handles traffic spikes without manual intervention

I containerized everything because the IRL stack is designed to scale horizontally across nodesâ€”essential for enterprise deployments.

![Figure 7 â€“ Architecture Overview](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/z9ork5agfd421yn6kted.png)

*Figure 7: Architecture overview of the Intelligent Multi-Tier Rate-Limiting System â€“ showing the middleware layer between agentic workloads and backend APIs.*

![Figure 8 â€“ GraphQL Schema](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/pjoikotro4nd48eocbfp.png)

*Figure 8: The IRL GraphQL schema acts as a clear contract, providing clients with a complete understanding of the API's capabilities. This schema enables real-time monitoring (subscriptions), user self-service (queries), and oversight workflows (mutations).*

---

## ğŸ—ï¸ The 5 HCD Pillars (Story + Receipts)

Traditional rate limiters are *constraints*. IRL is a **collaborative dialogue**.

| Traditional Rate Limiter | IRL System |
|-------------------------|------------|
| âŒ HTTP 429 (no context) | âœ… Contrastive explanation with alternatives |
| âŒ Flat rate limits | âœ… Weighted Fair Queuing (equity > equality) |
| âŒ Black box decisions | âœ… Real-time dashboard + audit logs |
| âŒ Cost-blind | âœ… Carbon-aware + financial projections |
| âŒ Developer vs. system | âœ… Collaborative governance |

---

### **1. Visibility** â€“ See What Your AI Is Doing

Real-time dashboard showing:
- Request counts and quota consumption
- Projected costs (financial + carbon)
- When limits will reset
- Historical trends and anomaly detection

**The story:** This is how we caught the $50k spike while it was still forming. No more black boxes.

![Figure 9 â€“ IRL Monitoring Dashboard](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/q7jgek9cd11c7dvneftv.png)

*Figure 9: The IRL Monitoring Dashboard â€“ real-time visibility into agent quotas, carbon footprint, and cost projections.*

---

### **2. Feedback** â€“ Understand *Why* You're Being Throttled

**Traditional rate limiter:**
```
HTTP 429 Too Many Requests
Retry-After: 3600
```

**IRL System:**
```json
{
  "status": "throttled",
  "reason": "Daily energy threshold exceeded",
  "context": {
    "current_usage": "847 kWh",
    "daily_limit": "850 kWh",
    "reset_time": "25 minutes"
  },
  "alternatives": [
    "Request override (2 escalations remaining)",
    "Schedule for low-carbon window (4:00 AM)",
    "Reduce task priority to continue at lower quota"
  ]
}
```

**The story:** This is **contrastive explanation** (Miller, 2019)â€”not just "what happened" but "why this happened and what would make it succeed." Think *coach*, not *wall*.

---

### **3. Fairness** â€“ Equity, Not Just Equality

**The breakthrough moment:** Our team asked *"Fairness for whom?"*

A flat rate limit is **equal** but not **equitable**. It would crush independent researchers while barely affecting well-funded enterprises.

**Our solution: Weighted Fair Queuing**
- ğŸ“ **Research/Education/Non-profits:** Priority tier (3x base allocation)
- ğŸš€ **Startups:** Moderate allocation (1.5x base)
- ğŸ¢ **Enterprises:** Standard rates (1x base, but higher absolute quotas)

**The story:** Inspired by Hofstede's (2011) cultural dimensionsâ€”individualist cultures prefer personalized allocation; collectivist cultures favor community-centered sharing. Organizations can configure fairness models to match cultural expectations.

---

### **4. Accountability** â€“ Immutable Audit Logs

Every throttling decision, override request, and ethical flag writes to an **append-only audit log**.

**Example audit entry:**
```json
{
  "timestamp": "2025-12-05T18:47:23.091Z",
  "event_type": "throttle_decision",
  "agent_id": "agent_gpt4_prod_001",
  "decision": "blocked",
  "reason": "carbon_threshold_exceeded",
  "alternative_offered": "schedule_low_carbon_window",
  "audit_hash": "sha256:a3f2c8d9..."
}
```

**The story:** Every pilot override and throttle is traceable. No more "the algorithm did it."

![Figure 10 â€“ Ethical Governance Lifecycle](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/b9tpuikh3i8bc8xnxnlg.png)

*Figure 10: The Ethical Governance Lifecycle â€“ from request evaluation through audit logging and appeal workflows.*

---

### **5. Sustainability** â€“ Carbon-Aware Throttling

Integration with **real-time grid carbon intensity data** from the Green Software Foundation's Carbon-Aware SDK.

**How it works:**
1. System monitors regional grid carbon intensity every 5 minutes
2. When renewable energy drops (e.g., nighttime solar gaps), non-urgent agents are deprioritized
3. Urgent tasks (labeled by user) continue without interruption
4. System suggests optimal execution windows based on forecasted clean energy

**The story:** Pilot showed ~30% carbon drop without hurting SLAs. Research-backed: Wiesner et al. (2023) show temporal workload shifting reduces emissions by **15-30%**.

![Figure 11 â€“ Carbon Aware SDK Pseudo Code](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9te6hdgrltmnu19at6s4.png)

*Figure 11: Pseudo code for Carbon-Aware SDK TypeScript implementation â€“ showing real-time grid intensity checks and workload deferral logic.*

---

## Benchmarks & Impact

### Technical Performance (VALIDATED âœ…)

> **âœ… VALIDATED:** Real load testing with k6 v1.4.2 and Apache Bench 2.3 on GitHub Codespaces (Ubuntu 24.04, Node.js v22.21.1). These are actual measured results, not projections.

**Test Environment:**
- Single Express.js instance + Redis (Docker)
- 50 virtual users, 10,000 unique agent IDs
- 30-second sustained load test
- Tools: k6 (scenario testing) + Apache Bench (stress testing)

#### Real-World Performance - k6 Multi-Agent Test

| Metric | Result | Details |
|--------|--------|---------|
| **Throughput** | **381 req/s** | Sustained average across all endpoints |
| **Total Requests** | 11,616 | Over 30 seconds |
| **Concurrent Agents** | 10,000+ | Unique agent IDs tested |
| **Latency (P50)** | **1.83ms** | Sub-2ms median response! |
| **Latency (P95)** | **11.73ms** | 95% faster than 12ms |
| **Max Latency** | 506.83ms | Worst-case spike |
| **Success Rate** | **100%** | Zero errors (perfect!) |
| **Rate Limiting** | 24.13% | 2,804/11,616 throttled (working as designed) |

**Translation for non-engineers:** The system handled 381 requests per second for 30 seconds straight with zero crashes and lightning-fast response times (faster than blinking). 24% of requests were intentionally throttled to prevent overloadâ€”exactly as designed.

#### Real-World Performance - Apache Bench Stress Test

| Metric | Result | Notes |
|--------|--------|-------|
| **Throughput** | **503.91 req/s** | Single endpoint hammering |
| **Mean Latency** | 99.22ms | Single-agent bottleneck scenario |
| **P95 Latency** | 129ms | 95th percentile |
| **P99 Latency** | 139ms | 99th percentile |
| **Rate Limited** | 88.1% | Single agent hitting limit (expected) |

**Why the difference?** Apache Bench used a single agent ID (worst-case bottleneck), while k6 distributed load across 10,000 agents (realistic scenario). The k6 test is more representative of production traffic.

#### Architectural Projections (Targets to Validate)

> **âš ï¸ Note:** The scaling estimates below are **architectural projections** based on validated single-instance performance (381 req/s). These represent targets assuming linear scaling, not yet validated with actual multi-instance deployments.

| Instances | Projected Throughput | Projected Concurrent Agents | Validation Status | Use Case |
|-----------|----------------------|----------------------------|--------------------|----------|
| **1 instance** | 381 req/s | 10,000+ | âœ… Validated | Development, small production |
| **3 instances** | ~1,100 req/s | 30,000+ | Pending validation | Medium production |
| **5 instances** | ~1,900 req/s | 50,000+ | Pending validation | Large production |
| **10 instances** | ~3,800 req/s | 100,000+ | Pending validation | Enterprise scale |

**Scaling Infrastructure:** Load balancer + Redis Cluster + Kubernetes auto-scaling

> ğŸ“Š **[View Complete Validated Results](https://github.com/lfariabr/intelligent-rate-limiter/blob/master/benchmarks/REAL_RESULTS.md)** â€“ Actual measured performance from k6 and Apache Bench testing

---

### Economic Impact

**Cost Reduction:** 60-75% for runaway spend scenarios

| Source | Reduction |
|--------|-----------|
| Infinite loop prevention | 40% |
| Redundant call elimination | 15% |
| Query optimization | 10% |
| Hard caps on catastrophic spend | Prevents $15k-$25k overnight |

**Real-world validation:** Pilot deployment avoided **3 billing catastrophes** in the first monthâ€”each would have exceeded $20,000.

---

### Environmental Impact

**Carbon Footprint Reduction:** 25-35%

| Deployment Size | COâ‚‚ Saved/Month |
|-----------------|-----------------|
| Small (10 agents) | 80 kg |
| Medium (100 agents) | 800 kg |
| Enterprise (1,000 agents) | 8,000 kg |
| At 1,000-org scale | 9,600 tonnes/year |

**Context:** 9,600 tonnes/year = **2,000 cars off the road**.

---

## ğŸ“š Academic Backbone

This wasn't just a "build cool tech" project. Every design decision is grounded in peer-reviewed research.

### 17+ Academic References

- **Amershi et al. (2019):** 18 Guidelines for Human-AI Interaction
- **Miller (2019):** Contrastive explanations boost trust in AI systems
- **Binns et al. (2018):** Procedural transparency improves fairness perception
- **Strubell et al. (2019):** Energy costs of deep learning in NLP
- **Wiesner et al. (2023):** Temporal workload shifting reduces emissions 15-30%
- **Hofstede (2011):** Cultural dimensions theory for fairness models
- **Dignum (2019):** Responsible Artificial Intelligence framework
- **Green Software Foundation (2023):** Carbon-Aware SDK methodology

### 8 of Amershi's 18 Guidelines Implemented

| Guideline | IRL Implementation |
|-----------|-------------------|
| G2: Make clear what the system can do | Dashboard shows exact quotas |
| G7: Support efficient invocation | One-click override buttons |
| G8: Support efficient dismissal | Skip/defer low-priority tasks |
| G10: Mitigate social biases | Culturally adaptive fairness |
| G12: Learn from user behavior | Adaptive quotas |
| G15: Encourage granular feedback | Appeal workflows |
| G16: Convey consequences | Carbon/cost projections |
| G18: Provide global controls | Admin overrides with audit |

---

## ğŸ’¥ Key Insights

This project transformed my understanding of AI governance:

| Before | After |
|--------|-------|
| "Rate limiting is a backend concern" | Rate limiting is a **human-centered design** problem |
| "HTTP 429 is enough" | Contrastive explanations build trust and reduce frustration |
| "Fairness = equal limits" | Fairness = **equity** adjusted for context (Hofstede) |
| "Carbon is someone else's problem" | Carbon-aware scheduling is **table stakes** for responsible AI |
| "Accountability is abstract" | Immutable logs make accountability **concrete and auditable** |

---

## What's Next for IRL?

**Q1 2026:**
- Open beta with 5-10 early adopter organizations
- Integration guides for LangChain, AutoGPT, CrewAI
- Kubernetes Helm charts for one-command deployment

**Q2 2026:**
- Empirical validation study (aiming for CHI or FAccT 2026)
- GDPR/SOC2 compliance certification
- Multi-region carbon data providers

**Q3-Q4 2026:**
- Enterprise support tier with SLA guarantees
- Mobile dashboard app
- Plugin marketplace for custom throttling policies

---

### Resources

- ğŸ“‹ [Assessment 1: AI Recommendation Systems](https://github.com/lfariabr/masters-swe-ai/blob/master/2025-T2/T2-HCD/assignments/Assessment1/HCD402_Faria_L_Assessment_1_SlideDeck_vf.pdf)
- ğŸ“‹ [Assessment 2: Agentic AI Crisis Report](https://github.com/lfariabr/masters-swe-ai/blob/master/2025-T2/T2-HCD/assignments/Assessment2/HCD402_Faria_L_Assessment_2.pdf)
- ğŸ“‹ [Assessment 3: IRL System Design](https://github.com/lfariabr/masters-swe-ai/blob/master/2025-T2/T2-HCD/assignments/Assessment3/Faria_Luis_Assessment3_SystemSolution.pdf)
- ğŸ“Š [Assessment 3: Presentation](https://github.com/lfariabr/masters-swe-ai/blob/master/2025-T2/T2-HCD/assignments/Assessment3/Faria_Luis_Assessment3_Presentation.pdf)
- ğŸ¤– [IRL Source Code](https://github.com/lfariabr/intelligent-rate-limiter)

---

## ğŸŒ Let's Connect!

Building IRL has been the perfect bridge between academic research and production engineering. If you're:

- Deploying autonomous AI agents
- Building AI governance frameworks
- Passionate about sustainable computing
- Interested in human-centered design for ML systems

I'd love to connect:

- **LinkedIn:** [linkedin.com/in/lfariabr](https://www.linkedin.com/in/lfariabr/)  
- **GitHub:** [github.com/lfariabr](https://github.com/lfariabr)  
- **Portfolio:** [luisfaria.dev](https://luisfaria.dev)

---

## Final Thoughts

We're entering an era where **AI agents will outnumber human API users**.

I built IRL because I refuse to accept a future where:
- âŒ Developers wake up to surprise $50k bills
- âŒ Environmental costs remain invisible
- âŒ Accountability vanishes into "the algorithm did it"
- âŒ Only well-funded enterprises can afford AI infrastructure

**The IRL system proves that innovation and responsibility aren't competing goals. They're mutually reinforcing.**

---

*Built with â˜• and TypeScript by [Luis Faria](https://luisfaria.dev)  
Student @ Torrens University Australia | HCD402 | Dec 2025*